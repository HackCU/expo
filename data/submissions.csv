Opt-in prize,Submission Title,Submission Url,Submission Tagline,Submission Created At,Plain Description,Video,Website,File Url,Built With,Mlh Points,If You Submitted For The Domain.Com Prize What Was The Domain You Chose?,Mlh Hardware Lab,Mlh Software Lab,Submitter Screen Name,Submitter First Name,Submitter Last Name,Submitter Email,College/Universities Of Team Members,Additional Team Member Count,Team Member 1 Screen Name,Team Member 1 First Name,Team Member 1 Last Name,Team Member 1 Email,...
MLH: Best use of MongoDB Atlas,SpeakUp,https://hackcu-vi.devpost.com/submissions/142659-speakup,"SpeakUp is a platform that gives victims/survivors a voice speaking out against acts of bullying, racial discrimination and domestic violence.",02/22/2020 16:10:25,"Inspiration

Victims of bullying, domestic abuse, and racism feel as if their voices are silenced through the current legal system. Various methods of reporting incidents undergo a strenuous routine that leaves the victim feeling silenced. Reported incidents of bullying, racial discrimination, and domestic violence have the possibility of being drowned out by the local schools, workplaces, and the local police force. Using the SpeakUp application will give the victims and survivors of various incidents a platform to speak their truth and raise awareness of issues within the community as well. 

What it does

SpeakUp is designed to be accessible from any device anywhere in the nation. This platform uses an independent database system to record all reports of incidents and flag particular incidents. The database collects the number of times an incident has been filed against a specific person. If there is a buildup of incidents reported the database is triggered and will send a notification to the local resources regarding the accumulation of incident reports. If an incident is deemed critical by the monitor of the database they flag the incident and send a notification to resources in the local area regarding the specific incident. SpeakUp logs the victim/survivors' name, location, description of the incident, and when the incident occurred. This information (except the victim/survivor's name) is provided to the public on the website. 

How SpeakUp was built

Database

The database is built with MongoDB Atlas on Google Cloud, and served by Python on Amazon Web Services.

Incident Reporting System

The hardware interface is built with the database using an LCD screen, switches, potentiometer, buttons, and the brain is a particle photon developed using a custom C++

SpeakUp App

Flutter is the main framework for the app, and dart is the language used. Also, android studio is used to emulate a phone with the screen recorder.

Challenges

Credibility

Maintaining credibility for this project was challenging. Utilizing the public voice, the incidents reported to SpeakUp will be able to be tracked and reviewed by the public. Also, there will be a person who monitors and reads all reports of incidents to determine if the incident should be flagged and to track the legitimacy of the victim/survivor. 

Technical challenges

Learning to use Flutter/Dart, a language that is relatively new and lacks online help.


Sending form responses via HTTPS to the mongoDB database from the forms created in Flutter as there wasn't much documentation/help online as to how achieve this. 
Attempting to have a three-way link between the forms created in Flutter , the mongoDB database and the Photon IOT device.  


What we learned


Using Flutter to create responsive cross-platform applications
Connecting Python with MongoDB database and attempting to GET/POST requests
Learned how to integrate the Photon IOT, display text, use the controls, add buttons
Application of better teamwork skills
Working with multiple frameworks


Why SpeakUp is necessary

The silenced victims/survivors of reported crimes and incidents will gain back their voice with the use of SpeakUp.  SpeakUp will help accumulate and report data based on user-reported incidents. There is an abundance of crimes that are reported, but a minuscule amount of the reports are actually logged within the databases run by law enforcement. Currently, there is a crisis impacting the Indigenous people of this nation, the MMIW (Murdered and Missing Indigenous Women.) There are thousands of reported murdered and missing Indigenous women across this country mainly located on reservations. Furthermore, very few of the reports actually make it into the databases. For example, in 2016, there were 5,712 reported cases regarding the MMIW crisis, but only two percent of the reports were logged in the database run by the  US Department of Justice’s federal missing person database (Lucchesi and Echo-Hawk 2). Additionally, there is an alarming amount of domestic violence reports related to a higher socioeconomic status in married couples. A study conducted in 2016, regarding the relationship between higher incomes and domestic violence, showed a positive correlation with each other (Farmer and Tiefenthaler 1858). Lastly, there is consistency towards low-income areas and a higher than average crime rate. A study conducted in 2017 concluded that areas with higher income inequality are subject to more crime. Thus, supporting the notion that areas with low income are more vulnerable to crime than areas with a higher income rate (Hip and Kubrin 148). This research justifies the need for SpeakUp in both low and high-income areas, as well as rural areas with little to none federal action. 

Sources Cited

Farmer, Amy, and Jill Tiefenthaler. “An Economic Analysis of Domestic Violence.” Review of Social Economy, vol. 55, 
       no. 3, 1997, pp. 337–358. JSTOR, www.jstor.org/stable/29769903. Accessed 23 Feb. 2020.

John R. Hipp, and Charis E. Kubrin. “From Bad to Worse: How Changing Inequality in Nearby Areas Impacts Local 
      Crime.” RSF: The Russell Sage Foundation Journal of the Social Sciences, vol. 3, no. 2, 2017, pp. 129–151. 
      JSTOR, www.jstor.org/stable/10.7758/rsf.2017.3.2.06. Accessed 23 Feb. 2020.

Lucchesi, Annita, and Abigail Echo-Hawk. Missing and Murdered Indigenous Women and Girls. Urban Indian Health 
     Institute, 2016, pp. 1–32, Missing and Murdered Indigenous Women and Girls.
",https://www.youtube.com/watch?v=dXNwrWTEvGs,https://github.com/Kareem21/SpeakUp---HackCU-2020-project,,"flutter, dart, mongodb",Colorado State University,"","","",Kareemator,Kareem,Youssef,kareemy9000@gmail.com,Colorado State University,3,CaseyKey,Casey,Key,casey.james.key@gmail.com,MiguelAnGuerrero,Miguel,Guerrero,miguel.guerrero5445@gmail.com,lizzyandhackathons,lizzy,osterhoudt,littlebugga@live.com
MLH: Best Use of Google Cloud,SpeakUp,https://hackcu-vi.devpost.com/submissions/142659-speakup,"SpeakUp is a platform that gives victims/survivors a voice speaking out against acts of bullying, racial discrimination and domestic violence.",02/22/2020 16:10:25,"Inspiration

Victims of bullying, domestic abuse, and racism feel as if their voices are silenced through the current legal system. Various methods of reporting incidents undergo a strenuous routine that leaves the victim feeling silenced. Reported incidents of bullying, racial discrimination, and domestic violence have the possibility of being drowned out by the local schools, workplaces, and the local police force. Using the SpeakUp application will give the victims and survivors of various incidents a platform to speak their truth and raise awareness of issues within the community as well. 

What it does

SpeakUp is designed to be accessible from any device anywhere in the nation. This platform uses an independent database system to record all reports of incidents and flag particular incidents. The database collects the number of times an incident has been filed against a specific person. If there is a buildup of incidents reported the database is triggered and will send a notification to the local resources regarding the accumulation of incident reports. If an incident is deemed critical by the monitor of the database they flag the incident and send a notification to resources in the local area regarding the specific incident. SpeakUp logs the victim/survivors' name, location, description of the incident, and when the incident occurred. This information (except the victim/survivor's name) is provided to the public on the website. 

How SpeakUp was built

Database

The database is built with MongoDB Atlas on Google Cloud, and served by Python on Amazon Web Services.

Incident Reporting System

The hardware interface is built with the database using an LCD screen, switches, potentiometer, buttons, and the brain is a particle photon developed using a custom C++

SpeakUp App

Flutter is the main framework for the app, and dart is the language used. Also, android studio is used to emulate a phone with the screen recorder.

Challenges

Credibility

Maintaining credibility for this project was challenging. Utilizing the public voice, the incidents reported to SpeakUp will be able to be tracked and reviewed by the public. Also, there will be a person who monitors and reads all reports of incidents to determine if the incident should be flagged and to track the legitimacy of the victim/survivor. 

Technical challenges

Learning to use Flutter/Dart, a language that is relatively new and lacks online help.


Sending form responses via HTTPS to the mongoDB database from the forms created in Flutter as there wasn't much documentation/help online as to how achieve this. 
Attempting to have a three-way link between the forms created in Flutter , the mongoDB database and the Photon IOT device.  


What we learned


Using Flutter to create responsive cross-platform applications
Connecting Python with MongoDB database and attempting to GET/POST requests
Learned how to integrate the Photon IOT, display text, use the controls, add buttons
Application of better teamwork skills
Working with multiple frameworks


Why SpeakUp is necessary

The silenced victims/survivors of reported crimes and incidents will gain back their voice with the use of SpeakUp.  SpeakUp will help accumulate and report data based on user-reported incidents. There is an abundance of crimes that are reported, but a minuscule amount of the reports are actually logged within the databases run by law enforcement. Currently, there is a crisis impacting the Indigenous people of this nation, the MMIW (Murdered and Missing Indigenous Women.) There are thousands of reported murdered and missing Indigenous women across this country mainly located on reservations. Furthermore, very few of the reports actually make it into the databases. For example, in 2016, there were 5,712 reported cases regarding the MMIW crisis, but only two percent of the reports were logged in the database run by the  US Department of Justice’s federal missing person database (Lucchesi and Echo-Hawk 2). Additionally, there is an alarming amount of domestic violence reports related to a higher socioeconomic status in married couples. A study conducted in 2016, regarding the relationship between higher incomes and domestic violence, showed a positive correlation with each other (Farmer and Tiefenthaler 1858). Lastly, there is consistency towards low-income areas and a higher than average crime rate. A study conducted in 2017 concluded that areas with higher income inequality are subject to more crime. Thus, supporting the notion that areas with low income are more vulnerable to crime than areas with a higher income rate (Hip and Kubrin 148). This research justifies the need for SpeakUp in both low and high-income areas, as well as rural areas with little to none federal action. 

Sources Cited

Farmer, Amy, and Jill Tiefenthaler. “An Economic Analysis of Domestic Violence.” Review of Social Economy, vol. 55, 
       no. 3, 1997, pp. 337–358. JSTOR, www.jstor.org/stable/29769903. Accessed 23 Feb. 2020.

John R. Hipp, and Charis E. Kubrin. “From Bad to Worse: How Changing Inequality in Nearby Areas Impacts Local 
      Crime.” RSF: The Russell Sage Foundation Journal of the Social Sciences, vol. 3, no. 2, 2017, pp. 129–151. 
      JSTOR, www.jstor.org/stable/10.7758/rsf.2017.3.2.06. Accessed 23 Feb. 2020.

Lucchesi, Annita, and Abigail Echo-Hawk. Missing and Murdered Indigenous Women and Girls. Urban Indian Health 
     Institute, 2016, pp. 1–32, Missing and Murdered Indigenous Women and Girls.
",https://www.youtube.com/watch?v=dXNwrWTEvGs,https://github.com/Kareem21/SpeakUp---HackCU-2020-project,,"flutter, dart, mongodb",Colorado State University,"","","",Kareemator,Kareem,Youssef,kareemy9000@gmail.com,Colorado State University,3,CaseyKey,Casey,Key,casey.james.key@gmail.com,MiguelAnGuerrero,Miguel,Guerrero,miguel.guerrero5445@gmail.com,lizzyandhackathons,lizzy,osterhoudt,littlebugga@live.com
Sustainability,SpeakUp,https://hackcu-vi.devpost.com/submissions/142659-speakup,"SpeakUp is a platform that gives victims/survivors a voice speaking out against acts of bullying, racial discrimination and domestic violence.",02/22/2020 16:10:25,"Inspiration

Victims of bullying, domestic abuse, and racism feel as if their voices are silenced through the current legal system. Various methods of reporting incidents undergo a strenuous routine that leaves the victim feeling silenced. Reported incidents of bullying, racial discrimination, and domestic violence have the possibility of being drowned out by the local schools, workplaces, and the local police force. Using the SpeakUp application will give the victims and survivors of various incidents a platform to speak their truth and raise awareness of issues within the community as well. 

What it does

SpeakUp is designed to be accessible from any device anywhere in the nation. This platform uses an independent database system to record all reports of incidents and flag particular incidents. The database collects the number of times an incident has been filed against a specific person. If there is a buildup of incidents reported the database is triggered and will send a notification to the local resources regarding the accumulation of incident reports. If an incident is deemed critical by the monitor of the database they flag the incident and send a notification to resources in the local area regarding the specific incident. SpeakUp logs the victim/survivors' name, location, description of the incident, and when the incident occurred. This information (except the victim/survivor's name) is provided to the public on the website. 

How SpeakUp was built

Database

The database is built with MongoDB Atlas on Google Cloud, and served by Python on Amazon Web Services.

Incident Reporting System

The hardware interface is built with the database using an LCD screen, switches, potentiometer, buttons, and the brain is a particle photon developed using a custom C++

SpeakUp App

Flutter is the main framework for the app, and dart is the language used. Also, android studio is used to emulate a phone with the screen recorder.

Challenges

Credibility

Maintaining credibility for this project was challenging. Utilizing the public voice, the incidents reported to SpeakUp will be able to be tracked and reviewed by the public. Also, there will be a person who monitors and reads all reports of incidents to determine if the incident should be flagged and to track the legitimacy of the victim/survivor. 

Technical challenges

Learning to use Flutter/Dart, a language that is relatively new and lacks online help.


Sending form responses via HTTPS to the mongoDB database from the forms created in Flutter as there wasn't much documentation/help online as to how achieve this. 
Attempting to have a three-way link between the forms created in Flutter , the mongoDB database and the Photon IOT device.  


What we learned


Using Flutter to create responsive cross-platform applications
Connecting Python with MongoDB database and attempting to GET/POST requests
Learned how to integrate the Photon IOT, display text, use the controls, add buttons
Application of better teamwork skills
Working with multiple frameworks


Why SpeakUp is necessary

The silenced victims/survivors of reported crimes and incidents will gain back their voice with the use of SpeakUp.  SpeakUp will help accumulate and report data based on user-reported incidents. There is an abundance of crimes that are reported, but a minuscule amount of the reports are actually logged within the databases run by law enforcement. Currently, there is a crisis impacting the Indigenous people of this nation, the MMIW (Murdered and Missing Indigenous Women.) There are thousands of reported murdered and missing Indigenous women across this country mainly located on reservations. Furthermore, very few of the reports actually make it into the databases. For example, in 2016, there were 5,712 reported cases regarding the MMIW crisis, but only two percent of the reports were logged in the database run by the  US Department of Justice’s federal missing person database (Lucchesi and Echo-Hawk 2). Additionally, there is an alarming amount of domestic violence reports related to a higher socioeconomic status in married couples. A study conducted in 2016, regarding the relationship between higher incomes and domestic violence, showed a positive correlation with each other (Farmer and Tiefenthaler 1858). Lastly, there is consistency towards low-income areas and a higher than average crime rate. A study conducted in 2017 concluded that areas with higher income inequality are subject to more crime. Thus, supporting the notion that areas with low income are more vulnerable to crime than areas with a higher income rate (Hip and Kubrin 148). This research justifies the need for SpeakUp in both low and high-income areas, as well as rural areas with little to none federal action. 

Sources Cited

Farmer, Amy, and Jill Tiefenthaler. “An Economic Analysis of Domestic Violence.” Review of Social Economy, vol. 55, 
       no. 3, 1997, pp. 337–358. JSTOR, www.jstor.org/stable/29769903. Accessed 23 Feb. 2020.

John R. Hipp, and Charis E. Kubrin. “From Bad to Worse: How Changing Inequality in Nearby Areas Impacts Local 
      Crime.” RSF: The Russell Sage Foundation Journal of the Social Sciences, vol. 3, no. 2, 2017, pp. 129–151. 
      JSTOR, www.jstor.org/stable/10.7758/rsf.2017.3.2.06. Accessed 23 Feb. 2020.

Lucchesi, Annita, and Abigail Echo-Hawk. Missing and Murdered Indigenous Women and Girls. Urban Indian Health 
     Institute, 2016, pp. 1–32, Missing and Murdered Indigenous Women and Girls.
",https://www.youtube.com/watch?v=dXNwrWTEvGs,https://github.com/Kareem21/SpeakUp---HackCU-2020-project,,"flutter, dart, mongodb",Colorado State University,"","","",Kareemator,Kareem,Youssef,kareemy9000@gmail.com,Colorado State University,3,CaseyKey,Casey,Key,casey.james.key@gmail.com,MiguelAnGuerrero,Miguel,Guerrero,miguel.guerrero5445@gmail.com,lizzyandhackathons,lizzy,osterhoudt,littlebugga@live.com
Most Random,GreenScreen,https://hackcu-vi.devpost.com/submissions/142719-greenscreen,Ever feel like the internet isn't a very vegan-friendly place? Let's change that.,02/22/2020 20:09:56,"Why GreenScreen?

The internet is rife with images and language that can be disturbing to individuals who follow a vegan lifestyle. Wouldn't it be nice if your browser could ensure that you won't be exposed to the undue stress that an unfiltered internet brings?

Experience a Kinder Internet

GreenScreen is a Google Chrome extension that filters out any words and images that are not vegan-friendly and replaces them with plant-based alternatives. This will ensure ease of mind when browsing, and even come up with vegan-friendly recipe substitutions for when you find a recipe that wasn't developed with moral concern in mind.

Behind the Screen

We began by creating a simple Chrome extension that replaced meat-related terms on any webpage with a random vegetable-related word. We then added the functionality to replace images on a page, and further refined that to replace only images that contained meat. This was done by piping image data through the Watson API, which classifies images based on key terms that relate to the image contents, and only targeting images that contain potentially disturbing content.

Our Journey

Chrome extensions don't interface nicely with Node.js, so we had to troubleshoot this and eventually resort to writing our extension in raw JavaScript. This was a challenge for all of our team members, non of whom had much prior experience with the language. We used a Watson image-recognition API instead of our original plan, which was the Google Cloud Vision API, because of troubles with authorization across HTTP calls. Additionally, one of our members was editing the DevPost with the word-replacement extension enabled, which replaced some choice words in the text and caused confusion when the DevPost decided to save the edited text.

Compatibility

GreenScreen works brilliantly for websites! However, because of Google's image caching procedures, this extension won't be successful for Google Images searches. If you'd like to see an example of how the image search replacement would work if Google was slightly less secure, navigate to Bing.com and run an images search there--it'll behave as expected. The word replacement algorithm works universally.
",,https://github.com/ecmele/lettuce,,"javascript, ibm-watson",Colorado School of Mines,"","","",eliserenwick,Elise,Renwick,renwick.elise@gmail.com,Colorado School of Mines,3,dagnystahl,Dagny,Stahl,dagnystahl@gmail.com,ecmele,ecmele,,evanmele@mymail.mines.edu,ChadiIlac,ChadiIlac,,chadsmith@mymail.mines.edu
Best UX/UI,PC Jackal,https://hackcu-vi.devpost.com/submissions/142720-pc-jackal,"A Chrome extension for converting numbers of different bases, inspired by CSCI 2400 at CU Boulder!",02/22/2020 20:12:09,"PC Jackal: Base Conversion Chrome Extension

Made by Paolo Castro, Anne Chen, Anushka Kathait, and John Lee during HackCU VI (February 22 - 23, 2020)

PC Jackal is a Google Chrome extension which allows users to convert between bases up to base 32 (inclusive). The extension provides a popup which can perform conversions on a previously highlighted number or a number entered into its text box. 

Adding the Extension

1) Download and unzip the project on local device.

2) Enter chrome://extensions in the Chrome browser and enable developer mode.

3) Select ""Load unpacked"" and select the project folder.


4) Voila! The extension should appear at the top of the page.


Using the Extension

Highlight a number, click the extension icon on the top right of the page, select the highlighted number's base from the binary, decimal, or hexadecimal button or the custom dropdown menu button. Alternatively, the user can also type the number to be converted directly into the text box and then click the entered number's base for its conversions.





Inspiration

The creators of the PC Jackal extension are freshmen who are currently enrolled in Computer Systems at CU Boulder. Shoutout to CSCI 2400 for inspiring the project lol!

What We Learned Over the Course of the Day

Two of our members learned JavaScript and CSS. All of us learned how to make a Chrome Extension, how to use HTML, and that it is best to enter the HackCU lunch line early because it gets really long really fast. 
",,https://github.com/PCastro128/hackcu2020,,"javascript, html, css","","","","",akathait,akathait,Kathait,anushka.kathait@colorado.edu,University of Colorado at Boulder,3,jule8198,jule8198,,jule8198@colorado.edu,PCastro128,PCastro128,,paolocastro128@gmail.com,anch9523,Anne,Chen,anch9523@colorado.edu
Most Random,PC Jackal,https://hackcu-vi.devpost.com/submissions/142720-pc-jackal,"A Chrome extension for converting numbers of different bases, inspired by CSCI 2400 at CU Boulder!",02/22/2020 20:12:09,"PC Jackal: Base Conversion Chrome Extension

Made by Paolo Castro, Anne Chen, Anushka Kathait, and John Lee during HackCU VI (February 22 - 23, 2020)

PC Jackal is a Google Chrome extension which allows users to convert between bases up to base 32 (inclusive). The extension provides a popup which can perform conversions on a previously highlighted number or a number entered into its text box. 

Adding the Extension

1) Download and unzip the project on local device.

2) Enter chrome://extensions in the Chrome browser and enable developer mode.

3) Select ""Load unpacked"" and select the project folder.


4) Voila! The extension should appear at the top of the page.


Using the Extension

Highlight a number, click the extension icon on the top right of the page, select the highlighted number's base from the binary, decimal, or hexadecimal button or the custom dropdown menu button. Alternatively, the user can also type the number to be converted directly into the text box and then click the entered number's base for its conversions.





Inspiration

The creators of the PC Jackal extension are freshmen who are currently enrolled in Computer Systems at CU Boulder. Shoutout to CSCI 2400 for inspiring the project lol!

What We Learned Over the Course of the Day

Two of our members learned JavaScript and CSS. All of us learned how to make a Chrome Extension, how to use HTML, and that it is best to enter the HackCU lunch line early because it gets really long really fast. 
",,https://github.com/PCastro128/hackcu2020,,"javascript, html, css","","","","",akathait,akathait,Kathait,anushka.kathait@colorado.edu,University of Colorado at Boulder,3,jule8198,jule8198,,jule8198@colorado.edu,PCastro128,PCastro128,,paolocastro128@gmail.com,anch9523,Anne,Chen,anch9523@colorado.edu
All Beginner,PC Jackal,https://hackcu-vi.devpost.com/submissions/142720-pc-jackal,"A Chrome extension for converting numbers of different bases, inspired by CSCI 2400 at CU Boulder!",02/22/2020 20:12:09,"PC Jackal: Base Conversion Chrome Extension

Made by Paolo Castro, Anne Chen, Anushka Kathait, and John Lee during HackCU VI (February 22 - 23, 2020)

PC Jackal is a Google Chrome extension which allows users to convert between bases up to base 32 (inclusive). The extension provides a popup which can perform conversions on a previously highlighted number or a number entered into its text box. 

Adding the Extension

1) Download and unzip the project on local device.

2) Enter chrome://extensions in the Chrome browser and enable developer mode.

3) Select ""Load unpacked"" and select the project folder.


4) Voila! The extension should appear at the top of the page.


Using the Extension

Highlight a number, click the extension icon on the top right of the page, select the highlighted number's base from the binary, decimal, or hexadecimal button or the custom dropdown menu button. Alternatively, the user can also type the number to be converted directly into the text box and then click the entered number's base for its conversions.





Inspiration

The creators of the PC Jackal extension are freshmen who are currently enrolled in Computer Systems at CU Boulder. Shoutout to CSCI 2400 for inspiring the project lol!

What We Learned Over the Course of the Day

Two of our members learned JavaScript and CSS. All of us learned how to make a Chrome Extension, how to use HTML, and that it is best to enter the HackCU lunch line early because it gets really long really fast. 
",,https://github.com/PCastro128/hackcu2020,,"javascript, html, css","","","","",akathait,akathait,Kathait,anushka.kathait@colorado.edu,University of Colorado at Boulder,3,jule8198,jule8198,,jule8198@colorado.edu,PCastro128,PCastro128,,paolocastro128@gmail.com,anch9523,Anne,Chen,anch9523@colorado.edu
All Beginner,Autonotes,https://hackcu-vi.devpost.com/submissions/142796-autonotes,"Ever sit in a lecture and wish that you could write notes even when dozing off? With Autonotes, send in your lecture slides and you will receive a beautiful sheet of notes, with all of the info!",02/23/2020 00:32:35,"Inspiration

As college students, we know that writing notes is a chore in itself. We wanted to make that easier for those who want to learn, but in an abridged manner

What it does

A simple Powerpoint to .txt conversion, parser, and file builder that returns a new and simplified .txt file

How I built it

Challenges I ran into

With little experience in app development, connecting work from multiple people became a chore that we failed to overcome. Knowledge of the IDE we were utilizing did not help, however, we learned a lot about teamwork and implementing new software into the creative process

Accomplishments that I'm proud of

Trying our best!
",,https://github.com/Jessetj/HackCU,,"java, adobe-creative-suite","","","","",Jessetj,Jessetj,Jason,jessetj@rams.colostate.edu,Colorado State University,0
Best Use of Adobe XD,Autonotes,https://hackcu-vi.devpost.com/submissions/142796-autonotes,"Ever sit in a lecture and wish that you could write notes even when dozing off? With Autonotes, send in your lecture slides and you will receive a beautiful sheet of notes, with all of the info!",02/23/2020 00:32:35,"Inspiration

As college students, we know that writing notes is a chore in itself. We wanted to make that easier for those who want to learn, but in an abridged manner

What it does

A simple Powerpoint to .txt conversion, parser, and file builder that returns a new and simplified .txt file

How I built it

Challenges I ran into

With little experience in app development, connecting work from multiple people became a chore that we failed to overcome. Knowledge of the IDE we were utilizing did not help, however, we learned a lot about teamwork and implementing new software into the creative process

Accomplishments that I'm proud of

Trying our best!
",,https://github.com/Jessetj/HackCU,,"java, adobe-creative-suite","","","","",Jessetj,Jessetj,Jason,jessetj@rams.colostate.edu,Colorado State University,0
All Beginner,mazeRunner,https://hackcu-vi.devpost.com/submissions/142809-mazerunner,Randomly generated maze with enemies that try to stop you from completing it.,02/23/2020 01:20:30,"Inspiration

We liked the idea of mazes, and the movie Maze Runner
",,https://github.com/eddyalder/mazeRunner,,python,"","","","",eddyalder,eddyalder,Alder,eddy.alder@hotmail.com,University of Colorado at Boulder,1,brhe4593,Brehn,Heil,brhe4593@colorado.edu
Most Creative Usage of Twitter API,Tweet Visualizer,https://hackcu-vi.devpost.com/submissions/142821-tweet-visualizer,Making drawings out of tweets,02/23/2020 03:21:47,"Inspiration

A while ago, I was fascinated with this website that would create a matrix for a song based on it's lyrics, effectively creating a visual representation of a song. This was what inspired us to create this program, in an attempt to reach the same goal. Creating a visual image to represent a tweet. 

Description

This program takes in a user's twitter handle and shows their 10 most recent tweets for the user to choose from. Once a tweet is chosen, a picture is drawn based on the characters that make up the tweet.

How we built it

We built this using the Turtle Python library and the Twitter API. Each character has a specific thing that it does in order to create the picture.
",,https://github.com/kmsbusch/silver-octo-engine,,"python, tweepy, twitter",University Of Colorado At Boulder,"","","",kmsbusch,Kevin,Busch,kebu5372@colorado.edu,University of Colorado at Boulder,1,tiva1693,tiva1693,,tiva1693@colorado.edu
All Beginner,Tweet Visualizer,https://hackcu-vi.devpost.com/submissions/142821-tweet-visualizer,Making drawings out of tweets,02/23/2020 03:21:47,"Inspiration

A while ago, I was fascinated with this website that would create a matrix for a song based on it's lyrics, effectively creating a visual representation of a song. This was what inspired us to create this program, in an attempt to reach the same goal. Creating a visual image to represent a tweet. 

Description

This program takes in a user's twitter handle and shows their 10 most recent tweets for the user to choose from. Once a tweet is chosen, a picture is drawn based on the characters that make up the tweet.

How we built it

We built this using the Turtle Python library and the Twitter API. Each character has a specific thing that it does in order to create the picture.
",,https://github.com/kmsbusch/silver-octo-engine,,"python, tweepy, twitter",University Of Colorado At Boulder,"","","",kmsbusch,Kevin,Busch,kebu5372@colorado.edu,University of Colorado at Boulder,1,tiva1693,tiva1693,,tiva1693@colorado.edu
Most Random,Computer Crafting,https://hackcu-vi.devpost.com/submissions/142884-computer-crafting,A computer made in Minecraft,02/23/2020 08:08:11,"Inspiration

We wanted to build a computer, and minecraft is a great place to do that. It is a really interesting tool for learning about electronics in a unique way.

What it does

It has a very limited instruction set and can add two numbers, load values from memory, and jump to a hard coded address. This gives us enough tools to compute the fibonacci sequence and display it on a binary display.

How I built it

We placed all the blocks in the world ourselves and used some outside resources for learning about logic gates and optimized circuits.

Challenges I ran into

We had to debug a ton of issues which is not close at all to debugging software.

Accomplishments that I'm proud of

The fact that it actually works is really amazing. We definitely learned a lot in the development of this project.

What I learned

We all learned a lot about computer architecture and actually designing computers in hardware.

What's next for Computer Crafting
",https://youtu.be/-oWnxQVBA24,https://github.com/andrewwellercs/minecraft_computer,,"","University of Colorado, Boulder","","","",andrewwellercs,Andrew,Weller,andrewweller.cs@gmail.com,University of Colorado at Boulder,3,makwayne117,Wayne,Mak,mak.wayne117@gmail.com,Justin-Astalos,Justin,A.,justiastal@gmail.com,teoschollmaier,Teo,Schollmaier,teo.schollmaier@gmail.com
"",Domain.com best entry for new domain ever. Thanks,https://hackcu-vi.devpost.com/submissions/142885-domain-com-best-entry-for-new-domain-ever-thanks,This domain is the best domain registered at CUHACK 2020. Duh,02/23/2020 08:12:57,"I walked into the jennie smoly caruthers biotechnology building this morning around 8:45AM yesterday morning, feeling a little hungover, a bit tired, but mostly excited for whatever delicious breakfast snacks (and coffee) awaited me. After receiving my lanyard and sloppily sharpie-ing in my name upon the lanyard tag, I indulged indeed with some sloppy burrito and oh-so-delicious coffee. Heaven, and not even 9AM. I then wandered about, perusing, mostly at a distance, at the many sponsor-booths and other's wandering about. As I settled near the back row of A108, a wonderful room, though not one that is especially conducive to collaborative engineering, considering it's layout. Anywho, despite the room's shortcomings, my dear friends and colleagues eventually wandered in to post up where I'd been relaxing with my coffee, subduing that stout-month-induced hangover sip by sip. As dear friends settled in, I noticed one of them had a little white card proclaiming 1 FREE DOMAIN from domain.com, courtesy the code ""WINTERCODING."" I felt enamored, elated, and likely other positively exciting words beginning with the letter ""E"". So I took it upon myself to consider, very carefully, for at least 20-30 minutes, the best possible domain I could procure with the winter wonder code. 

So I give you - 

haxr.fun

Because - 

Hacks ARE fun. This was my first ever hackathon. And it was great fun. 

Pete
",,,,"wintercode, love",CU Boulder; CSU,haxr.fun,"","",peterpascente,Pete,Pascente,peter.pascente@colorado.edu,University of Colorado at Boulder,0
Sustainability,Material Matters,https://hackcu-vi.devpost.com/submissions/142888-material-matters,Technology that informs environmentally conscious choice,02/23/2020 08:27:22,"Please see the following pdf document prepared by our team for the Materials Matter sustainability initiative. 

https://drive.google.com/file/d/16g91IARxMN6bpg0_AA7tLcpJZpq6_M0H/view?usp=sharing

Thanks!

p.s. for your enjoyment - a fun boat quiz:

https://www.google.com/amp/s/quizzes.clickhole.com/do-you-know-what-boats-are-1825124656/amp
",,https://github.com/pingaspete/impact_index,,"javascript, firebase, love, caffeine, chrome, adobe-illustrator, github, zenhub, slack",CU Boulder; CSU,"","","",peterpascente,Pete,Pascente,peter.pascente@colorado.edu,University of Colorado at Boulder,1,anly6571,anly6571,,anly6571@colorado.edu
Dish Network Challenge,Party Room,https://hackcu-vi.devpost.com/submissions/142905-party-room,Its a music recommendation system for social gatherings where people have a varied music taste.,02/23/2020 08:50:37,"Inspiration

Have you ever been in a social situation where you were expected to play the music. People have all type of expectations for what music should be played in what situation and there are times when they will judge you for the music you play. In those cases, rather than having a escape goat, use Party Room. Social anxiety is a crippling social disorder that is the 2nd most common mental illness in the US according to the Anxiety and Depression Association of America.

This app will help you relieve the social anxiety that comes from having to make decisions. I found a great paper that analyzes the market for such a product here: https://drive.google.com/file/d/1hB8wJljq18PJSeOY3CkCRXyOEzDE62O6/view?usp=sharing

What it does

Party Room is a system that will recommend and play music for you based on the people in the virtual room. All you have to do is log in with your Spotify account, and Party Room takes care of the rest. It will go and map all of the songs you and your virtual roommates like onto a mathematical topological space and uses a deep learning and other data science techniques to recommend songs that are new that everyone would like.

Also, is there a particular vibe you are going for? We also go you covered. You can create a dance room or a chill room. The rooms can be tuned to a vibe.

A most special aspect of Party Room is how easy it is to use.

How I built it

Spotify has people's music history and some attributes about the song. Based on people's listening history and attributes about the songs, I used Neural Nets and other AI techniques to give an accurate recommendation for the songs that people would like listening to. There were complex topics from advanced math classes like randomized algorithms used to deal with the size of the data and accurately same the most meaningful points.

Challenges I ran into

I had never worked with the Spotify API and it took me more than half the Hackathon time to figure out how that worked. As is in most hackathons, I spent more than 3 hours working on a bug that was just a simple caching mistake. I had never ever worked with music data before either. I also am not a ""data scientist"" in any way so this project was specially difficult. This is a great learning experience in general.

Accomplishments that I'm proud of

I think I am proud of the fact that I even go this project to work in the first place. I learned about new topological space mapping techniques, and new data science techniques while figuring out how to work with Spotify.

What's next for Party Room

I think that next steps include a more visually pleasing UI and I did not have time to work on that. Afterwards, I think that there are improvements that I can more on performance. I also need to think about collecting data on how often this is being used.
",,https://github.com/SuyogSoti/PartyRoom,,"python, flask, spotify",Boulder,"","","",suso4455,Suyog,Soti,suso4455@colorado.edu,University of Colorado at Boulder,0
MLH: Best use of MongoDB Atlas,Party Room,https://hackcu-vi.devpost.com/submissions/142905-party-room,Its a music recommendation system for social gatherings where people have a varied music taste.,02/23/2020 08:50:37,"Inspiration

Have you ever been in a social situation where you were expected to play the music. People have all type of expectations for what music should be played in what situation and there are times when they will judge you for the music you play. In those cases, rather than having a escape goat, use Party Room. Social anxiety is a crippling social disorder that is the 2nd most common mental illness in the US according to the Anxiety and Depression Association of America.

This app will help you relieve the social anxiety that comes from having to make decisions. I found a great paper that analyzes the market for such a product here: https://drive.google.com/file/d/1hB8wJljq18PJSeOY3CkCRXyOEzDE62O6/view?usp=sharing

What it does

Party Room is a system that will recommend and play music for you based on the people in the virtual room. All you have to do is log in with your Spotify account, and Party Room takes care of the rest. It will go and map all of the songs you and your virtual roommates like onto a mathematical topological space and uses a deep learning and other data science techniques to recommend songs that are new that everyone would like.

Also, is there a particular vibe you are going for? We also go you covered. You can create a dance room or a chill room. The rooms can be tuned to a vibe.

A most special aspect of Party Room is how easy it is to use.

How I built it

Spotify has people's music history and some attributes about the song. Based on people's listening history and attributes about the songs, I used Neural Nets and other AI techniques to give an accurate recommendation for the songs that people would like listening to. There were complex topics from advanced math classes like randomized algorithms used to deal with the size of the data and accurately same the most meaningful points.

Challenges I ran into

I had never worked with the Spotify API and it took me more than half the Hackathon time to figure out how that worked. As is in most hackathons, I spent more than 3 hours working on a bug that was just a simple caching mistake. I had never ever worked with music data before either. I also am not a ""data scientist"" in any way so this project was specially difficult. This is a great learning experience in general.

Accomplishments that I'm proud of

I think I am proud of the fact that I even go this project to work in the first place. I learned about new topological space mapping techniques, and new data science techniques while figuring out how to work with Spotify.

What's next for Party Room

I think that next steps include a more visually pleasing UI and I did not have time to work on that. Afterwards, I think that there are improvements that I can more on performance. I also need to think about collecting data on how often this is being used.
",,https://github.com/SuyogSoti/PartyRoom,,"python, flask, spotify",Boulder,"","","",suso4455,Suyog,Soti,suso4455@colorado.edu,University of Colorado at Boulder,0
Best Use of TapWithUS SDK,Hand of God,https://hackcu-vi.devpost.com/submissions/142980-hand-of-god,Use the Tap Strap to control lights and music with hand gestures. An accessible alternative to voice-based smart home controllers.,02/23/2020 10:05:49,"Inspiration

We were intrigued by the Tap Strap and saw a lot of potential for it to improve people's lives. We wanted to make an intuitive gesture-based option to control smart devices for those who are unable to use voice commands.

What it does

Users can point at lights, and use gestures while wearing a Tap Strap to turn them on and off. They can also control their Spotify stream with gestures. It is an alternative control system to voice-based smart home control. Our program can be extended to add gesture controls to any home automation device, such as smart speakers, smart lights, smart thermostats, or even smart refrigerators.

How we built it

The frontend application is an Android application that uses the Tap SDK to create an app that can interface with a Tap Strap. The app detects the position of the hand, and any gestures performed, and sends them to a backend Python Flask server running on a Raspberry Pi. The Raspberry Pi sends requests to Wifi boards to toggle the LEDs attached to them on and off, much line a smart home hub would. The Raspberry Pi also sends requests to the Spotify API based on the gestures the user makes.

Challenges we ran into

The primary challenge we had was figuring out what data to use for detecting the position of the hand. We also ran into problems with determining how some of the values we were using were being measured, particularly whether they had to do with position, orientation, or both.

Accomplishments that we're proud of

It was really satisfying to finally see our project come together and work. It felt awesome to be able to control lights with the flick of a finger and change the song with the swipe of a hand.

What we learned

We learned to use the Tap SDK, and how to develop an Android app. We also learned to integrate with the Spotify API, and communicate among multiple individual devices.

What's next for Hand of God

Adding more gestures to allow for more actions for a device. For example, changing the color of the lights rather than just turning them on and off. 

The Hand of God has potential to integrate with smart home devices such as Google Home or Amazon Alexa. With the calibration feature in our app, it is easy for users to use the Hand of God with any set of devices.
",https://youtu.be/mgfRLQeBH1U,https://github.com/The-Hand-of-God,,"tap-android-sdk, flask, python, c#, java, android, raspberry-pi, spotify, arduino",Colorado School of Mines,"","","",sColin16,Colin,Siles,colinsiles@mymail.mines.edu,Colorado School of Mines,2,danbeneventano,Dan,Beneventano,danbeneventano@protonmail.com,Mx2002,Mohammed,Alnasser,w-r-t-2002@hotmail.com
Social Impact,Hand of God,https://hackcu-vi.devpost.com/submissions/142980-hand-of-god,Use the Tap Strap to control lights and music with hand gestures. An accessible alternative to voice-based smart home controllers.,02/23/2020 10:05:49,"Inspiration

We were intrigued by the Tap Strap and saw a lot of potential for it to improve people's lives. We wanted to make an intuitive gesture-based option to control smart devices for those who are unable to use voice commands.

What it does

Users can point at lights, and use gestures while wearing a Tap Strap to turn them on and off. They can also control their Spotify stream with gestures. It is an alternative control system to voice-based smart home control. Our program can be extended to add gesture controls to any home automation device, such as smart speakers, smart lights, smart thermostats, or even smart refrigerators.

How we built it

The frontend application is an Android application that uses the Tap SDK to create an app that can interface with a Tap Strap. The app detects the position of the hand, and any gestures performed, and sends them to a backend Python Flask server running on a Raspberry Pi. The Raspberry Pi sends requests to Wifi boards to toggle the LEDs attached to them on and off, much line a smart home hub would. The Raspberry Pi also sends requests to the Spotify API based on the gestures the user makes.

Challenges we ran into

The primary challenge we had was figuring out what data to use for detecting the position of the hand. We also ran into problems with determining how some of the values we were using were being measured, particularly whether they had to do with position, orientation, or both.

Accomplishments that we're proud of

It was really satisfying to finally see our project come together and work. It felt awesome to be able to control lights with the flick of a finger and change the song with the swipe of a hand.

What we learned

We learned to use the Tap SDK, and how to develop an Android app. We also learned to integrate with the Spotify API, and communicate among multiple individual devices.

What's next for Hand of God

Adding more gestures to allow for more actions for a device. For example, changing the color of the lights rather than just turning them on and off. 

The Hand of God has potential to integrate with smart home devices such as Google Home or Amazon Alexa. With the calibration feature in our app, it is easy for users to use the Hand of God with any set of devices.
",https://youtu.be/mgfRLQeBH1U,https://github.com/The-Hand-of-God,,"tap-android-sdk, flask, python, c#, java, android, raspberry-pi, spotify, arduino",Colorado School of Mines,"","","",sColin16,Colin,Siles,colinsiles@mymail.mines.edu,Colorado School of Mines,2,danbeneventano,Dan,Beneventano,danbeneventano@protonmail.com,Mx2002,Mohammed,Alnasser,w-r-t-2002@hotmail.com
Best Use of TapWithUS SDK,TapVRap,https://hackcu-vi.devpost.com/submissions/143079-tapvrap,TapVRap brings wireless gaming to a whole new level. Experience a revolutionary gesture capture control using the Tap Strap virtual keyboard. ,02/23/2020 11:20:51,"Inspiration

We where inspired by the Tap Strap Virtual Keyboard and their proposed challenge to creatively use their hardware. Our initial goals was to challenge ourselves all while exploring new things and have fun testing something we have never used before.

What it does

Currently the our project takes the raw data from finger accelerators, and then parses it into graphs. Then after searching through those graphs we are able to make our own custom hand gestures to use as controls in a game environment.

How we built it

We took the tap strap and using the provided windows sdk, we retrieved the raw data from the tap strap. With the data in hand we graphed the output of the sensors available to see how the data changes with movement. Using the patterns we saw on the graphs, we created our own custom gestures to use.

Challenges we ran into

One of the many challenges we ran it to was trying to figure out a new programming environment called Visual Studio. Since none of the SDKs worked on Linux, we had to quickly come up with a solution on a windows machine. None of us had ever used Visual Studio before and it was a new thing the we all had to figure out. Another challenge was that since two of us where beginners we struggled as a team to figuring out what to each could contribute and how we could equally share the experience.

Accomplishments that we're proud of

We are proud that we got personalized hand gestures that map to certain buttons on a keyboard to play a game through the Tap Strap Virtual Keyboard. Also, we where able to figure out how to navigate through a new interface and a new programming language all while making it work the way we wanted.

What we learned

We learned how to improve the efficiency of data parsing and how to properly interpret such data. We also learned how to briefly use Visual Studio along with how to better communicate with each other as we got sleep deprived and frustrated with our project.

What's next for TapVRap

We want to implement a second hand with more hand gestures. We also want to make it VR compatible since we were not able to implement such feature at this time. We also want to get the gyroscope working in order to have joystick like controls.
",,https://github.com/jnunez101/TapVRap,,"c#, jupytr, python",Colorado School of Mines,"",Oculus Rift,"",erojorocha,erojorocha,Rojo,erojorocha@mymail.mines.edu,Colorado School of Mines,3,jnunez101,Jesus,Nunez,jnunez@mines.edu,lloe,lloe,,lauren.a.l173@gmail.com,r3a4,r3a4,,racoronanunez@gmail.com
Social Impact,TheGenerousFoundation,https://hackcu-vi.devpost.com/submissions/143086-thegenerousfoundation,A New Way to Provide Housing and Other Resources for the Homeless,02/23/2020 11:27:24,"Inspiration

We were inspired by the social impact challenge and we sought to fix a problem that affects millions of Americans and people around the world. We wanted to increase the accessibility of information to homeless populations especially in large cities.

What it does

Our web application is made to be used on a kiosk, specifically ones in larger cities. For example, in New York City, there are already a variety of kiosks used for directions. The way our web application works is that the user would select whether they are looking for food or shelter to which the kiosk will calculate the closest food banks or homeless shelters and provide directions to the users. Homeless shelters and food banks will also have the option to update their server to show updated availability and times. When designing the web application, we focused on creating simple yet important functions that would help both those seeking assistance and the shelters and food banks offering their services. We also focused on creating a simplistic UI to increase the accessibility of the web application, we aimed on allowing the user to never have to type anything into the kiosk but still being able to use all of our functions. Finally, we decided on creating designs with universal symbols to increase the accessibility to people who do not speak English (or the other three languages we had chosen to translate it into).

How We built it

The front-end of our web application was designed using Figma and Sketch to provide wireframes that allowed us to analyse which functions were most important to us. The front-end was built using HTML/CSS and Javascript to provide a simple yet sleek interface. Some tools used to enhance the front-end was Google Maps Embed API as well as using JSON databases to host the information for the shelters and food banks. The website was hosted on Google Cloud, using a domain from domain.com. To host our website, we used node.js and express.js to support the backend of the web application.

Challenges We ran into

A challenge we faced was creating the website and hosting it. For most of us, this was our first hackathon and we didn't have a lot of prior experience building a website in only 24 hours. Creating this web application was full of challenges but eventually, we were able to make it fully functional. Another challenge was the backend, none of us had any experience in creating a backend server so we used Google Cloud and node.js tutorial to create the backend. At first, it was difficult connecting the different components but we were soon able to host a fully functional app.

Accomplishments that We're proud of

An accomplishment that we're proud of was the development of the website and creating a solution to a pressing issue.

What We learned

We learned how to use node.js, Google Cloud web services, and gained more insight into how to create a fully functional website with HTML/CSS. 

What's next for TheGenerousFoundation

The next step for TheGenerousFoundation would be to create a reservation based system which would allow users to enter their information and have their picture taken in order to reserve their spot at a shelter. We would also like to look into creating a mobile app version, allowing those without access to a kiosk to still be able to check the directory based on their location.
",,http://thegenerousfoundation.tech,,"node.js, javascript, google-cloud, google-maps, html5, css3, express.js, figma, sketch","University of Waterloo, University of Colorado Boulder",thegenerousfoundation.tech,"",Domain.com,juliaturner073,Julia,Turner,juliaturner073@gmail.com,"University of Waterloo, University of Colorado at Boulder",3,Chritopher-Gonzalez,Chritopher-Gonzalez,Gonzalez-Millan,chgo7806@colorado.edu,DefinitleyNotChucky,DefinitleyNotChucky,,chmo5422@colorado.edu,anva1453,Andres,Varela Robles,anva1453@colorado.edu
MLH: Best Use of Google Cloud,TheGenerousFoundation,https://hackcu-vi.devpost.com/submissions/143086-thegenerousfoundation,A New Way to Provide Housing and Other Resources for the Homeless,02/23/2020 11:27:24,"Inspiration

We were inspired by the social impact challenge and we sought to fix a problem that affects millions of Americans and people around the world. We wanted to increase the accessibility of information to homeless populations especially in large cities.

What it does

Our web application is made to be used on a kiosk, specifically ones in larger cities. For example, in New York City, there are already a variety of kiosks used for directions. The way our web application works is that the user would select whether they are looking for food or shelter to which the kiosk will calculate the closest food banks or homeless shelters and provide directions to the users. Homeless shelters and food banks will also have the option to update their server to show updated availability and times. When designing the web application, we focused on creating simple yet important functions that would help both those seeking assistance and the shelters and food banks offering their services. We also focused on creating a simplistic UI to increase the accessibility of the web application, we aimed on allowing the user to never have to type anything into the kiosk but still being able to use all of our functions. Finally, we decided on creating designs with universal symbols to increase the accessibility to people who do not speak English (or the other three languages we had chosen to translate it into).

How We built it

The front-end of our web application was designed using Figma and Sketch to provide wireframes that allowed us to analyse which functions were most important to us. The front-end was built using HTML/CSS and Javascript to provide a simple yet sleek interface. Some tools used to enhance the front-end was Google Maps Embed API as well as using JSON databases to host the information for the shelters and food banks. The website was hosted on Google Cloud, using a domain from domain.com. To host our website, we used node.js and express.js to support the backend of the web application.

Challenges We ran into

A challenge we faced was creating the website and hosting it. For most of us, this was our first hackathon and we didn't have a lot of prior experience building a website in only 24 hours. Creating this web application was full of challenges but eventually, we were able to make it fully functional. Another challenge was the backend, none of us had any experience in creating a backend server so we used Google Cloud and node.js tutorial to create the backend. At first, it was difficult connecting the different components but we were soon able to host a fully functional app.

Accomplishments that We're proud of

An accomplishment that we're proud of was the development of the website and creating a solution to a pressing issue.

What We learned

We learned how to use node.js, Google Cloud web services, and gained more insight into how to create a fully functional website with HTML/CSS. 

What's next for TheGenerousFoundation

The next step for TheGenerousFoundation would be to create a reservation based system which would allow users to enter their information and have their picture taken in order to reserve their spot at a shelter. We would also like to look into creating a mobile app version, allowing those without access to a kiosk to still be able to check the directory based on their location.
",,http://thegenerousfoundation.tech,,"node.js, javascript, google-cloud, google-maps, html5, css3, express.js, figma, sketch","University of Waterloo, University of Colorado Boulder",thegenerousfoundation.tech,"",Domain.com,juliaturner073,Julia,Turner,juliaturner073@gmail.com,"University of Waterloo, University of Colorado at Boulder",3,Chritopher-Gonzalez,Chritopher-Gonzalez,Gonzalez-Millan,chgo7806@colorado.edu,DefinitleyNotChucky,DefinitleyNotChucky,,chmo5422@colorado.edu,anva1453,Andres,Varela Robles,anva1453@colorado.edu
MLH: Best Domain Registered with Domain.com,TheGenerousFoundation,https://hackcu-vi.devpost.com/submissions/143086-thegenerousfoundation,A New Way to Provide Housing and Other Resources for the Homeless,02/23/2020 11:27:24,"Inspiration

We were inspired by the social impact challenge and we sought to fix a problem that affects millions of Americans and people around the world. We wanted to increase the accessibility of information to homeless populations especially in large cities.

What it does

Our web application is made to be used on a kiosk, specifically ones in larger cities. For example, in New York City, there are already a variety of kiosks used for directions. The way our web application works is that the user would select whether they are looking for food or shelter to which the kiosk will calculate the closest food banks or homeless shelters and provide directions to the users. Homeless shelters and food banks will also have the option to update their server to show updated availability and times. When designing the web application, we focused on creating simple yet important functions that would help both those seeking assistance and the shelters and food banks offering their services. We also focused on creating a simplistic UI to increase the accessibility of the web application, we aimed on allowing the user to never have to type anything into the kiosk but still being able to use all of our functions. Finally, we decided on creating designs with universal symbols to increase the accessibility to people who do not speak English (or the other three languages we had chosen to translate it into).

How We built it

The front-end of our web application was designed using Figma and Sketch to provide wireframes that allowed us to analyse which functions were most important to us. The front-end was built using HTML/CSS and Javascript to provide a simple yet sleek interface. Some tools used to enhance the front-end was Google Maps Embed API as well as using JSON databases to host the information for the shelters and food banks. The website was hosted on Google Cloud, using a domain from domain.com. To host our website, we used node.js and express.js to support the backend of the web application.

Challenges We ran into

A challenge we faced was creating the website and hosting it. For most of us, this was our first hackathon and we didn't have a lot of prior experience building a website in only 24 hours. Creating this web application was full of challenges but eventually, we were able to make it fully functional. Another challenge was the backend, none of us had any experience in creating a backend server so we used Google Cloud and node.js tutorial to create the backend. At first, it was difficult connecting the different components but we were soon able to host a fully functional app.

Accomplishments that We're proud of

An accomplishment that we're proud of was the development of the website and creating a solution to a pressing issue.

What We learned

We learned how to use node.js, Google Cloud web services, and gained more insight into how to create a fully functional website with HTML/CSS. 

What's next for TheGenerousFoundation

The next step for TheGenerousFoundation would be to create a reservation based system which would allow users to enter their information and have their picture taken in order to reserve their spot at a shelter. We would also like to look into creating a mobile app version, allowing those without access to a kiosk to still be able to check the directory based on their location.
",,http://thegenerousfoundation.tech,,"node.js, javascript, google-cloud, google-maps, html5, css3, express.js, figma, sketch","University of Waterloo, University of Colorado Boulder",thegenerousfoundation.tech,"",Domain.com,juliaturner073,Julia,Turner,juliaturner073@gmail.com,"University of Waterloo, University of Colorado at Boulder",3,Chritopher-Gonzalez,Chritopher-Gonzalez,Gonzalez-Millan,chgo7806@colorado.edu,DefinitleyNotChucky,DefinitleyNotChucky,,chmo5422@colorado.edu,anva1453,Andres,Varela Robles,anva1453@colorado.edu
Dish Network Challenge,Visualize Attacks,https://hackcu-vi.devpost.com/submissions/143093-visualize-attacks,"Data visualization of common HTTP, SSH, and Telnet attack vectors",02/23/2020 11:30:11,"Inspiration

The mirai botnet hits every single external ip (besides GE and US-DOD) on average once every 8 seconds.

Thats a lot. Visualizing and creating awareness to the nature of botnets and network attacks/vulnerabilities becomes more important with zero days and infosec leaks looming seeemingly more and more. 

What it does

Displays server logs in a managable fashion from logs collected from server requests/connections/rpc calls/shell connections 

How I built it

With python and GraphQL server running an ASGI web app hosted on GCE.

Challenges I ran into

Getting deployment working in GCE

Accomplishments that I'm proud of

It has a fully fledged SQL -> ORM -> GraphQL API backend that just flies. 

What I learned

GraphQL query notation

What's next for Visualize Attacks

Custom data visualization from user defined queries rather than static display.
",,http://visualizeyour.tech/,,"python, vue, gcp, sqlite, starlette, graphql",Metropolitan State University of Denver,visualizeyour.tech,"","",LSmith-Zenoscave,Luke,Smith,lsmith@zenoscave.com,Metropolitan State University of Denver,0
Social Impact,Visualize Attacks,https://hackcu-vi.devpost.com/submissions/143093-visualize-attacks,"Data visualization of common HTTP, SSH, and Telnet attack vectors",02/23/2020 11:30:11,"Inspiration

The mirai botnet hits every single external ip (besides GE and US-DOD) on average once every 8 seconds.

Thats a lot. Visualizing and creating awareness to the nature of botnets and network attacks/vulnerabilities becomes more important with zero days and infosec leaks looming seeemingly more and more. 

What it does

Displays server logs in a managable fashion from logs collected from server requests/connections/rpc calls/shell connections 

How I built it

With python and GraphQL server running an ASGI web app hosted on GCE.

Challenges I ran into

Getting deployment working in GCE

Accomplishments that I'm proud of

It has a fully fledged SQL -> ORM -> GraphQL API backend that just flies. 

What I learned

GraphQL query notation

What's next for Visualize Attacks

Custom data visualization from user defined queries rather than static display.
",,http://visualizeyour.tech/,,"python, vue, gcp, sqlite, starlette, graphql",Metropolitan State University of Denver,visualizeyour.tech,"","",LSmith-Zenoscave,Luke,Smith,lsmith@zenoscave.com,Metropolitan State University of Denver,0
MLH: Best Use of Google Cloud,Visualize Attacks,https://hackcu-vi.devpost.com/submissions/143093-visualize-attacks,"Data visualization of common HTTP, SSH, and Telnet attack vectors",02/23/2020 11:30:11,"Inspiration

The mirai botnet hits every single external ip (besides GE and US-DOD) on average once every 8 seconds.

Thats a lot. Visualizing and creating awareness to the nature of botnets and network attacks/vulnerabilities becomes more important with zero days and infosec leaks looming seeemingly more and more. 

What it does

Displays server logs in a managable fashion from logs collected from server requests/connections/rpc calls/shell connections 

How I built it

With python and GraphQL server running an ASGI web app hosted on GCE.

Challenges I ran into

Getting deployment working in GCE

Accomplishments that I'm proud of

It has a fully fledged SQL -> ORM -> GraphQL API backend that just flies. 

What I learned

GraphQL query notation

What's next for Visualize Attacks

Custom data visualization from user defined queries rather than static display.
",,http://visualizeyour.tech/,,"python, vue, gcp, sqlite, starlette, graphql",Metropolitan State University of Denver,visualizeyour.tech,"","",LSmith-Zenoscave,Luke,Smith,lsmith@zenoscave.com,Metropolitan State University of Denver,0
MLH: Best Domain Registered with Domain.com,Visualize Attacks,https://hackcu-vi.devpost.com/submissions/143093-visualize-attacks,"Data visualization of common HTTP, SSH, and Telnet attack vectors",02/23/2020 11:30:11,"Inspiration

The mirai botnet hits every single external ip (besides GE and US-DOD) on average once every 8 seconds.

Thats a lot. Visualizing and creating awareness to the nature of botnets and network attacks/vulnerabilities becomes more important with zero days and infosec leaks looming seeemingly more and more. 

What it does

Displays server logs in a managable fashion from logs collected from server requests/connections/rpc calls/shell connections 

How I built it

With python and GraphQL server running an ASGI web app hosted on GCE.

Challenges I ran into

Getting deployment working in GCE

Accomplishments that I'm proud of

It has a fully fledged SQL -> ORM -> GraphQL API backend that just flies. 

What I learned

GraphQL query notation

What's next for Visualize Attacks

Custom data visualization from user defined queries rather than static display.
",,http://visualizeyour.tech/,,"python, vue, gcp, sqlite, starlette, graphql",Metropolitan State University of Denver,visualizeyour.tech,"","",LSmith-Zenoscave,Luke,Smith,lsmith@zenoscave.com,Metropolitan State University of Denver,0
Most Random,Blockchain-of-Custody,https://hackcu-vi.devpost.com/submissions/143104-blockchain-of-custody,"At the intersection of exciting emerging technology and painstaking, detail-oriented work is an opportunity to innovate; the chain of custody on the blockchain is a unique step into the future.",02/23/2020 11:43:24,"Fresh in my mind were the concepts I collided in this project when I decided this use case is completely viable. 

The chain of custody can be an absolute hassle for a digital forensics investigator. Keep highly detailed notes on the whereabouts of any evidence that makes a difference in court. Slip up in the slightest and the defense will guarantee that your exhibits are thrown out of court. Invalidating good evidence cripples out justice system. Therefore, why not take advantage of the futuristic technologies that we as technologists have access to today? The immutable nature of the blockchain enables investigators to circumvent the possibility of their un-tampered evidence being misrepresented. 

This Idea came to me almost primarily as a wonderful opportunity for word play, but also as an interesting way to innovate while taking advantage of disruptive technology. I did all my building in the web-based solidity IDE Remix, which is what's used by my professor during lecture for real-time demos. 

At the beginning of the hackathon, I was very enthusiastic to build and develop with the unique hardware that companies brought. Use cases and realistic applicability were out of the question, I was just curious. Soon, my team disillusioned me as I started understanding the barriers that I could not personally overcome to start developing in a meaningful way. 

We chose a new project, and frankly I was even more lost with the technologies and tools they were employing. I decided to go solo half way through the event and regroup to design and implement a smart contract for the chain of custody. Though I do understand them, this is indeed my first time developing my own contract from scratch.

As I worked, what I learned is that the intricacy of smart contracts lies in creating security only from the tools you're given. Moreover, having never interacted with an authentic chain of custody and instead did research to derive processes from individual pieces of information. Finally, deriving real security problems and solving them all on my own continues to serve as the largest barrier between me and the most completed version of this smart contract. 

What I learned more resoundingly than anything else in this, my second hackathon, is that being dynamic and adaptable from ideation to execution makes all the difference. I thought I knew my project three times before hammering this out. 
",,https://github.com/wstnmssr/Blockchain-of-Custody,,"solidity, ethereum, remix",Colorado State University,"","","",wstnmssr,wstnmssr,Musser,wstnmssr@gmail.com,Colorado State University,0
MLH: Best use of MongoDB Atlas,HateBad,https://hackcu-vi.devpost.com/submissions/143107-hatebad,Shred the hate. Spread the love.,02/23/2020 11:43:57,"Inspiration

While social media can be a good thing, its negative impact cannot be understated. This creates an ideal environment for predators of all kinds to spread their negativity internationally. Our goal with this project was to create an escape from this toxicity and provide a platform specifically designed to spread positivity while also having some fun.

What it does

The HateBad initiative accomplishes three main tasks. One, we use the power of Deep Learning to create a model able to categorize tweets as positive, neutral, or negative/hateful. We then take this output and display a collection of positive tweets in our website. The website also allows the user to print out a random negative/hateful tweet, which will subsequently be shredded, symbolizing the breaking down of this harmful mindset this project aims to accomplish.

How we built it

After finding two data sets containing presorted hate speech and presorted positive/negative tweets, we parsed the raw data into a MongoDB for easy and quick access by our machine learning models. After sanitizing input, we used TensorFlow to create and train two separate models, one for each data set, to categorize a tweet as hateful/negative or positive. We then exported the trained models for use in production. Using the Twitter API, we created a tweet stream to funnel new tweets to the trained models, which would in turn give a pandas dataframe consisting of the tweet and its categorization. The program would then go through the dataframe and like tweets that were categorized as hateful/negative while retweeting the ones that were considered positive tweets under our twitter account ""@hate_no_good"". On the website back end, a js script would hook into the twitter account and display any retweeted tweets on the website. There is also a negativity-mode page in which you are able to print one of the liked or hateful/negative posts which would then get printed to a printer configuration that immediately feeds the paper into a shredder, providing unreasonable amounts of positive thoughts and satisfaction. There is also a feed for cute animals in case of an emergency.

Challenges we ran into

The Model
The hardest part of the project was defiantly getting two neural networks up and running. We initially tried to use the TensorFlow estimator toolkit. After training one of our data sets, we were able to get a fairly good categorization rate, but we were unable to pull useful information from the generator that the model output. For some reason the generator wouldn't act as a normal python generator and error out any time we tried to iterate over it. We solved this by scrapping the estimator model and electing for a traditional TensorFlow model, which after some painful data normalization, worked like a charm.

The Website
Unfortunately, we were unable to host our website with a domain on domain.com so for now it is a local site on our computers. We did not have the time nor resources to figure out how to host the site in the allotted 24hrs.

Accomplishments that we're proud of

The biggest accomplishment has to be the fact that this project does actually work. Going into this, none of us had messed with Deep Learning AI so we figured that the probability of us actually creating a usable product was very small. After a very long and painful night, however, we finally managed to get a reasonable categorization schema that exceeded our expectations.

What we learned

While it was interesting to learn how to work with this level of AI, we learned that it really is not for us. While being a cool branch of CS, machine learning with neural networks is not the most exhilarating activity out there.

On the plus side we did get experience with a powerful toolkit, TensorFlow, and a convenient and easy to use database in MongoDB.

What's next for HateBad

While reasonable, the model for categorizing tweets is far from perfect. In the future we intend to optimize the model so as to minimize the false positive and categorization that occurs. We also would like to make the site public to the internet for the public to enjoy and use.
",,https://github.com/neel010427/Hate-Bad,,"python, tensorflow, tweepy, mongodb, pandas, numpy",University of Colorado Boulder,"","",MongoDB,zhouzhouthezhou,Kyle,Zhou,kylezhou2222@gmail.com,University of Colorado at Boulder,2,neel010427,Neel,Katuri,neka7176@colorado.edu,adamhoerger,Adam,Hoerger,adam.hoerger@gmail.com
Most Creative Usage of Twitter API,HateBad,https://hackcu-vi.devpost.com/submissions/143107-hatebad,Shred the hate. Spread the love.,02/23/2020 11:43:57,"Inspiration

While social media can be a good thing, its negative impact cannot be understated. This creates an ideal environment for predators of all kinds to spread their negativity internationally. Our goal with this project was to create an escape from this toxicity and provide a platform specifically designed to spread positivity while also having some fun.

What it does

The HateBad initiative accomplishes three main tasks. One, we use the power of Deep Learning to create a model able to categorize tweets as positive, neutral, or negative/hateful. We then take this output and display a collection of positive tweets in our website. The website also allows the user to print out a random negative/hateful tweet, which will subsequently be shredded, symbolizing the breaking down of this harmful mindset this project aims to accomplish.

How we built it

After finding two data sets containing presorted hate speech and presorted positive/negative tweets, we parsed the raw data into a MongoDB for easy and quick access by our machine learning models. After sanitizing input, we used TensorFlow to create and train two separate models, one for each data set, to categorize a tweet as hateful/negative or positive. We then exported the trained models for use in production. Using the Twitter API, we created a tweet stream to funnel new tweets to the trained models, which would in turn give a pandas dataframe consisting of the tweet and its categorization. The program would then go through the dataframe and like tweets that were categorized as hateful/negative while retweeting the ones that were considered positive tweets under our twitter account ""@hate_no_good"". On the website back end, a js script would hook into the twitter account and display any retweeted tweets on the website. There is also a negativity-mode page in which you are able to print one of the liked or hateful/negative posts which would then get printed to a printer configuration that immediately feeds the paper into a shredder, providing unreasonable amounts of positive thoughts and satisfaction. There is also a feed for cute animals in case of an emergency.

Challenges we ran into

The Model
The hardest part of the project was defiantly getting two neural networks up and running. We initially tried to use the TensorFlow estimator toolkit. After training one of our data sets, we were able to get a fairly good categorization rate, but we were unable to pull useful information from the generator that the model output. For some reason the generator wouldn't act as a normal python generator and error out any time we tried to iterate over it. We solved this by scrapping the estimator model and electing for a traditional TensorFlow model, which after some painful data normalization, worked like a charm.

The Website
Unfortunately, we were unable to host our website with a domain on domain.com so for now it is a local site on our computers. We did not have the time nor resources to figure out how to host the site in the allotted 24hrs.

Accomplishments that we're proud of

The biggest accomplishment has to be the fact that this project does actually work. Going into this, none of us had messed with Deep Learning AI so we figured that the probability of us actually creating a usable product was very small. After a very long and painful night, however, we finally managed to get a reasonable categorization schema that exceeded our expectations.

What we learned

While it was interesting to learn how to work with this level of AI, we learned that it really is not for us. While being a cool branch of CS, machine learning with neural networks is not the most exhilarating activity out there.

On the plus side we did get experience with a powerful toolkit, TensorFlow, and a convenient and easy to use database in MongoDB.

What's next for HateBad

While reasonable, the model for categorizing tweets is far from perfect. In the future we intend to optimize the model so as to minimize the false positive and categorization that occurs. We also would like to make the site public to the internet for the public to enjoy and use.
",,https://github.com/neel010427/Hate-Bad,,"python, tensorflow, tweepy, mongodb, pandas, numpy",University of Colorado Boulder,"","",MongoDB,zhouzhouthezhou,Kyle,Zhou,kylezhou2222@gmail.com,University of Colorado at Boulder,2,neel010427,Neel,Katuri,neka7176@colorado.edu,adamhoerger,Adam,Hoerger,adam.hoerger@gmail.com
Social Impact,HateBad,https://hackcu-vi.devpost.com/submissions/143107-hatebad,Shred the hate. Spread the love.,02/23/2020 11:43:57,"Inspiration

While social media can be a good thing, its negative impact cannot be understated. This creates an ideal environment for predators of all kinds to spread their negativity internationally. Our goal with this project was to create an escape from this toxicity and provide a platform specifically designed to spread positivity while also having some fun.

What it does

The HateBad initiative accomplishes three main tasks. One, we use the power of Deep Learning to create a model able to categorize tweets as positive, neutral, or negative/hateful. We then take this output and display a collection of positive tweets in our website. The website also allows the user to print out a random negative/hateful tweet, which will subsequently be shredded, symbolizing the breaking down of this harmful mindset this project aims to accomplish.

How we built it

After finding two data sets containing presorted hate speech and presorted positive/negative tweets, we parsed the raw data into a MongoDB for easy and quick access by our machine learning models. After sanitizing input, we used TensorFlow to create and train two separate models, one for each data set, to categorize a tweet as hateful/negative or positive. We then exported the trained models for use in production. Using the Twitter API, we created a tweet stream to funnel new tweets to the trained models, which would in turn give a pandas dataframe consisting of the tweet and its categorization. The program would then go through the dataframe and like tweets that were categorized as hateful/negative while retweeting the ones that were considered positive tweets under our twitter account ""@hate_no_good"". On the website back end, a js script would hook into the twitter account and display any retweeted tweets on the website. There is also a negativity-mode page in which you are able to print one of the liked or hateful/negative posts which would then get printed to a printer configuration that immediately feeds the paper into a shredder, providing unreasonable amounts of positive thoughts and satisfaction. There is also a feed for cute animals in case of an emergency.

Challenges we ran into

The Model
The hardest part of the project was defiantly getting two neural networks up and running. We initially tried to use the TensorFlow estimator toolkit. After training one of our data sets, we were able to get a fairly good categorization rate, but we were unable to pull useful information from the generator that the model output. For some reason the generator wouldn't act as a normal python generator and error out any time we tried to iterate over it. We solved this by scrapping the estimator model and electing for a traditional TensorFlow model, which after some painful data normalization, worked like a charm.

The Website
Unfortunately, we were unable to host our website with a domain on domain.com so for now it is a local site on our computers. We did not have the time nor resources to figure out how to host the site in the allotted 24hrs.

Accomplishments that we're proud of

The biggest accomplishment has to be the fact that this project does actually work. Going into this, none of us had messed with Deep Learning AI so we figured that the probability of us actually creating a usable product was very small. After a very long and painful night, however, we finally managed to get a reasonable categorization schema that exceeded our expectations.

What we learned

While it was interesting to learn how to work with this level of AI, we learned that it really is not for us. While being a cool branch of CS, machine learning with neural networks is not the most exhilarating activity out there.

On the plus side we did get experience with a powerful toolkit, TensorFlow, and a convenient and easy to use database in MongoDB.

What's next for HateBad

While reasonable, the model for categorizing tweets is far from perfect. In the future we intend to optimize the model so as to minimize the false positive and categorization that occurs. We also would like to make the site public to the internet for the public to enjoy and use.
",,https://github.com/neel010427/Hate-Bad,,"python, tensorflow, tweepy, mongodb, pandas, numpy",University of Colorado Boulder,"","",MongoDB,zhouzhouthezhou,Kyle,Zhou,kylezhou2222@gmail.com,University of Colorado at Boulder,2,neel010427,Neel,Katuri,neka7176@colorado.edu,adamhoerger,Adam,Hoerger,adam.hoerger@gmail.com
Best UX/UI,Sparrow Courier,https://hackcu-vi.devpost.com/submissions/143112-sparrow-courier,"Need to send something to a friend, but don't have the time? Sparrow it.",02/23/2020 11:49:17,"Inspiration

Time is more valuable than money. Sparrow allows users to accomplish more with their day than once possible. 

In the film industry, cameras, batteries, and other equipment need to get places for various shoots. My time as a Director led me to believe in delegation. Specific work for specific hands. The owners or borrowers of the equipment don't always have the time to get that equipment transported, or it's out of their way to get it there. Enter Sparrow, the courier for personal needs; applicable to all aspects of the human experience.

What it does

Sparrow is a two-sided app, with one interface for regular users and another for drivers. Users can send an item somewhere, confirm that they intend to receive an item, or request an item. The app allows them to track an item real-time and schedule specific pickup and delivery windows. Drivers can pick up items, deliver them, and get paid for their courier work.

How we built it

Adobe XD was used to wireframe, prototype, and design the app interface.

Challenges we ran into

The primary challenge lies in the very concept of the app. There are many potential loopholes for users to exercise in terms of the items they send and receive, and this remains a discussion for how the app can minimize the potential danger of transactions. Drug trafficking, terrorism, and fragile items are all risks we must release liability from. 

Employment of drivers. Scaling this for large business; drivers will have to be employed hourly instead of delivery-based commission; as the ""competition"" handles it.  

Timing/Pricing/Human Error

Accomplishments that we're proud of

The current state of the prototype is a big leap from where the idea started, and it has helped further conversation regarding the development of the app.

The modern and sleek design work is the basis for a successful brand. Xuedan went above and beyond in making the interface a friendly environment for all users. 

What's next for Sparrow Courier

The backend of the app requires a lot of attention, so the next step would simply be a fully functioning minimum viable product. The driver interface would also need to be built up from its current scratchboard state.

Using Apache Cordova and Javascript, we will be able to complete the MVP and run a full delivery using the current team. 

Scaling to larger business will require time and resources not yet set aside for Sparrow. 
",,https://xd.adobe.com/view/90104421-2582-485d-591f-d6108fdf2ecf-e621/?fullscreen,,adobe-xd,"University of Colorado, Boulder","","","",xfillmore,xfillmore,Fillmore,xuedan.fillmore@colorado.edu,University of Colorado at Boulder,1,fillmorejacob,Jacob,Fillmore,fillmorejacob@gmail.com
Best Use of Adobe XD,Sparrow Courier,https://hackcu-vi.devpost.com/submissions/143112-sparrow-courier,"Need to send something to a friend, but don't have the time? Sparrow it.",02/23/2020 11:49:17,"Inspiration

Time is more valuable than money. Sparrow allows users to accomplish more with their day than once possible. 

In the film industry, cameras, batteries, and other equipment need to get places for various shoots. My time as a Director led me to believe in delegation. Specific work for specific hands. The owners or borrowers of the equipment don't always have the time to get that equipment transported, or it's out of their way to get it there. Enter Sparrow, the courier for personal needs; applicable to all aspects of the human experience.

What it does

Sparrow is a two-sided app, with one interface for regular users and another for drivers. Users can send an item somewhere, confirm that they intend to receive an item, or request an item. The app allows them to track an item real-time and schedule specific pickup and delivery windows. Drivers can pick up items, deliver them, and get paid for their courier work.

How we built it

Adobe XD was used to wireframe, prototype, and design the app interface.

Challenges we ran into

The primary challenge lies in the very concept of the app. There are many potential loopholes for users to exercise in terms of the items they send and receive, and this remains a discussion for how the app can minimize the potential danger of transactions. Drug trafficking, terrorism, and fragile items are all risks we must release liability from. 

Employment of drivers. Scaling this for large business; drivers will have to be employed hourly instead of delivery-based commission; as the ""competition"" handles it.  

Timing/Pricing/Human Error

Accomplishments that we're proud of

The current state of the prototype is a big leap from where the idea started, and it has helped further conversation regarding the development of the app.

The modern and sleek design work is the basis for a successful brand. Xuedan went above and beyond in making the interface a friendly environment for all users. 

What's next for Sparrow Courier

The backend of the app requires a lot of attention, so the next step would simply be a fully functioning minimum viable product. The driver interface would also need to be built up from its current scratchboard state.

Using Apache Cordova and Javascript, we will be able to complete the MVP and run a full delivery using the current team. 

Scaling to larger business will require time and resources not yet set aside for Sparrow. 
",,https://xd.adobe.com/view/90104421-2582-485d-591f-d6108fdf2ecf-e621/?fullscreen,,adobe-xd,"University of Colorado, Boulder","","","",xfillmore,xfillmore,Fillmore,xuedan.fillmore@colorado.edu,University of Colorado at Boulder,1,fillmorejacob,Jacob,Fillmore,fillmorejacob@gmail.com
Best UX/UI,GrandGamer,https://hackcu-vi.devpost.com/submissions/143137-grandgamer,Playing games to combat loneliness in old age,02/23/2020 12:01:46,"Inspiration

Sadly, the elderly aged 85+ are the second most likely age group to die from suicide. 
Living in isolation, struggling with the death of a lifelong spouse or friends, or a lack of family visitation can lead seniors vulnerable to social isolation and loneliness.

Seeing my grandma's love for Mahjong and how the game connected her with our family and friends inspired me to design a more inclusive gaming experience that would allow seniors to interact with more friendly faces.

What it does

GrandGamer connects seniors to live volunteers who will schedule times to play games with them on a video call. 

How I built it

The prototypes were created with Adobe XD. Photoshop was used to create graphics. 

Challenges I ran into

This project made me focus more on design, when I'm usually on the coding end of things. I never fully appreciated before how slight changes in fonts, photos, or color schemes could make such big visual differences in a final product. 

Accomplishments that I'm proud of

Lots of firsts- first time trying Red Bull, first time having a solo team, first time being in Colorado, first time using Adobe XD, etc. 

What I learned

How to use Adobe XD! 
Including how to use various features: plugins, interactions, repeat grid, auto-animate, and more.

What's next for GrandGamer


I'd like to implement a friendly bot feature that would allow users to play games 24/7 when volunteers are not always available. 
A notification feature to remind users and volunteers when a game is scheduled soon. 
More animations would add increased responsiveness.


Accessibility


All games are suitable for those with physical or cognitive limitations. 
Large type and game boards make it easier for vision problems. 
Many games can be completed in under 30 minutes, preventing potential time or attention-span burnout. 
For those with colorblindness, patterns and textures emphasize contrast between objects.
GrandGamer is free to users. 


Ethical considerations


Information will be stored locally and not collected, shared, or sold to ensure autonomy is respected.
Volunteers will trained to not assume anything about the user- including gender, sexuality, age, etc. until told.
Volunteers will undergo a vigorous screening process to verify identity and weed out potential problems.

",,https://xd.adobe.com/view/425a1589-5751-4520-7c15-5713afd70fb9-346b/,,"adobe-xd, photoshop",Hinsdale Central High School,"","","",gabriellechang,Gabrielle,Chang,gchacha888@gmail.com,"",0
Best Use of Adobe XD,GrandGamer,https://hackcu-vi.devpost.com/submissions/143137-grandgamer,Playing games to combat loneliness in old age,02/23/2020 12:01:46,"Inspiration

Sadly, the elderly aged 85+ are the second most likely age group to die from suicide. 
Living in isolation, struggling with the death of a lifelong spouse or friends, or a lack of family visitation can lead seniors vulnerable to social isolation and loneliness.

Seeing my grandma's love for Mahjong and how the game connected her with our family and friends inspired me to design a more inclusive gaming experience that would allow seniors to interact with more friendly faces.

What it does

GrandGamer connects seniors to live volunteers who will schedule times to play games with them on a video call. 

How I built it

The prototypes were created with Adobe XD. Photoshop was used to create graphics. 

Challenges I ran into

This project made me focus more on design, when I'm usually on the coding end of things. I never fully appreciated before how slight changes in fonts, photos, or color schemes could make such big visual differences in a final product. 

Accomplishments that I'm proud of

Lots of firsts- first time trying Red Bull, first time having a solo team, first time being in Colorado, first time using Adobe XD, etc. 

What I learned

How to use Adobe XD! 
Including how to use various features: plugins, interactions, repeat grid, auto-animate, and more.

What's next for GrandGamer


I'd like to implement a friendly bot feature that would allow users to play games 24/7 when volunteers are not always available. 
A notification feature to remind users and volunteers when a game is scheduled soon. 
More animations would add increased responsiveness.


Accessibility


All games are suitable for those with physical or cognitive limitations. 
Large type and game boards make it easier for vision problems. 
Many games can be completed in under 30 minutes, preventing potential time or attention-span burnout. 
For those with colorblindness, patterns and textures emphasize contrast between objects.
GrandGamer is free to users. 


Ethical considerations


Information will be stored locally and not collected, shared, or sold to ensure autonomy is respected.
Volunteers will trained to not assume anything about the user- including gender, sexuality, age, etc. until told.
Volunteers will undergo a vigorous screening process to verify identity and weed out potential problems.

",,https://xd.adobe.com/view/425a1589-5751-4520-7c15-5713afd70fb9-346b/,,"adobe-xd, photoshop",Hinsdale Central High School,"","","",gabriellechang,Gabrielle,Chang,gchacha888@gmail.com,"",0
Most Creative Usage of Twitter API,Twitter talker,https://hackcu-vi.devpost.com/submissions/143141-twitter-talker,A bot that grabs mentions and posts a video with a face saying the tweet's content with a sentiment analysis,02/23/2020 12:03:01,"Inspiration

I wanted to do something interesting with the Twitter API and I thought the recent breakthroughs in face animation based on voice would be interesting to learn about

What it does

A bot that grabs mentions and posts a video with a face saying the tweet's content with a sentiment analysis

How I built it

I used a google cloud vm to first grab tweets that mentioned the bot, then the tweets' would be fed into a text to speech engine. Then this audio file would be fed into a research project that allows for face animation generation from an audio file. Finally a sentiment analysis would be done of the tweet and then the video would be uploaded saying the tweet sounds either positive, negative, or neutral

Challenges I ran into

There were a lot of dependency issues and not being familiar with any of the libraries I worked with made development a lot more of reading documentation rather than coding.

Accomplishments that I'm proud of

I am proud I was able to parse through a research project, integrate different unfamiliar technologies together, and finally have something that works(ish).

What I learned

I feel like I starting to get a grasp about how animations are generated using audio files.

What's next for Twitter talker

There are three main features that I would like to add


Add real human faces instead of just a mesh, this should not be too difficult as there are ways to map the generated mesh to a real photo
Use the sentiment analysis to choose different text to speech voices (e.g. an angry tweet will have an angry text to speech voice)
Use the sentiment analysis to choose different faces instead of just a wire (e.g. a happy tweet will have a happy face or emoji saying the text)

",https://youtu.be/FA3PODhEACU,https://twitter.com/swamulism,,python,University of Colorado Boulder,"","",Google Cloud,samueleubanks,Samuel,Eubanks,samuel.eubanks@colorado.edu,University of Colorado at Boulder,0
Most Random,Twitter talker,https://hackcu-vi.devpost.com/submissions/143141-twitter-talker,A bot that grabs mentions and posts a video with a face saying the tweet's content with a sentiment analysis,02/23/2020 12:03:01,"Inspiration

I wanted to do something interesting with the Twitter API and I thought the recent breakthroughs in face animation based on voice would be interesting to learn about

What it does

A bot that grabs mentions and posts a video with a face saying the tweet's content with a sentiment analysis

How I built it

I used a google cloud vm to first grab tweets that mentioned the bot, then the tweets' would be fed into a text to speech engine. Then this audio file would be fed into a research project that allows for face animation generation from an audio file. Finally a sentiment analysis would be done of the tweet and then the video would be uploaded saying the tweet sounds either positive, negative, or neutral

Challenges I ran into

There were a lot of dependency issues and not being familiar with any of the libraries I worked with made development a lot more of reading documentation rather than coding.

Accomplishments that I'm proud of

I am proud I was able to parse through a research project, integrate different unfamiliar technologies together, and finally have something that works(ish).

What I learned

I feel like I starting to get a grasp about how animations are generated using audio files.

What's next for Twitter talker

There are three main features that I would like to add


Add real human faces instead of just a mesh, this should not be too difficult as there are ways to map the generated mesh to a real photo
Use the sentiment analysis to choose different text to speech voices (e.g. an angry tweet will have an angry text to speech voice)
Use the sentiment analysis to choose different faces instead of just a wire (e.g. a happy tweet will have a happy face or emoji saying the text)

",https://youtu.be/FA3PODhEACU,https://twitter.com/swamulism,,python,University of Colorado Boulder,"","",Google Cloud,samueleubanks,Samuel,Eubanks,samuel.eubanks@colorado.edu,University of Colorado at Boulder,0
MLH: Best Use of Google Cloud,Twitter talker,https://hackcu-vi.devpost.com/submissions/143141-twitter-talker,A bot that grabs mentions and posts a video with a face saying the tweet's content with a sentiment analysis,02/23/2020 12:03:01,"Inspiration

I wanted to do something interesting with the Twitter API and I thought the recent breakthroughs in face animation based on voice would be interesting to learn about

What it does

A bot that grabs mentions and posts a video with a face saying the tweet's content with a sentiment analysis

How I built it

I used a google cloud vm to first grab tweets that mentioned the bot, then the tweets' would be fed into a text to speech engine. Then this audio file would be fed into a research project that allows for face animation generation from an audio file. Finally a sentiment analysis would be done of the tweet and then the video would be uploaded saying the tweet sounds either positive, negative, or neutral

Challenges I ran into

There were a lot of dependency issues and not being familiar with any of the libraries I worked with made development a lot more of reading documentation rather than coding.

Accomplishments that I'm proud of

I am proud I was able to parse through a research project, integrate different unfamiliar technologies together, and finally have something that works(ish).

What I learned

I feel like I starting to get a grasp about how animations are generated using audio files.

What's next for Twitter talker

There are three main features that I would like to add


Add real human faces instead of just a mesh, this should not be too difficult as there are ways to map the generated mesh to a real photo
Use the sentiment analysis to choose different text to speech voices (e.g. an angry tweet will have an angry text to speech voice)
Use the sentiment analysis to choose different faces instead of just a wire (e.g. a happy tweet will have a happy face or emoji saying the text)

",https://youtu.be/FA3PODhEACU,https://twitter.com/swamulism,,python,University of Colorado Boulder,"","",Google Cloud,samueleubanks,Samuel,Eubanks,samuel.eubanks@colorado.edu,University of Colorado at Boulder,0
All Beginner,BoldMetrics,https://hackcu-vi.devpost.com/submissions/143150-boldmetrics,Creating a streamline process for college students to view course grades and statistics.,02/23/2020 12:13:51,"Inspiration

As students who have to use multiple resources to find their grades at CU Boulder, we wanted to work on an idea that would better aid students to quickly know their grades.

What it does

BoldMetrics fetches data of the current classes the student is taking and the associated grades and tests. It allows for students to quickly see their grades by being on one central location.

How we built it

Our team heavily used React to create a dynamic framework with multiple components. We used GraphQL to better communicate with our BackEnd with the help of Hasura and Apollo. To stylize our FrontEnd, we used the Bloomer dependency as well as common .css

Challenges we ran into

Our team ran into multiple challenges throughout the Hackathon, mostly with querying and passing data between pages. Because we had troubles with querying, we spent a large portion of our time on working on a user authentication system that was never implemented.

Accomplishments that we're proud of

As a team, we are very proud of our BackEnd schema as it features many-to-many and one-to-many relationships. We are also very happy that we were able to create dynamic webpages that updated with different information based on various ids passed. Also, we are very proud that we successfully populated a graph with queried data.

What we learned

Although we all came from different backgrounds, we all became more familiar with React and integrating a BackEnd system. As well as React, we all got more comfortable using version control with git.

What's next for Islanders

We hope to continue developing BoldMetrics until it meets our vision we first had. This includes a secure user authentication, complete graph integration with our data base, and a clean UI/UX.
",,https://github.com/jfletcher98/Islanders,,"javascript, html, css, react, graphql, postgresql",University of Colorado Boulder,"","","",imjncarlson,Jacob,Carlson,imjncarlson@gmail.com,University of Colorado at Boulder,2,lujo8034,Luke,Joyce,lujo8034@colorado.edu,jfletcher98,jfletcher98,,jofl3978@colorado.edu
Most Creative Usage of Twitter API,HashMap - The Hashtag Map,https://hackcu-vi.devpost.com/submissions/143152-hashmap-the-hashtag-map,Visualizing opinions on popular topics through analyzing Twitter hashtags,02/23/2020 12:16:56,"Inspiration

We were inspired by looking at past projects on Devpost, learning about the Twitter API, and exploring Google Cloud's APIs.

What it does

It gives users insight into popular opinions and attitudes towards popular topics tracked by hashtags. Using sentiment analysis, we are able to grade the tweets grouped under a hashtag on their positive or negative emotion. By aggregating all of the emotion scores of the tweets belonging to a hashtag, we can show what people feel about trending topics around the world. It also shows where tweets originate to highlight what regions feel more positively or negatively towards a certain topic.

How we built it

We created a Twitter bot using Python that grabs tweets and popular hashtags from the Twitter API. This API gives us the text of tweets and any associated location data. It then groups the tweets by hashtag and feeds them to TextBlob, a Python natural language processing library, which uses sentiment analysis to grade each tweet on its positive and negative emotion. It then pushes the overall numeric scores for the hashtags and tweets as well as location data to a Firebase database. Our webapp, which we built using React JS, then pulls that data to rank the hashtags and plot them on a world map using Google Cloud's Maps and Geocode APIs.

Challenges we ran into

We weren't super experienced with JavaScript or natural language processing and we had no experience working with any of the APIs we used, so learning everything we needed to build this was time consuming.

Accomplishments that we're proud of

We are proud that we built a functioning webapp using so many new technologies and managed to juggle all of its components.

What we learned

We learned a ton about React and natural language processing. We also learned that it is fine to pivot away from an original, inferior plan even if substantial work has been done on it.

What's next for HashMap

One planned feature was allowing users to search for and grade any hashtag on Twitter, but it would have been prohibitively expensive and difficult. We also wanted to be able to do to sentiment analysis to extract emotions other than just ""positive"" and ""negative"".
",,http://34.70.140.87/,,"javascript, css3, html5, google-cloud, textblob, twitter, google-maps, python",Colorado School of Mines,hashmap.tech,"",Domain.com,AdamBeziou,Adam,Beziou,adam.beziou@gmail.com,Colorado School of Mines,2,juliahurtadoharvey,Julia,Harvey,julia.hurtado.harvey@gmail.com,jordannewport,Jordan,Newport,jordannewport@mymail.mines.edu
Best UX/UI,HashMap - The Hashtag Map,https://hackcu-vi.devpost.com/submissions/143152-hashmap-the-hashtag-map,Visualizing opinions on popular topics through analyzing Twitter hashtags,02/23/2020 12:16:56,"Inspiration

We were inspired by looking at past projects on Devpost, learning about the Twitter API, and exploring Google Cloud's APIs.

What it does

It gives users insight into popular opinions and attitudes towards popular topics tracked by hashtags. Using sentiment analysis, we are able to grade the tweets grouped under a hashtag on their positive or negative emotion. By aggregating all of the emotion scores of the tweets belonging to a hashtag, we can show what people feel about trending topics around the world. It also shows where tweets originate to highlight what regions feel more positively or negatively towards a certain topic.

How we built it

We created a Twitter bot using Python that grabs tweets and popular hashtags from the Twitter API. This API gives us the text of tweets and any associated location data. It then groups the tweets by hashtag and feeds them to TextBlob, a Python natural language processing library, which uses sentiment analysis to grade each tweet on its positive and negative emotion. It then pushes the overall numeric scores for the hashtags and tweets as well as location data to a Firebase database. Our webapp, which we built using React JS, then pulls that data to rank the hashtags and plot them on a world map using Google Cloud's Maps and Geocode APIs.

Challenges we ran into

We weren't super experienced with JavaScript or natural language processing and we had no experience working with any of the APIs we used, so learning everything we needed to build this was time consuming.

Accomplishments that we're proud of

We are proud that we built a functioning webapp using so many new technologies and managed to juggle all of its components.

What we learned

We learned a ton about React and natural language processing. We also learned that it is fine to pivot away from an original, inferior plan even if substantial work has been done on it.

What's next for HashMap

One planned feature was allowing users to search for and grade any hashtag on Twitter, but it would have been prohibitively expensive and difficult. We also wanted to be able to do to sentiment analysis to extract emotions other than just ""positive"" and ""negative"".
",,http://34.70.140.87/,,"javascript, css3, html5, google-cloud, textblob, twitter, google-maps, python",Colorado School of Mines,hashmap.tech,"",Domain.com,AdamBeziou,Adam,Beziou,adam.beziou@gmail.com,Colorado School of Mines,2,juliahurtadoharvey,Julia,Harvey,julia.hurtado.harvey@gmail.com,jordannewport,Jordan,Newport,jordannewport@mymail.mines.edu
MLH: Best Use of Google Cloud,HashMap - The Hashtag Map,https://hackcu-vi.devpost.com/submissions/143152-hashmap-the-hashtag-map,Visualizing opinions on popular topics through analyzing Twitter hashtags,02/23/2020 12:16:56,"Inspiration

We were inspired by looking at past projects on Devpost, learning about the Twitter API, and exploring Google Cloud's APIs.

What it does

It gives users insight into popular opinions and attitudes towards popular topics tracked by hashtags. Using sentiment analysis, we are able to grade the tweets grouped under a hashtag on their positive or negative emotion. By aggregating all of the emotion scores of the tweets belonging to a hashtag, we can show what people feel about trending topics around the world. It also shows where tweets originate to highlight what regions feel more positively or negatively towards a certain topic.

How we built it

We created a Twitter bot using Python that grabs tweets and popular hashtags from the Twitter API. This API gives us the text of tweets and any associated location data. It then groups the tweets by hashtag and feeds them to TextBlob, a Python natural language processing library, which uses sentiment analysis to grade each tweet on its positive and negative emotion. It then pushes the overall numeric scores for the hashtags and tweets as well as location data to a Firebase database. Our webapp, which we built using React JS, then pulls that data to rank the hashtags and plot them on a world map using Google Cloud's Maps and Geocode APIs.

Challenges we ran into

We weren't super experienced with JavaScript or natural language processing and we had no experience working with any of the APIs we used, so learning everything we needed to build this was time consuming.

Accomplishments that we're proud of

We are proud that we built a functioning webapp using so many new technologies and managed to juggle all of its components.

What we learned

We learned a ton about React and natural language processing. We also learned that it is fine to pivot away from an original, inferior plan even if substantial work has been done on it.

What's next for HashMap

One planned feature was allowing users to search for and grade any hashtag on Twitter, but it would have been prohibitively expensive and difficult. We also wanted to be able to do to sentiment analysis to extract emotions other than just ""positive"" and ""negative"".
",,http://34.70.140.87/,,"javascript, css3, html5, google-cloud, textblob, twitter, google-maps, python",Colorado School of Mines,hashmap.tech,"",Domain.com,AdamBeziou,Adam,Beziou,adam.beziou@gmail.com,Colorado School of Mines,2,juliahurtadoharvey,Julia,Harvey,julia.hurtado.harvey@gmail.com,jordannewport,Jordan,Newport,jordannewport@mymail.mines.edu
MLH: Best Domain Registered with Domain.com,HashMap - The Hashtag Map,https://hackcu-vi.devpost.com/submissions/143152-hashmap-the-hashtag-map,Visualizing opinions on popular topics through analyzing Twitter hashtags,02/23/2020 12:16:56,"Inspiration

We were inspired by looking at past projects on Devpost, learning about the Twitter API, and exploring Google Cloud's APIs.

What it does

It gives users insight into popular opinions and attitudes towards popular topics tracked by hashtags. Using sentiment analysis, we are able to grade the tweets grouped under a hashtag on their positive or negative emotion. By aggregating all of the emotion scores of the tweets belonging to a hashtag, we can show what people feel about trending topics around the world. It also shows where tweets originate to highlight what regions feel more positively or negatively towards a certain topic.

How we built it

We created a Twitter bot using Python that grabs tweets and popular hashtags from the Twitter API. This API gives us the text of tweets and any associated location data. It then groups the tweets by hashtag and feeds them to TextBlob, a Python natural language processing library, which uses sentiment analysis to grade each tweet on its positive and negative emotion. It then pushes the overall numeric scores for the hashtags and tweets as well as location data to a Firebase database. Our webapp, which we built using React JS, then pulls that data to rank the hashtags and plot them on a world map using Google Cloud's Maps and Geocode APIs.

Challenges we ran into

We weren't super experienced with JavaScript or natural language processing and we had no experience working with any of the APIs we used, so learning everything we needed to build this was time consuming.

Accomplishments that we're proud of

We are proud that we built a functioning webapp using so many new technologies and managed to juggle all of its components.

What we learned

We learned a ton about React and natural language processing. We also learned that it is fine to pivot away from an original, inferior plan even if substantial work has been done on it.

What's next for HashMap

One planned feature was allowing users to search for and grade any hashtag on Twitter, but it would have been prohibitively expensive and difficult. We also wanted to be able to do to sentiment analysis to extract emotions other than just ""positive"" and ""negative"".
",,http://34.70.140.87/,,"javascript, css3, html5, google-cloud, textblob, twitter, google-maps, python",Colorado School of Mines,hashmap.tech,"",Domain.com,AdamBeziou,Adam,Beziou,adam.beziou@gmail.com,Colorado School of Mines,2,juliahurtadoharvey,Julia,Harvey,julia.hurtado.harvey@gmail.com,jordannewport,Jordan,Newport,jordannewport@mymail.mines.edu
All Beginner,Circle App,https://hackcu-vi.devpost.com/submissions/143155-circle-app,This will judge a hand drawn circle and rank it versus other participants.,02/23/2020 12:22:51,"
Currently deployed on localhost. If you want a demo please text me @ 7204673609 and we can demo if for you


hack-cu-first-place-project

This app uses a variation of the Hough transformation for extracting lines from images. Instead we try to extract circles. There are several gifs attached showing the matrix that is used to extract the circle data (both x and y coordinates represent offsets and each frame is a different estimated radius). 

Basically though from the base directory of the repo running app.py in a terminal instance and then uploading an image to the website at localhost:5000/api/ will rank the image and compare it with other entries. A working POSTGRES connection is required and the credentials can be updated in db_creds.

-- Deployment may end up at circlejerk.herokuapp.com/api/
",,https://github.com/lukeingalls/hack-cu-first-place-project,,"python, html, javascript",CU,"","","",lukeingalls,lukeingalls,Ingalls,lukeingalls@me.com,"",0
Most Random,pyClicker++,https://hackcu-vi.devpost.com/submissions/143156-pyclicker,Enhancing the clicker experience,02/23/2020 12:23:14,"Inspiration

I'm taking an elective this semester that has mandatory clicker questions. Clicker questions can be boring, but I had one class where this wasn't the case. General Biology 1 had a system where they had a random number generator choose a student to answer each question. The student could pass if they wanted, so it made class participation more genuine. I wanted to take this style of participation and go even further with it. Everyone loved Kahoot in high school, so lets see if we can make something similar to it!

What it does

When the professor is done with a clicker session, the files from pyClicker++ will take the scores, and display the top three along with the names of those students on a web page. Don't worry, the name is optional if the professor wants to keep student confidentiality. Names are fetched from the .csv file Canvas provides to the professors. Additionally there is a feature called ""Hotseat"". It displays a random student that answered last clicker session. This feature can be used for many participation activities; however, it was also built in to prevent one person using multiple clickers. If Bob's name appears on the screen, and Bob isn't in class, things look a little suspicious! 

How I built it

pyClicker++ consists of 4 files not included with the iClicker Base Station software. There is a batch script that allows pyClicker++ to be lightweight and fast. This batch script runs the python script that is the main brain of the operation. This python script starts off by reading in names from a given .csv file, and then stores them for later use. The script then reads in the latest .xml file in the iClicker directory. This is how iClicker stores scores for each session. 

After parsing this file for clicker ID and score, these values are sorted from highest to lowest. Clicker ID is then replaced with appropriate names (This step can be skipped by the professor by commenting out 2 lines of code). The python script then writes a basic web page using html. 

The web page will open automatically, and show the top three students along with their scores for last session. The css and jpg file that accompanies the html file is included in the pyClicker++ package.

Hotseat was a little bit of a challenge being truly random. I decided to seed the random number generator using time. A random integer is generated between 0 and 10000, and is modulo'd by number of students +1, so everyone has as equal of a chance of answering as possible!

Challenges I ran into

I have been notoriously bad in the past at using file I/O in python, and this project depended heavily on file I/O. A major bump in the road was reading in the .csv file. The csv library has quite a few nuances such as not keeping the rows in order when writing to a dictionary. This wasn't too big of an issue when I realized I could just search by dictionary key value.

Another challenge was sorting the scores by highest value. This was a challenge because there was a name attached to each score, and they were pairs in a dictionary. Sorting the dictionary was a challenge that easily took about an hour! I eventually made the sorted scores a tuple, and it was easier to use from then on. 

The biggest challenge of pyClicker++ was finding the scores of each clicker. iClicker has some intentionally vague xml files. The scores were 2 sub nodes deep! This required a lot of iteration, but it was able to be done with the help of the ElementTree library. 

Accomplishments that I'm proud of

pyClicker++ reads files, writes files, parses files, and automatically opens your browser. At first this seemed like too big of a task for one person, but in the end, I am proud that it could do all I wanted it to. 

This hack is non intrusive either, making this an easily usable program that could be used in classes tomorrow if any professor wanted. This was a big deal to me because I really didn't want to step on iClicker's toes with this hack. 

What I learned

I learned how truly powerful Python is. One file is the brain of this whole operation, and there is still room for growth and improvement! I also learned how modular Python is as well. I imported from 8 libraries in order to accomplish what I wanted, and along the way I learned about each library. 

What's next for pyClicker++

I would say the next step is total leader boards. I didn't implement it into this version because if you miss a class, your chances of being in the top three are really slim, and this would become an attendance checker. Going off of this thought, I would say make multiple pyClicker++ packages depending on what class environment the professor wants. A stretch goal for this would be to actually implement this into a class. 
",,,,"python, html, css, batch",University of Colorado Boulder,"","","",kurtsprague,Kurt,Sprague,kurtsprague8@gmail.com,University of Colorado at Boulder,0
Dish Network Challenge,Healthometer,https://hackcu-vi.devpost.com/submissions/143161-healthometer,Website that assesses the level of health of the user based on the calories ingested in a certain time interval and their physical conditions,02/23/2020 12:37:30,"The Inspiration:
How healthy do you think you are?
Are you healthier than your friends?
Now you can compare yourself with them! And even with the entire world population!
Gamification of data has always been something that amazes both of us, especially in a society where everybody is connected online and we like to compare and compete with each other.
We are also concerned about the health issues related to the bad alimentation habits of the population nowadays, and the feeding disorders that a big part of humanity has.
This little project with huge projection is the combination of our interests and passions with a delicate and severe worldwide problem.

What does Healthometer do?
Healthometer takes the calories you ingested and the time frame you ate them, as well as your weight and your sex and gives you a score 0-100 of how healthy you are. This score or GPA will be recorded and will update itself each time you add a ""record of calories"" (ROC for short) to the site.
Not only this, as soon as you enter your first ROC, you will become part of a World Health Ranking where you can compare your score with other users.
In the Menu option you can also find a ""My Stats"" chart and see your progress through a timeline.

How did we build Healthometer?
It was a process done from scratch, even the idea came up within the HackCU schedule.
First we developed the idea and what exactly we wanted our project to do, since the options were infinite. We shared the code via Codeshare, and built everything with html, css and javascript, to relate the website operations with the code behind.

About the challenges...
The Database: since we don't use a database for the web, we have instead built a not operative prototype that shows the functionalities of our proposal.
Only one of us had experience with web design, so the process also involved fast learning and patience teaching.
The Ranking and Stats options were the most difficult parts of the program to code, and the ones that took the most time to develop.
Designing a website can be such a difficult task... Especially when the resources are limited and the time is short. The implementation of the main ideas we had that seemed easy to process were the hardest to implement! But the result looks very nice and we are very happy with our work.

Sweet accomplishments:
This idea is a very good way to spread awareness among all humankind about a proper alimentation, and we are very proud of how this can help to improve the world we live in any way.
It was the first time for one of us! We are glad this did not prevent the project from progressing and get to a satisfying end.
In addition, having a final project uploaded to the internet that everybody can have access to is a nice way of spreading our idea and having people using it and giving us feedback.

Learnings:
We learned sooo much doing this project. Not only about the languages used, the relations between them, website building, codesharing... but also about dividing the tasks and working as a team. The programmation part took a lot of research not only for coding functions and tips, but also for color match and presentation techniques. This type of work also forces you to manage time and be able to choose what is really important and what can be dismissed. Counselling each other and debating each step was hard but very fun, and we are already looking forward to the next HackCU.

And... What's next for Healthometer?
This project has a lot that can be done in the future, here are some ideas we have and wish we had the time to implement:
Separate the users into ""leagues"" (silver, platinum, gold, diamond...) such that they would move up or down depending on their diet. Even get food discounts as an incentive to use Healthometer more often and scale up in their stats.
Instead of using as an input the number of calories ingested, an implementation could be added so that the user inputs the food he or she ate and the program itself would calculate the calories and give the grading answer.
We could also implement a connection with the databases of apps like ""Yuka"" that grade the quality and healthiness of food from their barcode, and make a grading of your diet.
What if we make a mobile App so that the interaction with the user is easier? What if we could recommend people what to buy via this App? We could even give them QR discounts for their next shopping cart based on their good GPA!
The options are unlimited.
",,http://creative.colorado.edu/~capr5053/Hackaton/allInOne.html,,"html, css, javascript",University of Colorado Boulder,"","","",gumo8243,Guillermo,Moraes,gumo8243@colorado.edu,University of Colorado at Boulder,1,capr5053,Carlos,Prieto Fernández,capr5053@colorado.edu
Social Impact,Healthometer,https://hackcu-vi.devpost.com/submissions/143161-healthometer,Website that assesses the level of health of the user based on the calories ingested in a certain time interval and their physical conditions,02/23/2020 12:37:30,"The Inspiration:
How healthy do you think you are?
Are you healthier than your friends?
Now you can compare yourself with them! And even with the entire world population!
Gamification of data has always been something that amazes both of us, especially in a society where everybody is connected online and we like to compare and compete with each other.
We are also concerned about the health issues related to the bad alimentation habits of the population nowadays, and the feeding disorders that a big part of humanity has.
This little project with huge projection is the combination of our interests and passions with a delicate and severe worldwide problem.

What does Healthometer do?
Healthometer takes the calories you ingested and the time frame you ate them, as well as your weight and your sex and gives you a score 0-100 of how healthy you are. This score or GPA will be recorded and will update itself each time you add a ""record of calories"" (ROC for short) to the site.
Not only this, as soon as you enter your first ROC, you will become part of a World Health Ranking where you can compare your score with other users.
In the Menu option you can also find a ""My Stats"" chart and see your progress through a timeline.

How did we build Healthometer?
It was a process done from scratch, even the idea came up within the HackCU schedule.
First we developed the idea and what exactly we wanted our project to do, since the options were infinite. We shared the code via Codeshare, and built everything with html, css and javascript, to relate the website operations with the code behind.

About the challenges...
The Database: since we don't use a database for the web, we have instead built a not operative prototype that shows the functionalities of our proposal.
Only one of us had experience with web design, so the process also involved fast learning and patience teaching.
The Ranking and Stats options were the most difficult parts of the program to code, and the ones that took the most time to develop.
Designing a website can be such a difficult task... Especially when the resources are limited and the time is short. The implementation of the main ideas we had that seemed easy to process were the hardest to implement! But the result looks very nice and we are very happy with our work.

Sweet accomplishments:
This idea is a very good way to spread awareness among all humankind about a proper alimentation, and we are very proud of how this can help to improve the world we live in any way.
It was the first time for one of us! We are glad this did not prevent the project from progressing and get to a satisfying end.
In addition, having a final project uploaded to the internet that everybody can have access to is a nice way of spreading our idea and having people using it and giving us feedback.

Learnings:
We learned sooo much doing this project. Not only about the languages used, the relations between them, website building, codesharing... but also about dividing the tasks and working as a team. The programmation part took a lot of research not only for coding functions and tips, but also for color match and presentation techniques. This type of work also forces you to manage time and be able to choose what is really important and what can be dismissed. Counselling each other and debating each step was hard but very fun, and we are already looking forward to the next HackCU.

And... What's next for Healthometer?
This project has a lot that can be done in the future, here are some ideas we have and wish we had the time to implement:
Separate the users into ""leagues"" (silver, platinum, gold, diamond...) such that they would move up or down depending on their diet. Even get food discounts as an incentive to use Healthometer more often and scale up in their stats.
Instead of using as an input the number of calories ingested, an implementation could be added so that the user inputs the food he or she ate and the program itself would calculate the calories and give the grading answer.
We could also implement a connection with the databases of apps like ""Yuka"" that grade the quality and healthiness of food from their barcode, and make a grading of your diet.
What if we make a mobile App so that the interaction with the user is easier? What if we could recommend people what to buy via this App? We could even give them QR discounts for their next shopping cart based on their good GPA!
The options are unlimited.
",,http://creative.colorado.edu/~capr5053/Hackaton/allInOne.html,,"html, css, javascript",University of Colorado Boulder,"","","",gumo8243,Guillermo,Moraes,gumo8243@colorado.edu,University of Colorado at Boulder,1,capr5053,Carlos,Prieto Fernández,capr5053@colorado.edu
Most Random,Healthometer,https://hackcu-vi.devpost.com/submissions/143161-healthometer,Website that assesses the level of health of the user based on the calories ingested in a certain time interval and their physical conditions,02/23/2020 12:37:30,"The Inspiration:
How healthy do you think you are?
Are you healthier than your friends?
Now you can compare yourself with them! And even with the entire world population!
Gamification of data has always been something that amazes both of us, especially in a society where everybody is connected online and we like to compare and compete with each other.
We are also concerned about the health issues related to the bad alimentation habits of the population nowadays, and the feeding disorders that a big part of humanity has.
This little project with huge projection is the combination of our interests and passions with a delicate and severe worldwide problem.

What does Healthometer do?
Healthometer takes the calories you ingested and the time frame you ate them, as well as your weight and your sex and gives you a score 0-100 of how healthy you are. This score or GPA will be recorded and will update itself each time you add a ""record of calories"" (ROC for short) to the site.
Not only this, as soon as you enter your first ROC, you will become part of a World Health Ranking where you can compare your score with other users.
In the Menu option you can also find a ""My Stats"" chart and see your progress through a timeline.

How did we build Healthometer?
It was a process done from scratch, even the idea came up within the HackCU schedule.
First we developed the idea and what exactly we wanted our project to do, since the options were infinite. We shared the code via Codeshare, and built everything with html, css and javascript, to relate the website operations with the code behind.

About the challenges...
The Database: since we don't use a database for the web, we have instead built a not operative prototype that shows the functionalities of our proposal.
Only one of us had experience with web design, so the process also involved fast learning and patience teaching.
The Ranking and Stats options were the most difficult parts of the program to code, and the ones that took the most time to develop.
Designing a website can be such a difficult task... Especially when the resources are limited and the time is short. The implementation of the main ideas we had that seemed easy to process were the hardest to implement! But the result looks very nice and we are very happy with our work.

Sweet accomplishments:
This idea is a very good way to spread awareness among all humankind about a proper alimentation, and we are very proud of how this can help to improve the world we live in any way.
It was the first time for one of us! We are glad this did not prevent the project from progressing and get to a satisfying end.
In addition, having a final project uploaded to the internet that everybody can have access to is a nice way of spreading our idea and having people using it and giving us feedback.

Learnings:
We learned sooo much doing this project. Not only about the languages used, the relations between them, website building, codesharing... but also about dividing the tasks and working as a team. The programmation part took a lot of research not only for coding functions and tips, but also for color match and presentation techniques. This type of work also forces you to manage time and be able to choose what is really important and what can be dismissed. Counselling each other and debating each step was hard but very fun, and we are already looking forward to the next HackCU.

And... What's next for Healthometer?
This project has a lot that can be done in the future, here are some ideas we have and wish we had the time to implement:
Separate the users into ""leagues"" (silver, platinum, gold, diamond...) such that they would move up or down depending on their diet. Even get food discounts as an incentive to use Healthometer more often and scale up in their stats.
Instead of using as an input the number of calories ingested, an implementation could be added so that the user inputs the food he or she ate and the program itself would calculate the calories and give the grading answer.
We could also implement a connection with the databases of apps like ""Yuka"" that grade the quality and healthiness of food from their barcode, and make a grading of your diet.
What if we make a mobile App so that the interaction with the user is easier? What if we could recommend people what to buy via this App? We could even give them QR discounts for their next shopping cart based on their good GPA!
The options are unlimited.
",,http://creative.colorado.edu/~capr5053/Hackaton/allInOne.html,,"html, css, javascript",University of Colorado Boulder,"","","",gumo8243,Guillermo,Moraes,gumo8243@colorado.edu,University of Colorado at Boulder,1,capr5053,Carlos,Prieto Fernández,capr5053@colorado.edu
"",GW Data Visualizer,https://hackcu-vi.devpost.com/submissions/143167-gw-data-visualizer,See your data come to life,02/23/2020 12:44:40,"Inspiration

It was a good opportunity for us to explore a framework that we were interested in for a while and hone in our data science skills. Besides this, we hope that our application could give novice data scientists a glimpse of what can be achieved through data science and potentially inspire them to continue learning more about it. Moreover, we believe our application could be useful for the general population since it offers them a relatively easy way for them to learn some interesting insights about a particular data set.

How we built it

The application was written in Python using the Dash framework. We also used data science libraries, such as scikit-learn and numpy. 

Challenges I ran into

The main challenges came from the fact that we decided to use a framework that we weren't very experience with. Thus, during the hackathon, we spent a majority of the time learning more about the framework and discovering which tools of the framework would be useful for us when creating our application. 

What I learned

We learned how to build applications using the Dash framework and the features that the framework has to offer.
",https://www.youtube.com/watch?v=CC6EzvvlZtc&feature=youtu.be,https://github.com/SatishUpadhyaya/GWDataVisualizer,,"python, dash, numpy, pandas, scikit-learn",University of Colorado at Boulder,"","","",SatishUpadhyaya,Satish,Upadhyaya,satishrajupadhyaya@gmail.com,University of Colorado at Boulder,0
MLH: Best use of MongoDB Atlas,HackCU,https://hackcu-vi.devpost.com/submissions/143168-hackcu,Just Keep Reading!,02/23/2020 12:45:39,"Papyr-Us

Being ardent book readers, it pains to see old books accumulating dust in a corner. Worse yet is when your parents decide to ""recycle"" it. This idea revolves around promoting/building a strong community of readers by making accessibility to books easier - lending and borrowing. 
Looking for a book? All you need to do is search if the books on your wishlist are available on our website and simply connect with the lender. Its all point-to-point with no intermediary partners which means making new friends as well! 
Looking to donate/lend books? Simply register with us and we'll connect you with people. 

The whole application is available as a web-app. Connect with other readers and exchange books with each other. 

Features


Sign-up for new users
Login for existing users
Search for books to borrow
One-click add to lend books to library
Book description 
Twitter chatter about the book/author
Connect with owner of book with one-click to schedule pickup/drop


Tech Stack


Design : Adobe XD
Database : MongoDB Atlas
Back-End : Python Flask
APIs : Twitter API, Google Books API
Front-End : HTML, CSS, JQuery

",,https://github.com/SwarnaLathaNatarajan/HackCU,,"css, python, html, javascript, adobe-xd, jquery, twitter, google-books-api, mongodb",University of Colorado Boulder,"","",MongoDB,swna2675,Swarnalatha,Natarajan,swna2675@colorado.edu,University of Colorado at Boulder,2,aditiprakash,Aditi,Prakash,ap2205@gmail.com,KeerthikaRajvel,Keerthika,Rajvel,keerthikarajvel@gmail.com
Most Creative Usage of Twitter API,HackCU,https://hackcu-vi.devpost.com/submissions/143168-hackcu,Just Keep Reading!,02/23/2020 12:45:39,"Papyr-Us

Being ardent book readers, it pains to see old books accumulating dust in a corner. Worse yet is when your parents decide to ""recycle"" it. This idea revolves around promoting/building a strong community of readers by making accessibility to books easier - lending and borrowing. 
Looking for a book? All you need to do is search if the books on your wishlist are available on our website and simply connect with the lender. Its all point-to-point with no intermediary partners which means making new friends as well! 
Looking to donate/lend books? Simply register with us and we'll connect you with people. 

The whole application is available as a web-app. Connect with other readers and exchange books with each other. 

Features


Sign-up for new users
Login for existing users
Search for books to borrow
One-click add to lend books to library
Book description 
Twitter chatter about the book/author
Connect with owner of book with one-click to schedule pickup/drop


Tech Stack


Design : Adobe XD
Database : MongoDB Atlas
Back-End : Python Flask
APIs : Twitter API, Google Books API
Front-End : HTML, CSS, JQuery

",,https://github.com/SwarnaLathaNatarajan/HackCU,,"css, python, html, javascript, adobe-xd, jquery, twitter, google-books-api, mongodb",University of Colorado Boulder,"","",MongoDB,swna2675,Swarnalatha,Natarajan,swna2675@colorado.edu,University of Colorado at Boulder,2,aditiprakash,Aditi,Prakash,ap2205@gmail.com,KeerthikaRajvel,Keerthika,Rajvel,keerthikarajvel@gmail.com
MLH: Best Use of Google Cloud,HackCU,https://hackcu-vi.devpost.com/submissions/143168-hackcu,Just Keep Reading!,02/23/2020 12:45:39,"Papyr-Us

Being ardent book readers, it pains to see old books accumulating dust in a corner. Worse yet is when your parents decide to ""recycle"" it. This idea revolves around promoting/building a strong community of readers by making accessibility to books easier - lending and borrowing. 
Looking for a book? All you need to do is search if the books on your wishlist are available on our website and simply connect with the lender. Its all point-to-point with no intermediary partners which means making new friends as well! 
Looking to donate/lend books? Simply register with us and we'll connect you with people. 

The whole application is available as a web-app. Connect with other readers and exchange books with each other. 

Features


Sign-up for new users
Login for existing users
Search for books to borrow
One-click add to lend books to library
Book description 
Twitter chatter about the book/author
Connect with owner of book with one-click to schedule pickup/drop


Tech Stack


Design : Adobe XD
Database : MongoDB Atlas
Back-End : Python Flask
APIs : Twitter API, Google Books API
Front-End : HTML, CSS, JQuery

",,https://github.com/SwarnaLathaNatarajan/HackCU,,"css, python, html, javascript, adobe-xd, jquery, twitter, google-books-api, mongodb",University of Colorado Boulder,"","",MongoDB,swna2675,Swarnalatha,Natarajan,swna2675@colorado.edu,University of Colorado at Boulder,2,aditiprakash,Aditi,Prakash,ap2205@gmail.com,KeerthikaRajvel,Keerthika,Rajvel,keerthikarajvel@gmail.com
Sustainability,HackCU,https://hackcu-vi.devpost.com/submissions/143168-hackcu,Just Keep Reading!,02/23/2020 12:45:39,"Papyr-Us

Being ardent book readers, it pains to see old books accumulating dust in a corner. Worse yet is when your parents decide to ""recycle"" it. This idea revolves around promoting/building a strong community of readers by making accessibility to books easier - lending and borrowing. 
Looking for a book? All you need to do is search if the books on your wishlist are available on our website and simply connect with the lender. Its all point-to-point with no intermediary partners which means making new friends as well! 
Looking to donate/lend books? Simply register with us and we'll connect you with people. 

The whole application is available as a web-app. Connect with other readers and exchange books with each other. 

Features


Sign-up for new users
Login for existing users
Search for books to borrow
One-click add to lend books to library
Book description 
Twitter chatter about the book/author
Connect with owner of book with one-click to schedule pickup/drop


Tech Stack


Design : Adobe XD
Database : MongoDB Atlas
Back-End : Python Flask
APIs : Twitter API, Google Books API
Front-End : HTML, CSS, JQuery

",,https://github.com/SwarnaLathaNatarajan/HackCU,,"css, python, html, javascript, adobe-xd, jquery, twitter, google-books-api, mongodb",University of Colorado Boulder,"","",MongoDB,swna2675,Swarnalatha,Natarajan,swna2675@colorado.edu,University of Colorado at Boulder,2,aditiprakash,Aditi,Prakash,ap2205@gmail.com,KeerthikaRajvel,Keerthika,Rajvel,keerthikarajvel@gmail.com
Best Use of Adobe XD,HackCU,https://hackcu-vi.devpost.com/submissions/143168-hackcu,Just Keep Reading!,02/23/2020 12:45:39,"Papyr-Us

Being ardent book readers, it pains to see old books accumulating dust in a corner. Worse yet is when your parents decide to ""recycle"" it. This idea revolves around promoting/building a strong community of readers by making accessibility to books easier - lending and borrowing. 
Looking for a book? All you need to do is search if the books on your wishlist are available on our website and simply connect with the lender. Its all point-to-point with no intermediary partners which means making new friends as well! 
Looking to donate/lend books? Simply register with us and we'll connect you with people. 

The whole application is available as a web-app. Connect with other readers and exchange books with each other. 

Features


Sign-up for new users
Login for existing users
Search for books to borrow
One-click add to lend books to library
Book description 
Twitter chatter about the book/author
Connect with owner of book with one-click to schedule pickup/drop


Tech Stack


Design : Adobe XD
Database : MongoDB Atlas
Back-End : Python Flask
APIs : Twitter API, Google Books API
Front-End : HTML, CSS, JQuery

",,https://github.com/SwarnaLathaNatarajan/HackCU,,"css, python, html, javascript, adobe-xd, jquery, twitter, google-books-api, mongodb",University of Colorado Boulder,"","",MongoDB,swna2675,Swarnalatha,Natarajan,swna2675@colorado.edu,University of Colorado at Boulder,2,aditiprakash,Aditi,Prakash,ap2205@gmail.com,KeerthikaRajvel,Keerthika,Rajvel,keerthikarajvel@gmail.com
Best Use of TapWithUS SDK,Wavesculpter,https://hackcu-vi.devpost.com/submissions/143170-wavesculpter,A virtual playground for physically interacting with audio,02/23/2020 12:51:15,"Wavesculpter

An experimental audio playground, built in Unity. Intended to be motion-controlled
by the TapStrap 2 peripheral.

NOTE: The code depends on an audio asset that I have not uploaded to GitHub, as I don't own the rights to the sample that I've been using for testing, and I didn't put effort into finding free audio. In order for the code to run properly, you will have to provide your own audio asset that you wish to play with, and make sure that the AudioSource in GameObject is configured to play it.

Currently supports the following features:


Tap with pointer finger to increase volume, tap with middle finger to decrease volume
Tap with ring finger to play, tap with pinky finger to pause
Tap with pointer and middle finger to increase pitch, tap with ring and pinky finger to decrease pitch
Tap with thumb and pinky finger to increase distortion, tap with pointer/middle/ring finger to decrease distortion

",https://youtu.be/ZdAAEUdHmrc,https://github.com/p-lucero/Wavesculpter,,"c#, objective-c, unity, tapwithus, android",University of Colorado at Boulder,"","","",p-lucero,Paul,Lucero,paul.lucero08+github@gmail.com,University of Colorado at Boulder,0
Best UX/UI,Wavesculpter,https://hackcu-vi.devpost.com/submissions/143170-wavesculpter,A virtual playground for physically interacting with audio,02/23/2020 12:51:15,"Wavesculpter

An experimental audio playground, built in Unity. Intended to be motion-controlled
by the TapStrap 2 peripheral.

NOTE: The code depends on an audio asset that I have not uploaded to GitHub, as I don't own the rights to the sample that I've been using for testing, and I didn't put effort into finding free audio. In order for the code to run properly, you will have to provide your own audio asset that you wish to play with, and make sure that the AudioSource in GameObject is configured to play it.

Currently supports the following features:


Tap with pointer finger to increase volume, tap with middle finger to decrease volume
Tap with ring finger to play, tap with pinky finger to pause
Tap with pointer and middle finger to increase pitch, tap with ring and pinky finger to decrease pitch
Tap with thumb and pinky finger to increase distortion, tap with pointer/middle/ring finger to decrease distortion

",https://youtu.be/ZdAAEUdHmrc,https://github.com/p-lucero/Wavesculpter,,"c#, objective-c, unity, tapwithus, android",University of Colorado at Boulder,"","","",p-lucero,Paul,Lucero,paul.lucero08+github@gmail.com,University of Colorado at Boulder,0
Most Creative Usage of Twitter API,Privacy Destroyer,https://hackcu-vi.devpost.com/submissions/143177-privacy-destroyer,A twitter API that tweets a location inside of a geofence labeled by Radar.io. Also an android app that we created to log your location.,02/23/2020 13:00:14,"Privacy Destroyer

This project is made up of 3 primary components.

1. The App

An android app built in Kotlin that tracks your location in the background, sending updates at a set interval via requests to our web server. Location data is provided using Radar geofences, which allow the app to send an alert when the user moves between known locations and find the current location of the user at any given time.

2. The Web server

The web server is a Python Flask server listening for very simple requests that contain the current location of the user, the web server then invokes the Twitter bot to post a Tweet.

3. The Twitter Bot

Every time the web server receives a valid request, it sends the Twitter API a request to make a post detailing the current location and timestamp
",,https://twitter.com/Privacy_DSTRR,,"kotlin, python, radar, radar.io, twitter, flask, android, android-studio",University of Colorado Boulder,"","",Radar,Pumpkintitan,Enrico,Blackwell,pumpkintitan11@gmail.com,University of Colorado at Boulder,3,willemhscott,willemhscott,,willem.scott@colorado.edu,Bridge4,Bridge4,,s.abdulalhash@gmail.com,JakeMartin99,Jake,Martin,jcmartin987@gmail.com
MLH: Best Use of Google Cloud,Recyclable,https://hackcu-vi.devpost.com/submissions/143178-recyclable,A Web App To Help Create A Sustainable Future,02/23/2020 13:00:23,"Recyclable

A Web App To Help Create A Sustainable Future

HackCU VI: Max Rosoff, David Hallstrom, Ben Gillett

Our Live Site!

What is it?

You finish your delicious diabetes-in-a-bottle beverage graciously provided by the good organizers of HackCU, and then turn your attention to the problem of the plastic or light aluminum container with which you are about to pollute the environment. You inspect it for a recycling number or instruction, but in your sleep-deprived deliriousness, find nothing. You walk to the waste containers, and inspect the confusing graphical list of ""recycle this"" and ""landfill that"" items. Perhaps you're familiar with the recycling policies in your far distant hometown, but not in this new city which has temporarily become your home. What will you do??

Attempting to recycle containers that can't be recycled causes a lot of havoc and extra work for recycling plants, thereby decreasing their efficiency and increasing their cost. But putting extra waste in the landfills is just as bad: this practice is entirely unsustainable. What to do?

This is where Recyclable comes in: with just a brief interaction with our app using a mobile device of your choice, you can quickly determine which waste articles are recyclable in your area. Using sophisticated computer vision algorithms and our extensive hand-picked dataset, our app uses a single image of your waste product to determine its recycling class to help you make your decision.
By using our app, you save your recycling facilities time and work while also reducing unnecessary waste in our landfills!

How does it work?

This project is built on Express.js (server) and React.js (client). It uses Google Cloud for Neural Net Image processing.
We're hosting it on GCP, and our domain was free from Domain.com! See recyclable.tech.

To run it, you'll probably need nvm and npm and other delicious commands starting with node. Some combination of git clone, nvm install --lte, npm i, and npm run prod might help install and start it.

We made these design choices for a few reasons: since the project is a web app, it is platform independent and much easier to maintain. The Google Cloud Platform tools are easy to configure and scale, as make it easy to expand the training dataset.

Scaling

Recyclable is quite scalable: recycling capabilities are easily acquired or entered for any city, and the machine learning dataset can be improved upon to include products from all localities while also improving accuracy.
The model can be deployed in parallel using only minimal computing power. Our implementation costs only a few cents per hour to operate.
",,https://github.com/mrrosoff/Recyclable,,"javascript, html, google-cloud, auto-ml, express.js, react",Colorado State University,recyclable.tech,"",Domain.com,mrrosoff,Max,Rosoff,maxrosoff1@gmail.com,Colorado State University,2,dhallstr,dhallstr,,dhallstr@rams.colostate.edu,M3tanym,Ben,Gillett,bnjmn.gillett@gmail.com
MLH: Best Domain Registered with Domain.com,Recyclable,https://hackcu-vi.devpost.com/submissions/143178-recyclable,A Web App To Help Create A Sustainable Future,02/23/2020 13:00:23,"Recyclable

A Web App To Help Create A Sustainable Future

HackCU VI: Max Rosoff, David Hallstrom, Ben Gillett

Our Live Site!

What is it?

You finish your delicious diabetes-in-a-bottle beverage graciously provided by the good organizers of HackCU, and then turn your attention to the problem of the plastic or light aluminum container with which you are about to pollute the environment. You inspect it for a recycling number or instruction, but in your sleep-deprived deliriousness, find nothing. You walk to the waste containers, and inspect the confusing graphical list of ""recycle this"" and ""landfill that"" items. Perhaps you're familiar with the recycling policies in your far distant hometown, but not in this new city which has temporarily become your home. What will you do??

Attempting to recycle containers that can't be recycled causes a lot of havoc and extra work for recycling plants, thereby decreasing their efficiency and increasing their cost. But putting extra waste in the landfills is just as bad: this practice is entirely unsustainable. What to do?

This is where Recyclable comes in: with just a brief interaction with our app using a mobile device of your choice, you can quickly determine which waste articles are recyclable in your area. Using sophisticated computer vision algorithms and our extensive hand-picked dataset, our app uses a single image of your waste product to determine its recycling class to help you make your decision.
By using our app, you save your recycling facilities time and work while also reducing unnecessary waste in our landfills!

How does it work?

This project is built on Express.js (server) and React.js (client). It uses Google Cloud for Neural Net Image processing.
We're hosting it on GCP, and our domain was free from Domain.com! See recyclable.tech.

To run it, you'll probably need nvm and npm and other delicious commands starting with node. Some combination of git clone, nvm install --lte, npm i, and npm run prod might help install and start it.

We made these design choices for a few reasons: since the project is a web app, it is platform independent and much easier to maintain. The Google Cloud Platform tools are easy to configure and scale, as make it easy to expand the training dataset.

Scaling

Recyclable is quite scalable: recycling capabilities are easily acquired or entered for any city, and the machine learning dataset can be improved upon to include products from all localities while also improving accuracy.
The model can be deployed in parallel using only minimal computing power. Our implementation costs only a few cents per hour to operate.
",,https://github.com/mrrosoff/Recyclable,,"javascript, html, google-cloud, auto-ml, express.js, react",Colorado State University,recyclable.tech,"",Domain.com,mrrosoff,Max,Rosoff,maxrosoff1@gmail.com,Colorado State University,2,dhallstr,dhallstr,,dhallstr@rams.colostate.edu,M3tanym,Ben,Gillett,bnjmn.gillett@gmail.com
Sustainability,Recyclable,https://hackcu-vi.devpost.com/submissions/143178-recyclable,A Web App To Help Create A Sustainable Future,02/23/2020 13:00:23,"Recyclable

A Web App To Help Create A Sustainable Future

HackCU VI: Max Rosoff, David Hallstrom, Ben Gillett

Our Live Site!

What is it?

You finish your delicious diabetes-in-a-bottle beverage graciously provided by the good organizers of HackCU, and then turn your attention to the problem of the plastic or light aluminum container with which you are about to pollute the environment. You inspect it for a recycling number or instruction, but in your sleep-deprived deliriousness, find nothing. You walk to the waste containers, and inspect the confusing graphical list of ""recycle this"" and ""landfill that"" items. Perhaps you're familiar with the recycling policies in your far distant hometown, but not in this new city which has temporarily become your home. What will you do??

Attempting to recycle containers that can't be recycled causes a lot of havoc and extra work for recycling plants, thereby decreasing their efficiency and increasing their cost. But putting extra waste in the landfills is just as bad: this practice is entirely unsustainable. What to do?

This is where Recyclable comes in: with just a brief interaction with our app using a mobile device of your choice, you can quickly determine which waste articles are recyclable in your area. Using sophisticated computer vision algorithms and our extensive hand-picked dataset, our app uses a single image of your waste product to determine its recycling class to help you make your decision.
By using our app, you save your recycling facilities time and work while also reducing unnecessary waste in our landfills!

How does it work?

This project is built on Express.js (server) and React.js (client). It uses Google Cloud for Neural Net Image processing.
We're hosting it on GCP, and our domain was free from Domain.com! See recyclable.tech.

To run it, you'll probably need nvm and npm and other delicious commands starting with node. Some combination of git clone, nvm install --lte, npm i, and npm run prod might help install and start it.

We made these design choices for a few reasons: since the project is a web app, it is platform independent and much easier to maintain. The Google Cloud Platform tools are easy to configure and scale, as make it easy to expand the training dataset.

Scaling

Recyclable is quite scalable: recycling capabilities are easily acquired or entered for any city, and the machine learning dataset can be improved upon to include products from all localities while also improving accuracy.
The model can be deployed in parallel using only minimal computing power. Our implementation costs only a few cents per hour to operate.
",,https://github.com/mrrosoff/Recyclable,,"javascript, html, google-cloud, auto-ml, express.js, react",Colorado State University,recyclable.tech,"",Domain.com,mrrosoff,Max,Rosoff,maxrosoff1@gmail.com,Colorado State University,2,dhallstr,dhallstr,,dhallstr@rams.colostate.edu,M3tanym,Ben,Gillett,bnjmn.gillett@gmail.com
Best Use of TapWithUS SDK,Tap BlackJack,https://hackcu-vi.devpost.com/submissions/143181-tap-blackjack,Blackjack using the tap strap keyboard and mouse as input,02/23/2020 13:02:04,"Inspiration

Upon seeing the TapStrap device, it reminded me of the little gestures people do at card games in casinos. I thought it would be fun to make a casino card game where you could control the game using the gestures commonly used in real life.

What it does

You can play blackjack against a standard casino dealer, betting to try and make money or lose it all. The game has keyboard controls, but everything can also be done with the TapStrap. The controls are based off the gestures commonly used at casinos- for example, tapping on the table is a hit, so tapping with the TapStrap indicates you want to hit for a card.

How we built it

We started by building an initial blackjack game using Processing in Python mode. This allowed us to easily make a UI and base game logic together. Meanwhile, we experimented with using the TapWithUs SDK and eventually integrated it into the game. After that, we simply made various improvements using what we had left.

Challenges we ran into

The first challenge was environment- of our teammates, we used a variety of operating systems: Windows, MacOS, and Ubuntu. Since the TapWithUs SDK wasn't developed for Linux systems, it was particularly difficult to do anything in Ubuntu. However, we eventually got a setup that worked and we could all run the code in one way or another.

The second challenge was using the Python based SDK. Processing actually compiles its Python into Java code, which meant we couldn't use common Python libraries like numpy in our game code. This also meant we couldn't use the SDK. We got a (very hacky) workaround where we used the networking tools available in processing to connect to a server on localhost. The server sent all the data for the TapStrap to the game to be used in the game logic.

Finally, having low experience with most of our tools, we couldn't plan much design. Although design can be a great way to start a hackathon, our code became much hack-ier because we didn't. By 3am, it was difficult to read and edit, but we were more familiar with the tools so we made attempts to clean it up throughout the night. It's still terrible code (but it works).

Accomplishments that we're proud of

1) Getting it to work. Seriously.

2) Some of the visual design elements. None of us had any experience using Processing for Python before so it was new using it to build an entire game. It has relatively primitive tools (compared to engines like Unity), so even small animations took a fair amount of work.

3) The feel of the game. Casinos are meant for recreational, so it wouldn't make sense if our game didn't feel recreational. Using the TapStrap, we found that players could lean back and relax, controlling the game on the desk or even their lap. Compared to the usual computer stance of being hunched over your keyboard (like we have been since noon yesterday), this is refreshing and relaxing. Anybody familiar with the rules of blackjack can just pick up the game very quick.

4) Our ownership. Apart from a set of playing card pngs, Flask, and the SDK itself, we wrote almost everything from the ground up ourselves. We're not using something prebuilt to make our product look flashy or just using some other API to do most of the work for us- what we're showing off is our own work. Additionally, it does a really great job at highlighting the TapWithUs device.

We also stayed up all night (mostly).

What we learned

We all experimented with a ton of new tools. Two of our members were novices with Python, and the third could teach a lot to the other two members. On the other hand, the member most familiar with Python has never built anything with a drawing based GUI toolkit like Processing, so he learned quite a lot as well. Having to use the Flask server, we learned more about HTTP and sending data across sockets. 

What's next for Tap BlackJack

Using so many unknown technologies, we only really dived into some basic usages of the SDK available to us. The new SDK gave access to raw data from an IMU on the device, but we simply weren't prepared to attempt to process that data. However, going forward, perhaps with more than 24 hours, and a better programming environment to group in, we could aim more ambitiously, However, Blackjack won't be able to take advantage of this.

As for improvements to Tap BlackJack itself, it could do with some graphical improvements or functionality buffs, like the inclusion of multiplayer or even different casino games like poker. As a first go at using the SDK, it was lots of fun and turned out surprisingly well, However, it could never make it to a production app unless you basically rewrite it with better planning. This would be a great opportunity to try out the other SDKs available, particularly those for mobile apps.
",,https://github.com/Joseph-Riva/processing_blackjack,,"processing, flask, python, tapwithuspythonsdk",Colorado State University,"","","",akarduna,Alex,Karduna,alexkarduna@gmail.com,Colorado State University,2,Joseph-Riva,Joseph,Riva,josephariva@gmail.com,kaseda1027,Kacey,Schulz,kaseda@cs.colostate.edu
Best UX/UI,Tap BlackJack,https://hackcu-vi.devpost.com/submissions/143181-tap-blackjack,Blackjack using the tap strap keyboard and mouse as input,02/23/2020 13:02:04,"Inspiration

Upon seeing the TapStrap device, it reminded me of the little gestures people do at card games in casinos. I thought it would be fun to make a casino card game where you could control the game using the gestures commonly used in real life.

What it does

You can play blackjack against a standard casino dealer, betting to try and make money or lose it all. The game has keyboard controls, but everything can also be done with the TapStrap. The controls are based off the gestures commonly used at casinos- for example, tapping on the table is a hit, so tapping with the TapStrap indicates you want to hit for a card.

How we built it

We started by building an initial blackjack game using Processing in Python mode. This allowed us to easily make a UI and base game logic together. Meanwhile, we experimented with using the TapWithUs SDK and eventually integrated it into the game. After that, we simply made various improvements using what we had left.

Challenges we ran into

The first challenge was environment- of our teammates, we used a variety of operating systems: Windows, MacOS, and Ubuntu. Since the TapWithUs SDK wasn't developed for Linux systems, it was particularly difficult to do anything in Ubuntu. However, we eventually got a setup that worked and we could all run the code in one way or another.

The second challenge was using the Python based SDK. Processing actually compiles its Python into Java code, which meant we couldn't use common Python libraries like numpy in our game code. This also meant we couldn't use the SDK. We got a (very hacky) workaround where we used the networking tools available in processing to connect to a server on localhost. The server sent all the data for the TapStrap to the game to be used in the game logic.

Finally, having low experience with most of our tools, we couldn't plan much design. Although design can be a great way to start a hackathon, our code became much hack-ier because we didn't. By 3am, it was difficult to read and edit, but we were more familiar with the tools so we made attempts to clean it up throughout the night. It's still terrible code (but it works).

Accomplishments that we're proud of

1) Getting it to work. Seriously.

2) Some of the visual design elements. None of us had any experience using Processing for Python before so it was new using it to build an entire game. It has relatively primitive tools (compared to engines like Unity), so even small animations took a fair amount of work.

3) The feel of the game. Casinos are meant for recreational, so it wouldn't make sense if our game didn't feel recreational. Using the TapStrap, we found that players could lean back and relax, controlling the game on the desk or even their lap. Compared to the usual computer stance of being hunched over your keyboard (like we have been since noon yesterday), this is refreshing and relaxing. Anybody familiar with the rules of blackjack can just pick up the game very quick.

4) Our ownership. Apart from a set of playing card pngs, Flask, and the SDK itself, we wrote almost everything from the ground up ourselves. We're not using something prebuilt to make our product look flashy or just using some other API to do most of the work for us- what we're showing off is our own work. Additionally, it does a really great job at highlighting the TapWithUs device.

We also stayed up all night (mostly).

What we learned

We all experimented with a ton of new tools. Two of our members were novices with Python, and the third could teach a lot to the other two members. On the other hand, the member most familiar with Python has never built anything with a drawing based GUI toolkit like Processing, so he learned quite a lot as well. Having to use the Flask server, we learned more about HTTP and sending data across sockets. 

What's next for Tap BlackJack

Using so many unknown technologies, we only really dived into some basic usages of the SDK available to us. The new SDK gave access to raw data from an IMU on the device, but we simply weren't prepared to attempt to process that data. However, going forward, perhaps with more than 24 hours, and a better programming environment to group in, we could aim more ambitiously, However, Blackjack won't be able to take advantage of this.

As for improvements to Tap BlackJack itself, it could do with some graphical improvements or functionality buffs, like the inclusion of multiplayer or even different casino games like poker. As a first go at using the SDK, it was lots of fun and turned out surprisingly well, However, it could never make it to a production app unless you basically rewrite it with better planning. This would be a great opportunity to try out the other SDKs available, particularly those for mobile apps.
",,https://github.com/Joseph-Riva/processing_blackjack,,"processing, flask, python, tapwithuspythonsdk",Colorado State University,"","","",akarduna,Alex,Karduna,alexkarduna@gmail.com,Colorado State University,2,Joseph-Riva,Joseph,Riva,josephariva@gmail.com,kaseda1027,Kacey,Schulz,kaseda@cs.colostate.edu
Social Impact,Color Climb,https://hackcu-vi.devpost.com/submissions/143182-color-climb,An app to help colorblind people find rock climbing routes for colors they cannot see,02/23/2020 13:02:59,"Inspiration

We wanted to create an app that would help color blind people find routes for the rock climbing holds they cannot see.

What it does

This app takes an inputted image and calculates the route that a person can take and returns that image with circles on top of specific climbing holds to indicate a route.

How we built it

We used NativeScript running Angular to build our app and created a service to identify same color climbing holds as routes.

Our team member also designed our background image.

Challenges we ran into

Half of our team were working remotely due to the building being over capacity. Therefore, communication was hard. 

Our teammate also got sick with food poisoning. 

Learning how Nativescript works on top of Angular at times was a challenge.

Accomplishments that we're proud of

We are happy that we were able to successfully create an app.

What we learned

We learned how to build an app. 

What's next for Color Climb

We want to improve our algorithm for detecting holds on the same route
",,https://github.com/joshf26/Color-Climb,,"nativescript, typescript, angular.js",University of Colorado at Boulder,"","","",TiffanyVPhan,Tiffany,Phan,tiffany.phan@colorado.edu,University of Colorado at Boulder,3,joshf26,Joshua,Franklin,joshuafranklin26@gmail.com,qlychee,Elizabeth,Qiu,eqiu21@gmail.com,vitr2218,vitr2218,,vitr2218@colorado.edu
Dish Network Challenge,LetStudy.Online,https://hackcu-vi.devpost.com/submissions/143183-letstudy-online,"Anonymously share your study habits and we'll help you find tried and true study materials. Save time on searching, so you can focus on what is most important.",02/23/2020 13:03:21,"Inspiration

Endless hours of searching for the best study material has contributed to wasted hours of time that should have been devoted to studying for exams or completing homework. The inspiration for this tool is what occurs in reality; oftentimes, students refer to their predecessors for assistance with this. However, not everyone is fortunate to have someone to look towards for help. Thus, LetStudy.Online was created for the students who lack a support group like this. They do not need to worry about their private data being used maliciously, as all web activity remains anonymous.

What it does

After signing up, the user downloads a Chrome extension. When the student is studying, they can activate the extension, select their school and the course they are studying for, and the extension tracks the browsing usage until the user clicks the button to stop recording. This gets logged in our records for future students and LetStudy.Online users taking the same course to see. None of the user data is stored including the username, which is hashed to ensure privacy.
To incentivize students to use this tool, only users who have contributed to LetStudy.Online records within the past week are able to access data from past students.

How we built it

Node.js, MongoDB Atlas, Google Cloud Platform's Compute Engine, Highcharts, Tweepy API and PyMongo

Challenges we ran into

Connecting everything together!

Accomplishments that we're proud of


Connecting frontend to MongoDB Atlas
Successfully tweeting a post via Twitter API that used data extracted from MongoDB Atlas
Creating a Google Chrome extension


What's next for LetStudy.Online


Increased privacy for users, including 2FA

",,https://github.com/alymaquiling/HackCU2020,,"mongodb, javascript, node.js, highcharts, express.js, gulp.js, html, twitter, bootstrap, google-compute-engine, chrome, python","Thomas Edison State University, New Jersey Institute of Technology",LetStudy.Online,"","",alymaquiling,Alyssa Marie,Maquiling,alymaquiling@gmail.com,"Thomas Edison State University, New Jersey Institute of Technology",1,yanicakj,Jacob,Yanicak,yanicakj@gmail.com
MLH: Best use of MongoDB Atlas,LetStudy.Online,https://hackcu-vi.devpost.com/submissions/143183-letstudy-online,"Anonymously share your study habits and we'll help you find tried and true study materials. Save time on searching, so you can focus on what is most important.",02/23/2020 13:03:21,"Inspiration

Endless hours of searching for the best study material has contributed to wasted hours of time that should have been devoted to studying for exams or completing homework. The inspiration for this tool is what occurs in reality; oftentimes, students refer to their predecessors for assistance with this. However, not everyone is fortunate to have someone to look towards for help. Thus, LetStudy.Online was created for the students who lack a support group like this. They do not need to worry about their private data being used maliciously, as all web activity remains anonymous.

What it does

After signing up, the user downloads a Chrome extension. When the student is studying, they can activate the extension, select their school and the course they are studying for, and the extension tracks the browsing usage until the user clicks the button to stop recording. This gets logged in our records for future students and LetStudy.Online users taking the same course to see. None of the user data is stored including the username, which is hashed to ensure privacy.
To incentivize students to use this tool, only users who have contributed to LetStudy.Online records within the past week are able to access data from past students.

How we built it

Node.js, MongoDB Atlas, Google Cloud Platform's Compute Engine, Highcharts, Tweepy API and PyMongo

Challenges we ran into

Connecting everything together!

Accomplishments that we're proud of


Connecting frontend to MongoDB Atlas
Successfully tweeting a post via Twitter API that used data extracted from MongoDB Atlas
Creating a Google Chrome extension


What's next for LetStudy.Online


Increased privacy for users, including 2FA

",,https://github.com/alymaquiling/HackCU2020,,"mongodb, javascript, node.js, highcharts, express.js, gulp.js, html, twitter, bootstrap, google-compute-engine, chrome, python","Thomas Edison State University, New Jersey Institute of Technology",LetStudy.Online,"","",alymaquiling,Alyssa Marie,Maquiling,alymaquiling@gmail.com,"Thomas Edison State University, New Jersey Institute of Technology",1,yanicakj,Jacob,Yanicak,yanicakj@gmail.com
Most Creative Usage of Twitter API,LetStudy.Online,https://hackcu-vi.devpost.com/submissions/143183-letstudy-online,"Anonymously share your study habits and we'll help you find tried and true study materials. Save time on searching, so you can focus on what is most important.",02/23/2020 13:03:21,"Inspiration

Endless hours of searching for the best study material has contributed to wasted hours of time that should have been devoted to studying for exams or completing homework. The inspiration for this tool is what occurs in reality; oftentimes, students refer to their predecessors for assistance with this. However, not everyone is fortunate to have someone to look towards for help. Thus, LetStudy.Online was created for the students who lack a support group like this. They do not need to worry about their private data being used maliciously, as all web activity remains anonymous.

What it does

After signing up, the user downloads a Chrome extension. When the student is studying, they can activate the extension, select their school and the course they are studying for, and the extension tracks the browsing usage until the user clicks the button to stop recording. This gets logged in our records for future students and LetStudy.Online users taking the same course to see. None of the user data is stored including the username, which is hashed to ensure privacy.
To incentivize students to use this tool, only users who have contributed to LetStudy.Online records within the past week are able to access data from past students.

How we built it

Node.js, MongoDB Atlas, Google Cloud Platform's Compute Engine, Highcharts, Tweepy API and PyMongo

Challenges we ran into

Connecting everything together!

Accomplishments that we're proud of


Connecting frontend to MongoDB Atlas
Successfully tweeting a post via Twitter API that used data extracted from MongoDB Atlas
Creating a Google Chrome extension


What's next for LetStudy.Online


Increased privacy for users, including 2FA

",,https://github.com/alymaquiling/HackCU2020,,"mongodb, javascript, node.js, highcharts, express.js, gulp.js, html, twitter, bootstrap, google-compute-engine, chrome, python","Thomas Edison State University, New Jersey Institute of Technology",LetStudy.Online,"","",alymaquiling,Alyssa Marie,Maquiling,alymaquiling@gmail.com,"Thomas Edison State University, New Jersey Institute of Technology",1,yanicakj,Jacob,Yanicak,yanicakj@gmail.com
Best UX/UI,LetStudy.Online,https://hackcu-vi.devpost.com/submissions/143183-letstudy-online,"Anonymously share your study habits and we'll help you find tried and true study materials. Save time on searching, so you can focus on what is most important.",02/23/2020 13:03:21,"Inspiration

Endless hours of searching for the best study material has contributed to wasted hours of time that should have been devoted to studying for exams or completing homework. The inspiration for this tool is what occurs in reality; oftentimes, students refer to their predecessors for assistance with this. However, not everyone is fortunate to have someone to look towards for help. Thus, LetStudy.Online was created for the students who lack a support group like this. They do not need to worry about their private data being used maliciously, as all web activity remains anonymous.

What it does

After signing up, the user downloads a Chrome extension. When the student is studying, they can activate the extension, select their school and the course they are studying for, and the extension tracks the browsing usage until the user clicks the button to stop recording. This gets logged in our records for future students and LetStudy.Online users taking the same course to see. None of the user data is stored including the username, which is hashed to ensure privacy.
To incentivize students to use this tool, only users who have contributed to LetStudy.Online records within the past week are able to access data from past students.

How we built it

Node.js, MongoDB Atlas, Google Cloud Platform's Compute Engine, Highcharts, Tweepy API and PyMongo

Challenges we ran into

Connecting everything together!

Accomplishments that we're proud of


Connecting frontend to MongoDB Atlas
Successfully tweeting a post via Twitter API that used data extracted from MongoDB Atlas
Creating a Google Chrome extension


What's next for LetStudy.Online


Increased privacy for users, including 2FA

",,https://github.com/alymaquiling/HackCU2020,,"mongodb, javascript, node.js, highcharts, express.js, gulp.js, html, twitter, bootstrap, google-compute-engine, chrome, python","Thomas Edison State University, New Jersey Institute of Technology",LetStudy.Online,"","",alymaquiling,Alyssa Marie,Maquiling,alymaquiling@gmail.com,"Thomas Edison State University, New Jersey Institute of Technology",1,yanicakj,Jacob,Yanicak,yanicakj@gmail.com
MLH: Best Use of Google Cloud,LetStudy.Online,https://hackcu-vi.devpost.com/submissions/143183-letstudy-online,"Anonymously share your study habits and we'll help you find tried and true study materials. Save time on searching, so you can focus on what is most important.",02/23/2020 13:03:21,"Inspiration

Endless hours of searching for the best study material has contributed to wasted hours of time that should have been devoted to studying for exams or completing homework. The inspiration for this tool is what occurs in reality; oftentimes, students refer to their predecessors for assistance with this. However, not everyone is fortunate to have someone to look towards for help. Thus, LetStudy.Online was created for the students who lack a support group like this. They do not need to worry about their private data being used maliciously, as all web activity remains anonymous.

What it does

After signing up, the user downloads a Chrome extension. When the student is studying, they can activate the extension, select their school and the course they are studying for, and the extension tracks the browsing usage until the user clicks the button to stop recording. This gets logged in our records for future students and LetStudy.Online users taking the same course to see. None of the user data is stored including the username, which is hashed to ensure privacy.
To incentivize students to use this tool, only users who have contributed to LetStudy.Online records within the past week are able to access data from past students.

How we built it

Node.js, MongoDB Atlas, Google Cloud Platform's Compute Engine, Highcharts, Tweepy API and PyMongo

Challenges we ran into

Connecting everything together!

Accomplishments that we're proud of


Connecting frontend to MongoDB Atlas
Successfully tweeting a post via Twitter API that used data extracted from MongoDB Atlas
Creating a Google Chrome extension


What's next for LetStudy.Online


Increased privacy for users, including 2FA

",,https://github.com/alymaquiling/HackCU2020,,"mongodb, javascript, node.js, highcharts, express.js, gulp.js, html, twitter, bootstrap, google-compute-engine, chrome, python","Thomas Edison State University, New Jersey Institute of Technology",LetStudy.Online,"","",alymaquiling,Alyssa Marie,Maquiling,alymaquiling@gmail.com,"Thomas Edison State University, New Jersey Institute of Technology",1,yanicakj,Jacob,Yanicak,yanicakj@gmail.com
MLH: Best Domain Registered with Domain.com,LetStudy.Online,https://hackcu-vi.devpost.com/submissions/143183-letstudy-online,"Anonymously share your study habits and we'll help you find tried and true study materials. Save time on searching, so you can focus on what is most important.",02/23/2020 13:03:21,"Inspiration

Endless hours of searching for the best study material has contributed to wasted hours of time that should have been devoted to studying for exams or completing homework. The inspiration for this tool is what occurs in reality; oftentimes, students refer to their predecessors for assistance with this. However, not everyone is fortunate to have someone to look towards for help. Thus, LetStudy.Online was created for the students who lack a support group like this. They do not need to worry about their private data being used maliciously, as all web activity remains anonymous.

What it does

After signing up, the user downloads a Chrome extension. When the student is studying, they can activate the extension, select their school and the course they are studying for, and the extension tracks the browsing usage until the user clicks the button to stop recording. This gets logged in our records for future students and LetStudy.Online users taking the same course to see. None of the user data is stored including the username, which is hashed to ensure privacy.
To incentivize students to use this tool, only users who have contributed to LetStudy.Online records within the past week are able to access data from past students.

How we built it

Node.js, MongoDB Atlas, Google Cloud Platform's Compute Engine, Highcharts, Tweepy API and PyMongo

Challenges we ran into

Connecting everything together!

Accomplishments that we're proud of


Connecting frontend to MongoDB Atlas
Successfully tweeting a post via Twitter API that used data extracted from MongoDB Atlas
Creating a Google Chrome extension


What's next for LetStudy.Online


Increased privacy for users, including 2FA

",,https://github.com/alymaquiling/HackCU2020,,"mongodb, javascript, node.js, highcharts, express.js, gulp.js, html, twitter, bootstrap, google-compute-engine, chrome, python","Thomas Edison State University, New Jersey Institute of Technology",LetStudy.Online,"","",alymaquiling,Alyssa Marie,Maquiling,alymaquiling@gmail.com,"Thomas Edison State University, New Jersey Institute of Technology",1,yanicakj,Jacob,Yanicak,yanicakj@gmail.com
Social Impact,SkoGreen Denver,https://hackcu-vi.devpost.com/submissions/143185-skogreen-denver,Measure carbon emissions over time from your daily commute!,02/23/2020 13:07:03,"SkoGreen​ Denver

Track, understand, react: with SkoGreen, we hope you'll make the conscious effort to better our future and curb your CO2 production!

Project made for HackCU VI at the University of Colorado Boulder by computer science students from Mines and Boulder. 

Contributors: Katherine Aubert, Cade Crandall, Lizzie Scotty, Cole Smith

Inspiration

This project was inspired by Cade and Katherine's engineering design project for IDEAS II (HNRS115) at the Colorado School of Mines, which focuses on solving Denver's wicked traffic problem. They found in their research that there are concrete changes we can all make to reduce our footprints, and a tool to visualize it all will help motivate us all. 

What it does

SkoGreen is our interpretation of the FitBit or Apple Watch for the age of conservation. Before this project, we found ourselves unaware of the impact each individual decision we make has upon the environment or concrete, actionable steps to reduce our pollution. 

When you SkoGreen, you'll be able to enter your starting point and your destination and receive directions via Google Maps, tailored to your preferred form of transport (e.g, public transit, bike, car, walking). This will be logged to your Carbon Tracker and show you the pounds of CO2 produced alongside the social cost of these emissions, the long-term damage done by carbon in USD. 

A weekly graph is available for you to view your emissions over time, with plans to include better graphing to show progress over time. 

How we built it

SkoGreen runs on a backend composed mostly of C++ code. We are using the Google Maps API for transportation data, and our environmental impact calculations are based off of data provided by the US Department of Energy.

We used Electron to present our webpage as a desktop application and integrate C++ into the front-end.  

Challenges we ran into

Integrating the backend C++ code with the front-end was a particular challenge, considering it was new for everyone. Cole learned a lot of JavaScript and front-end technology (thanks Cole <3) for this project, and now we appreciate the front-end devs. 

Accomplishments that we're proud of


Learning multiple Google Maps API (for the first time!)
No git merge conflicts!
Learning heinous amounts of JS 
the development of bool keepGoing4;


What we learned

None of us had any real experience with front-end development, so every part of the process was a challenge. The back-end came easy after we figured out what data we actually needed from the DOE.

We learned a lot about the complete development process and how to quickly communicate as a team to resolve errors and debug. Using APIs and JavaScript was a new skill for most of us, so we all feel a little bit more comfortable with using either in the future. 

What's next for SkoGreen Denver

Given the time constraints, we didn't have as much time as we would have liked to find the best data for our projections and graphs. In the future, we want to add functionality for the user-cost of each ride on public transit or biking vs. a solo car trip.

We'd also like to expand the scope of this application to include more habits that have profound impacts (to increase its accessibility (mobile version.......!!!) 
",,https://github.com/coleksmith9/SkoGreen,,"google-cloud, c++, python, javascript, html5, css3, electron, google-maps, node.js","Colorado School of Mines, University of Colorado Boulder","","",Google Cloud,cadecrandall,Cade,Crandall,ccrandall@mymail.mines.edu,"Colorado School of Mines, University of Colorado at Boulder",3,katherineaubert,Katherine,Aubert,kaubert@mymail.mines.edu,coleksmith9,Cole,Smith,colesmith559@gmail.com,ljscotty,ljscotty,,lizziejscotty@gmail.com
MLH: Best Use of Google Cloud,SkoGreen Denver,https://hackcu-vi.devpost.com/submissions/143185-skogreen-denver,Measure carbon emissions over time from your daily commute!,02/23/2020 13:07:03,"SkoGreen​ Denver

Track, understand, react: with SkoGreen, we hope you'll make the conscious effort to better our future and curb your CO2 production!

Project made for HackCU VI at the University of Colorado Boulder by computer science students from Mines and Boulder. 

Contributors: Katherine Aubert, Cade Crandall, Lizzie Scotty, Cole Smith

Inspiration

This project was inspired by Cade and Katherine's engineering design project for IDEAS II (HNRS115) at the Colorado School of Mines, which focuses on solving Denver's wicked traffic problem. They found in their research that there are concrete changes we can all make to reduce our footprints, and a tool to visualize it all will help motivate us all. 

What it does

SkoGreen is our interpretation of the FitBit or Apple Watch for the age of conservation. Before this project, we found ourselves unaware of the impact each individual decision we make has upon the environment or concrete, actionable steps to reduce our pollution. 

When you SkoGreen, you'll be able to enter your starting point and your destination and receive directions via Google Maps, tailored to your preferred form of transport (e.g, public transit, bike, car, walking). This will be logged to your Carbon Tracker and show you the pounds of CO2 produced alongside the social cost of these emissions, the long-term damage done by carbon in USD. 

A weekly graph is available for you to view your emissions over time, with plans to include better graphing to show progress over time. 

How we built it

SkoGreen runs on a backend composed mostly of C++ code. We are using the Google Maps API for transportation data, and our environmental impact calculations are based off of data provided by the US Department of Energy.

We used Electron to present our webpage as a desktop application and integrate C++ into the front-end.  

Challenges we ran into

Integrating the backend C++ code with the front-end was a particular challenge, considering it was new for everyone. Cole learned a lot of JavaScript and front-end technology (thanks Cole <3) for this project, and now we appreciate the front-end devs. 

Accomplishments that we're proud of


Learning multiple Google Maps API (for the first time!)
No git merge conflicts!
Learning heinous amounts of JS 
the development of bool keepGoing4;


What we learned

None of us had any real experience with front-end development, so every part of the process was a challenge. The back-end came easy after we figured out what data we actually needed from the DOE.

We learned a lot about the complete development process and how to quickly communicate as a team to resolve errors and debug. Using APIs and JavaScript was a new skill for most of us, so we all feel a little bit more comfortable with using either in the future. 

What's next for SkoGreen Denver

Given the time constraints, we didn't have as much time as we would have liked to find the best data for our projections and graphs. In the future, we want to add functionality for the user-cost of each ride on public transit or biking vs. a solo car trip.

We'd also like to expand the scope of this application to include more habits that have profound impacts (to increase its accessibility (mobile version.......!!!) 
",,https://github.com/coleksmith9/SkoGreen,,"google-cloud, c++, python, javascript, html5, css3, electron, google-maps, node.js","Colorado School of Mines, University of Colorado Boulder","","",Google Cloud,cadecrandall,Cade,Crandall,ccrandall@mymail.mines.edu,"Colorado School of Mines, University of Colorado at Boulder",3,katherineaubert,Katherine,Aubert,kaubert@mymail.mines.edu,coleksmith9,Cole,Smith,colesmith559@gmail.com,ljscotty,ljscotty,,lizziejscotty@gmail.com
All Beginner,SkoGreen Denver,https://hackcu-vi.devpost.com/submissions/143185-skogreen-denver,Measure carbon emissions over time from your daily commute!,02/23/2020 13:07:03,"SkoGreen​ Denver

Track, understand, react: with SkoGreen, we hope you'll make the conscious effort to better our future and curb your CO2 production!

Project made for HackCU VI at the University of Colorado Boulder by computer science students from Mines and Boulder. 

Contributors: Katherine Aubert, Cade Crandall, Lizzie Scotty, Cole Smith

Inspiration

This project was inspired by Cade and Katherine's engineering design project for IDEAS II (HNRS115) at the Colorado School of Mines, which focuses on solving Denver's wicked traffic problem. They found in their research that there are concrete changes we can all make to reduce our footprints, and a tool to visualize it all will help motivate us all. 

What it does

SkoGreen is our interpretation of the FitBit or Apple Watch for the age of conservation. Before this project, we found ourselves unaware of the impact each individual decision we make has upon the environment or concrete, actionable steps to reduce our pollution. 

When you SkoGreen, you'll be able to enter your starting point and your destination and receive directions via Google Maps, tailored to your preferred form of transport (e.g, public transit, bike, car, walking). This will be logged to your Carbon Tracker and show you the pounds of CO2 produced alongside the social cost of these emissions, the long-term damage done by carbon in USD. 

A weekly graph is available for you to view your emissions over time, with plans to include better graphing to show progress over time. 

How we built it

SkoGreen runs on a backend composed mostly of C++ code. We are using the Google Maps API for transportation data, and our environmental impact calculations are based off of data provided by the US Department of Energy.

We used Electron to present our webpage as a desktop application and integrate C++ into the front-end.  

Challenges we ran into

Integrating the backend C++ code with the front-end was a particular challenge, considering it was new for everyone. Cole learned a lot of JavaScript and front-end technology (thanks Cole <3) for this project, and now we appreciate the front-end devs. 

Accomplishments that we're proud of


Learning multiple Google Maps API (for the first time!)
No git merge conflicts!
Learning heinous amounts of JS 
the development of bool keepGoing4;


What we learned

None of us had any real experience with front-end development, so every part of the process was a challenge. The back-end came easy after we figured out what data we actually needed from the DOE.

We learned a lot about the complete development process and how to quickly communicate as a team to resolve errors and debug. Using APIs and JavaScript was a new skill for most of us, so we all feel a little bit more comfortable with using either in the future. 

What's next for SkoGreen Denver

Given the time constraints, we didn't have as much time as we would have liked to find the best data for our projections and graphs. In the future, we want to add functionality for the user-cost of each ride on public transit or biking vs. a solo car trip.

We'd also like to expand the scope of this application to include more habits that have profound impacts (to increase its accessibility (mobile version.......!!!) 
",,https://github.com/coleksmith9/SkoGreen,,"google-cloud, c++, python, javascript, html5, css3, electron, google-maps, node.js","Colorado School of Mines, University of Colorado Boulder","","",Google Cloud,cadecrandall,Cade,Crandall,ccrandall@mymail.mines.edu,"Colorado School of Mines, University of Colorado at Boulder",3,katherineaubert,Katherine,Aubert,kaubert@mymail.mines.edu,coleksmith9,Cole,Smith,colesmith559@gmail.com,ljscotty,ljscotty,,lizziejscotty@gmail.com
Sustainability,EcoBuy,https://hackcu-vi.devpost.com/submissions/143186-ecobuy,"A Chrome plugin that can rate how eco-friendly a product is in a given marketplace, make recommendations of more sustainable options and give statistics about the environmental footprint of the user.",02/23/2020 13:08:47,"Inspiration

We want to make a positive change in the way e-commerce is understood, make more sustainable online purchases and give conciousness to the users about the impact of delivering in the environment.

What it does

EcoBuy is a chrome plugin that can rate how eco-friendly a product is in a given marketplace, make recommendations of more sustainable options and give statistics about the environmental footprint of the user historical purchases.

How we built it

For building it, an scrapping algorithm takes the relevant information from a product such as the shipping distance, weight, volumen, origin, materials... and calculates an eco-friendly score that goes from 0 to 100. Close to the product price, a circle with this number will appear together with a color from red to green indicating how environmentally friendly is the product. If the user does the purchase, this will be sent to our data base, where it will be processed and stored in the chrome extension of the user. After that, the plugin will show statistics to the user about his historical and his ecofriendly behavior compared to the other users. 

Challenges we ran into

We ran into problems when:
-Connecting python with javascripts. 
-Standardizing the format for the scrapping.
-Learning how to build a Chrome Extension.

Accomplishments that we're proud of

We are proud of being able to present a MVP with the essential functionalities of the plugin we had in mind. 

What we learned

We learnt how to organize a multidisciplinary project with very unrelated professional profiles. In our team we have a physicist, two computer science and telecommunications engineers and an aerospace engineer and economist. Also, it has been really fulfilling to see the commitment of the team members without sleeping at all. 

What's next for EcoBuy

We want to operate in the main E - Commerce platforms such as Alibaba, Amazon… Also, EcoBuy was built for creating a community where to promote an eco-friendly consciousness in this business that is tremendously growing year by year. We would like to have a possible collaborations with big E - Commerce companies in order to get more accurate information and improve the eco-friendly product index. 

Related to our code, we would like to improve the more sustainable alternatives recommender together with the scrapping speed by using Google APIs and faster scrapping strategies. 
",https://youtu.be/J6cRJeZ2Clg,https://github.com/baarrull/ecobuy,,"javascript, python, html5, css, chrome, scrap, bs4, selenium","University of Colorado, Colorado Springs; Universitat Politècnica de Catalunya; Universitad de Barcelona; Universitat Autònoma de Barcelona;","","","",dsmolina2812,David,Sánchez Molina,dsmolina2812@gmail.com,University of Colorado at Colorado Springs,3,ericvelazquez,ericvelazquez,,eric-5@hotmail.com,AlbertMitjans,Albert,Mitjans,a.mitjanscoma@gmail.com,baarrull,baarrull,,rogerbarrull97@gmail.com
MLH: Best UiPath Automation Hack,Getloc,https://hackcu-vi.devpost.com/submissions/143187-getloc,The main idea of this project is to know the whereabouts of our closed ones' in emergency situations.,02/23/2020 13:09:20,"Inspiration

In the present world, almost everyone holds a smartphone. Also, emergency situations in our daily life are getting common. One such incident happened to my friend who wasn't able to call in an emergency situation but got out of it safely because of his presence of mind. That's when the whole idea of Getloc came into picture.

What it does

This application needs two phones. The senders phone sends a message to his friends phone. The receivers phone after getting a ""keyword"" message from his friend, immediately turns on wifi, mobile date and location. Then it retrieves the latitude and longitude of the receiver and returns an automated text message to sender. The text message contains a google link to the receiver's location. 

How I built it

I built it completely in Android Studio using Java. I also used google places API and google maps API.

Challenges I ran into

Given the permission issues, I had spent plenty of time trying to figure out how to overcome that. Thats when I went to basics and got it fixed.

Accomplishments that I'm proud of

I managed to develop the project in 6 hrs.

What I learned

The first thing I learned is being a team player. Also, learned how to navigate through issues in Android.

What's next for Getloc

I am planning to add last known place and also make it much sophisticated. UI improvements will also be done.
",,,,"android, google, ui",colorado state university,"","","",HariHaraKumar,,,rhariharakumar9@gmail.com,Colorado State University,1,suj1995,Suraj,Eswaran,suj1995@gmail.com
Social Impact,Getloc,https://hackcu-vi.devpost.com/submissions/143187-getloc,The main idea of this project is to know the whereabouts of our closed ones' in emergency situations.,02/23/2020 13:09:20,"Inspiration

In the present world, almost everyone holds a smartphone. Also, emergency situations in our daily life are getting common. One such incident happened to my friend who wasn't able to call in an emergency situation but got out of it safely because of his presence of mind. That's when the whole idea of Getloc came into picture.

What it does

This application needs two phones. The senders phone sends a message to his friends phone. The receivers phone after getting a ""keyword"" message from his friend, immediately turns on wifi, mobile date and location. Then it retrieves the latitude and longitude of the receiver and returns an automated text message to sender. The text message contains a google link to the receiver's location. 

How I built it

I built it completely in Android Studio using Java. I also used google places API and google maps API.

Challenges I ran into

Given the permission issues, I had spent plenty of time trying to figure out how to overcome that. Thats when I went to basics and got it fixed.

Accomplishments that I'm proud of

I managed to develop the project in 6 hrs.

What I learned

The first thing I learned is being a team player. Also, learned how to navigate through issues in Android.

What's next for Getloc

I am planning to add last known place and also make it much sophisticated. UI improvements will also be done.
",,,,"android, google, ui",colorado state university,"","","",HariHaraKumar,,,rhariharakumar9@gmail.com,Colorado State University,1,suj1995,Suraj,Eswaran,suj1995@gmail.com
Most Creative Usage of Twitter API,PostGold,https://hackcu-vi.devpost.com/submissions/143190-postgold,"Writing a bot to create hot, and top posts for various platforms. Also generate speeches.",02/23/2020 13:13:38,"Post Gold

Everyone wants to get more likes and upvotes when making posts on social media,  but it can  be hard to think of new, creative content. To accomplish this we made a program that looks at data from posts that did well on Twitter and Reddit to help you create your own post that will achieve gold.

In making this we learned about the basics of natural language processing (NLP), Twitter and Reddit APIs, Markov Chains, and networkx (a python graph library).

This  program is built with Django and deployed on a raspberry pi using the nginx web server and the gunicorn wrapper of uwsgi. We picked python as our primary language since it has good support for graphs and  everyone on our team is comfortable with it.

The major setback that we faced in this project was the learning curve for natural language processing. It wasn't too hard to get basic sentences working and sounding like something that someone would actually post, but  once we got to multiple sentences the algorithms begins to fail. We decided that the solution to this would be to implement a neural network but by the time we reached this decision it was too late to implement, so we settled for trying to improve your existing code as much as we could. 

Overall the project was fun and we are proud of what we were able to produce in the time limit. If we continued the project we would look more into NLP and using a neural network.
",,https://github.com/jacobfelknor/HackCU2020,,"python, html, django, nginx, gunicorn, uwsgi",CU Boulder,"",Raspberry Pi,"",Drsain,Dylan R,Sain,dylanray.sain@gmail.com,University of Colorado at Boulder,3,SarahLundell,Sarah,Lundell,s_lundell@att.net,jacobfelknor,Jacob,Felknor,jacobfelknor073@gmail.com,jackichickan,jackichickan,Stickrod,mail4jaci@gmail.com
Most Random,PostGold,https://hackcu-vi.devpost.com/submissions/143190-postgold,"Writing a bot to create hot, and top posts for various platforms. Also generate speeches.",02/23/2020 13:13:38,"Post Gold

Everyone wants to get more likes and upvotes when making posts on social media,  but it can  be hard to think of new, creative content. To accomplish this we made a program that looks at data from posts that did well on Twitter and Reddit to help you create your own post that will achieve gold.

In making this we learned about the basics of natural language processing (NLP), Twitter and Reddit APIs, Markov Chains, and networkx (a python graph library).

This  program is built with Django and deployed on a raspberry pi using the nginx web server and the gunicorn wrapper of uwsgi. We picked python as our primary language since it has good support for graphs and  everyone on our team is comfortable with it.

The major setback that we faced in this project was the learning curve for natural language processing. It wasn't too hard to get basic sentences working and sounding like something that someone would actually post, but  once we got to multiple sentences the algorithms begins to fail. We decided that the solution to this would be to implement a neural network but by the time we reached this decision it was too late to implement, so we settled for trying to improve your existing code as much as we could. 

Overall the project was fun and we are proud of what we were able to produce in the time limit. If we continued the project we would look more into NLP and using a neural network.
",,https://github.com/jacobfelknor/HackCU2020,,"python, html, django, nginx, gunicorn, uwsgi",CU Boulder,"",Raspberry Pi,"",Drsain,Dylan R,Sain,dylanray.sain@gmail.com,University of Colorado at Boulder,3,SarahLundell,Sarah,Lundell,s_lundell@att.net,jacobfelknor,Jacob,Felknor,jacobfelknor073@gmail.com,jackichickan,jackichickan,Stickrod,mail4jaci@gmail.com
Best Use of TapWithUS SDK,Reverb,https://hackcu-vi.devpost.com/submissions/143192-reverb,Reverb is a Perucussion Instrument app to teach and play music.The percussion instruments are heavy to carry for the musicians.Save the luggage and get a Tap Strap to perform the same music.,02/23/2020 13:19:08,"Inspiration

I have always been fascinated about using the phone or iPad to perform the music because a single device that can be used as many instruments. Piano, keyboard are fine but the percussion instruments are difficult to use in the phone. When I saw the tap strap, I saw its potential to perform the percussion music. 

What it does


Reproduces the sound of the percussion instruments
Teaches you how to play them. 


How I built it


I used Swift, AVFoundation to build the app. 


Challenges I ran into


Was working on a different project which didn’t work out.
Learning to use the tap strap and the SDK was initially difficult. But the learning curve was great. 


Accomplishments that I'm proud of


Built a product within 6 hours. Started around 6 in the morning and completed it by 11.40. 
Did what I always wanted to do. Built a music app. 


What I learned

AVFoundation, Tap Strap 2

What's next for Reverb

Built only for the Mridingam instrument. Have to extend it for Tabla, Bongo Drums and other percussion instruments. 
",https://www.youtube.com/watch?v=GSXeZkxzJOs,https://github.com/haresudhan/Reverb,,"swift, coreaudio, tapstrap2",University of Colorado Boulder,"","","",haremuthusamy,Hare Sudhan,Muthusamy,hare.muthusamy@colorado.edu,University of Colorado at Boulder,0
"",COLORADO DRIVING TEST,https://hackcu-vi.devpost.com/submissions/143193-colorado-driving-test,Driving test for the future students,02/23/2020 13:22:30,"Inspiration

The main inspiration behind this project was from the airplane instructions and simulation.But those applications fails to assess those aspiring drivers, so it can be a great idea.

What it does

It helps drivers to understand each scenarios so that it can help them progress towards atual driving.

How we built it

We did it with the help of unity with C# programming language.

Challenges we ran into

We thought of implementing it in virtual reality with the help of oculus rift but fails to get those resources. 

Accomplishments that we're proud of

We got to replicate actual roads with bridges with the help of sketchup applications.

What we learned

We learnt to develop more on C# in the case of unity.

What's next for COLORADO DRIVING TEST

Do it in a better way with the help of oculus rift along with proper assessments. 
",,https://github.com/surajeswar22/COLORADO-DRIVING-TEST,,"c#, unity",Colorado State University,"","","",suj1995,Suraj,Eswaran,suj1995@gmail.com,Colorado State University,3,HariHaraKumar,,,rhariharakumar9@gmail.com,rohitrohitg17,rohit,Gorle,rohit.rohitg17@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com
Most Creative Usage of Twitter API,Tweet Mood Graph,https://hackcu-vi.devpost.com/submissions/143196-tweet-mood-graph,Analyzing positivity and negativity in tweets.,02/23/2020 13:26:42,"Inspiration

The inspiration for my program was to see how positive and negative certain individuals were on twitter. By taking in a tweet and catching certain positive and negative words we can see a overall mood for the tweet.

What it does

Using tweepy we take in the 10 most recent tweets from a users account. After taking this you now have a choice of which tweet specifically you want to analyze. It takes this individual tweet and then graphs the positive negative and neutral words. 

How we built it

I built this by utilizing twitters api library ""tweepy"" and a twitter developer account to get the tweets from twitter. I also used turtle to be able to make a graph based on the words. The words that are positive and negative are all stored in text files we retrieved from GitHub.

Challenges we ran into

Figuring out the twitter api was probably the biggest challenge I had. Once I figured that out all that was left was trying to make a visually pleasing graph

Accomplishments that we're proud of

I am proud of being able to try something new and programming in python which I have rather limited experience with. We worked the whole day and overcame many challenges and ran through every brick wall in front of us. 

What we learned

We learned how to use the twitter api and make a graphic based on a tweet, as well as other problem solving skills. We also learned how to use MongoDB although we did not integrate it into the project.

What's next for Tweet Mood Graph

I want to expand the program to analyze a user as a whole by taking in hundreds of tweets and giving it a positive or negative score.
",,https://github.com/tiva1693/super-octo-pancake,,"tweepy, twitter, turtle, python",University of Colorado Boulder,"","","",tiva1693,tiva1693,,tiva1693@colorado.edu,University of Colorado at Boulder,1,kmsbusch,Kevin,Busch,kebu5372@colorado.edu
All Beginner,Tweet Mood Graph,https://hackcu-vi.devpost.com/submissions/143196-tweet-mood-graph,Analyzing positivity and negativity in tweets.,02/23/2020 13:26:42,"Inspiration

The inspiration for my program was to see how positive and negative certain individuals were on twitter. By taking in a tweet and catching certain positive and negative words we can see a overall mood for the tweet.

What it does

Using tweepy we take in the 10 most recent tweets from a users account. After taking this you now have a choice of which tweet specifically you want to analyze. It takes this individual tweet and then graphs the positive negative and neutral words. 

How we built it

I built this by utilizing twitters api library ""tweepy"" and a twitter developer account to get the tweets from twitter. I also used turtle to be able to make a graph based on the words. The words that are positive and negative are all stored in text files we retrieved from GitHub.

Challenges we ran into

Figuring out the twitter api was probably the biggest challenge I had. Once I figured that out all that was left was trying to make a visually pleasing graph

Accomplishments that we're proud of

I am proud of being able to try something new and programming in python which I have rather limited experience with. We worked the whole day and overcame many challenges and ran through every brick wall in front of us. 

What we learned

We learned how to use the twitter api and make a graphic based on a tweet, as well as other problem solving skills. We also learned how to use MongoDB although we did not integrate it into the project.

What's next for Tweet Mood Graph

I want to expand the program to analyze a user as a whole by taking in hundreds of tweets and giving it a positive or negative score.
",,https://github.com/tiva1693/super-octo-pancake,,"tweepy, twitter, turtle, python",University of Colorado Boulder,"","","",tiva1693,tiva1693,,tiva1693@colorado.edu,University of Colorado at Boulder,1,kmsbusch,Kevin,Busch,kebu5372@colorado.edu
"",C++ Runtime Reflection Engine,https://hackcu-vi.devpost.com/submissions/143197-c-runtime-reflection-engine,Provides Reflection for Projects Written in C++,02/23/2020 13:27:14,"Inspiration

Thoroughly enjoyed CSCI 2400 Computer Systems, and have wanted to try working with ELF files for a while. Make a reflection engine is a really cool thing to do with them.

What it does

This project provides files that can be included in any C++ project running on Linux that provide the ability for the program to identify and utilize data and function objects from just a string, without having to manually register each attribute.

How I built it

There are two classes that power this project; Reflection and ElfReader. ElfReader reads the ELF file describing the running process, and provides the symbols to Reflection. Reflection accepts arguments from the developer/user, and makes meaning from the symbols provided by ElfReader.

ElfReader

Currently, the ElfReader gets the current process's ELF file by opening /proc/<pid>/exe. This is really just a symlink to the executable elsewhere in the filesystem, but using the pid is an easy way to get an absolute path, which is why we use it.

Once the ELF file is opened, ElfReader parses the Section Header Table to identify the SHT_DYNSYM entry, and makes a list of the SHT_STRTAB and SHT_SYMTAB entries.

ElfReader also provides a function to lookup a symbol by a string, std::vector<Elf64_Sym*>* ElfReader::lookupSymbol(char *). This method goes through every entry in SHT_DYNSYM and resolves its name by looking it up in one of the SHT_STRTABs, and de-mangling it. If the name that we're looking for exists in the resolved name, the symbol is added to a list of matches, which is returned when all of the entries have been analyzed.

Reflection

The Reflection Class should be instantiated by the Reflection::FromCurrentProcess(void *main) method, which automatically identifies the process's pid and load the ElfReader. Passing the location of int main(int,char**) allow the class to map the value of a symbol to a location in memory; Reflection will lookup the main symbol and calculate the difference between its value and the address passed to it. This offset is then added to any other symbol's value to determine it's location in memory.

The main method to note in Reflection is int Reflection::exec(char*,void*). This currently allows the user to specify a function that they want to execute via the string method, and supply up to 6 arguments that are either strings or numbers. Due to the early stage of the project, only commands with one . seperator work. The fvalue of the command before . is used to identify an instance of a class, and the value after is used to determine the function to run. If no . is needed, it will try to find a global function.

Passing the arguments to a function is done through inline assembly code. The value is pulled from the string passed to the method and stored in the appropriate register. When all registers have populated, inline assembly code is used to call the function.

Calling functions on an object instantiated from a class is also possible. The identified object is simply passed 
as the first argument to the function in compliance with the machine's ABI.

Challenges I ran into

Passing arguments to the function was the hardest part, especially functions that were part of an instantiated class. I know that I was going to have to use inline assembly, but it proved to be more challenging than I initially thought. It was easy enough to set the registers to the right value, but doing it at the right time so that they weren't overwritten was difficult.

Accomplishments that I'm proud of

It works!

What I learned

More about ELF file, and how programs are linked and loaded in Linux.

What's next for C++ Runtime Reflection Engine

Investigate Support For MCUs

See if there's a way to also make this work for microcontrollers, where the code is flash directly and the ELF file is not available at runtime. May be limited to applications that have peripheral storage or implement an OS that loads the file.

Reading Debug Symbols

Read debug symbols as well to provide more data and options to the user/developer. This could include access to local variables as well as source code and type matching.

Attach To Another Process

Use the ElfReader to read a different process's ELF file, and use a system call like strace to take control of it.

Load and Link Object Files

Use the ElfReader to read another ELF file. Load that program's code and link it to the existing process, therefore providing methods and functionality from the other object.
",,https://github.com/DavidKopalaCU/CPP-Reflection,,"c++, elf, asm",University of Colorado Boulder,"","","",DavidKopalaCU,David,Kopala,david.kopala@colorado.edu,University of Colorado at Boulder,0
All Beginner,Rizu Ogata,https://hackcu-vi.devpost.com/submissions/143198-rizu-ogata,"A bot for discord that can help with simplifying, computing, and graphing math expressions, and displaying expressions using latex.",02/23/2020 13:31:01,"Inspiration

Our group uses Discord a ton. We're commonly asking each other for help on homework. A great barrier in this endeavor is: verbal math is difficult. It's hard to communicate our ideas and expressions to each other with just words. Screen sharing isn't that great as we still need to display this information in a digestible manner and have answers that produce correct answers. Thus our discord bot can help us communicate such information efficiently and on the same platform.

What it does

A bot on discord that helps with math and math communication.

How we built it

We're using various libraries, the main one is discord.js in order to host the bot to a discord server.

Challenges we ran into

Node.js is somewhat different than anything we have experience in and we faced various difficulties in getting the APIs to work with our code.

What we learned

We learned how to use APIs and node.js

What's next for Rizu Ogata

We're gonna update her periodically and use her for our server.
",,,,"node.js, discord.js, newton, plotly","CU Boulder, Colorado School of Mines","","","",ejk9,Jon,Serrano,serranojon02@gmail.com,"Colorado School of Mines, University of Colorado at Boulder",1,Utaha-Kasumigod,Grant,Junk,grantjunk15@gmail.com
MLH: Best Use of Google Cloud,Next Generation Networks with Telemetry Data,https://hackcu-vi.devpost.com/submissions/143199-next-generation-networks-with-telemetry-data,Telemetry and Distributed Scaling as a Service using IaaS Platform,02/23/2020 13:31:13,"Inspiration

Infrastructure as a Service (IaaS) Platform provided a level playing field allowing small and medium-sized companies
who don't have upfront investment capabilities. Networking has been hit with a sway of industry changes. We hear
about a lot of buzz words about Software-Defined Networking, OpenSource, DevOps Practices. These open a new
path not just to the top companies who are constantly competing to stay top at the market, but to those who now can
use opensource technologies to give these big companies a run for their money.
As a Team of Network Engineering Students, we wanted to explore some of these buzz words. Put into to use a robot
cloud platform like Google Cloud to provide “Telemetry and Distributed Scaling” as a Service.

What it does & How we built it

Any IaaS Service provider provides a rich set of metrics to evaluate the performance of servers that they host. Since
they have a robust methodology and well-defined templates for this, can these IaaS Providers market this? In this
project, we tried to build a Telemetry Pipeline hosted in the IaaS environment. The clients push telemetry data to
collectors(we are using GCloud MySQL Servers) distributed in the IaaS platform. (Of course, the IaaS already takes care
of the inter-networking of these collectors.) We are running Google Cloud Functions that periodically check for new
data in these collectors. Based on the service signed up by the client ( here due to time constraint we only did 2
servers, client infrastructure CPU measurement and auto-scaling based on the CPU). We took these data and feed them
into an InfluxDb Time Series Database. We further Visualized the data with Grafana. Once we have some data, we tried
to gather intelligence from the collected data. If the CPU Utilization was more than a predefined threshold , we used
the Grafana interface to alert the network admin. We didn't stop there. We triggered a Jenkins build to check if the
client has the allotted Quota to spin up new instances. If the Client has Quota we went on to provision these new
servers for them. If they don't have sufficient Quota we will revert back to the network admin.

Challenges we ran into


Updating the GCP Firewall policy to have required access for our IaaS service platform running on GCP.
Integration of SQL, InfluxDB, and Grafana.
Limited experience with the containerization with Docker
Running and configuring the Jenkins inside a Docker


Accomplishments that we're proud of


We have an end to end product working.
We were able to learn containerization with Docker in deep and were able to resolve all the challenges we faced.
We were able to have a complete CI/CD pipeline implemented on Jenkins.
Integrating all the components together.


What we learned


We learned containerization in detail.
We learned how to configure the Jenkins pipeline for automated testing.
We learned InfluxDB and Grafana integration


What's next for Next Generation Networks with Telemetry Data


Do it on real servers rather than VMs
Make it vendor-agnostic
Implement Kubernetes
Poll different types of data for more telemetry based decisions.

",,https://drive.google.com/file/d/1c2W_thTLWrOb0CfNhQoDm4h6FpeZyLhl/view?usp=sharing,,"python, docker, grafana, sql, gcp, domain.com, influxdb, jenkins",University of Colorado Boulder,tellmerouter.tech & telemetrynetworks.tech,"",Google Cloud,parthadroja,Parth,Adroja,parth.adroja@colorado.edu,University of Colorado at Boulder,1,mrgokulmurali,Gokul,Murali,mrgokulmurali@gmail.com
MLH: Best Domain Registered with Domain.com,Next Generation Networks with Telemetry Data,https://hackcu-vi.devpost.com/submissions/143199-next-generation-networks-with-telemetry-data,Telemetry and Distributed Scaling as a Service using IaaS Platform,02/23/2020 13:31:13,"Inspiration

Infrastructure as a Service (IaaS) Platform provided a level playing field allowing small and medium-sized companies
who don't have upfront investment capabilities. Networking has been hit with a sway of industry changes. We hear
about a lot of buzz words about Software-Defined Networking, OpenSource, DevOps Practices. These open a new
path not just to the top companies who are constantly competing to stay top at the market, but to those who now can
use opensource technologies to give these big companies a run for their money.
As a Team of Network Engineering Students, we wanted to explore some of these buzz words. Put into to use a robot
cloud platform like Google Cloud to provide “Telemetry and Distributed Scaling” as a Service.

What it does & How we built it

Any IaaS Service provider provides a rich set of metrics to evaluate the performance of servers that they host. Since
they have a robust methodology and well-defined templates for this, can these IaaS Providers market this? In this
project, we tried to build a Telemetry Pipeline hosted in the IaaS environment. The clients push telemetry data to
collectors(we are using GCloud MySQL Servers) distributed in the IaaS platform. (Of course, the IaaS already takes care
of the inter-networking of these collectors.) We are running Google Cloud Functions that periodically check for new
data in these collectors. Based on the service signed up by the client ( here due to time constraint we only did 2
servers, client infrastructure CPU measurement and auto-scaling based on the CPU). We took these data and feed them
into an InfluxDb Time Series Database. We further Visualized the data with Grafana. Once we have some data, we tried
to gather intelligence from the collected data. If the CPU Utilization was more than a predefined threshold , we used
the Grafana interface to alert the network admin. We didn't stop there. We triggered a Jenkins build to check if the
client has the allotted Quota to spin up new instances. If the Client has Quota we went on to provision these new
servers for them. If they don't have sufficient Quota we will revert back to the network admin.

Challenges we ran into


Updating the GCP Firewall policy to have required access for our IaaS service platform running on GCP.
Integration of SQL, InfluxDB, and Grafana.
Limited experience with the containerization with Docker
Running and configuring the Jenkins inside a Docker


Accomplishments that we're proud of


We have an end to end product working.
We were able to learn containerization with Docker in deep and were able to resolve all the challenges we faced.
We were able to have a complete CI/CD pipeline implemented on Jenkins.
Integrating all the components together.


What we learned


We learned containerization in detail.
We learned how to configure the Jenkins pipeline for automated testing.
We learned InfluxDB and Grafana integration


What's next for Next Generation Networks with Telemetry Data


Do it on real servers rather than VMs
Make it vendor-agnostic
Implement Kubernetes
Poll different types of data for more telemetry based decisions.

",,https://drive.google.com/file/d/1c2W_thTLWrOb0CfNhQoDm4h6FpeZyLhl/view?usp=sharing,,"python, docker, grafana, sql, gcp, domain.com, influxdb, jenkins",University of Colorado Boulder,tellmerouter.tech & telemetrynetworks.tech,"",Google Cloud,parthadroja,Parth,Adroja,parth.adroja@colorado.edu,University of Colorado at Boulder,1,mrgokulmurali,Gokul,Murali,mrgokulmurali@gmail.com
Most Creative Usage of Twitter API,Twitter Hashtag Race,https://hackcu-vi.devpost.com/submissions/143200-twitter-hashtag-race,How fast can you navigate from #Start_Hashtag to #End_Hashtag??,02/23/2020 13:31:35,"What it does

Queries Twitter based on 'start' / 'finish' hashtags and returns the most common hashtags included in tweets with the input tags.  The user can then click through the returned values in an effort to navigate from #start to #finish.

How we built it

Fueled by Redbull

Challenges we ran into

Linking returned hashtags into HTML/CSS with Flask (which we'd never used before)

Accomplishments that we're proud of

We had no idea what to hack out when we arrived and in a matter of 24 LONG hours, we came up with a creative, engaging, interesting, and entertaining concept.  And we've nearly got a fully functioning product.

What we learned

Sleep deprivation affects productivity

What's next for Twitter Hashtag Race

Implement ads so we can afford the professional Twitter API and rework the gameplay/UX into there intended form.
",,http://www.github.com/pai-sho/the-race,,"twitter, api, python, flask, css, html",CU Boulder,"","","",stev2368,Stephen,Evans,stev2368@colorado.edu,University of Colorado at Boulder,1,Pai-Sho,Pai-Sho,,jackhessburg94@gmail.com
Best UX/UI,Twitter Hashtag Race,https://hackcu-vi.devpost.com/submissions/143200-twitter-hashtag-race,How fast can you navigate from #Start_Hashtag to #End_Hashtag??,02/23/2020 13:31:35,"What it does

Queries Twitter based on 'start' / 'finish' hashtags and returns the most common hashtags included in tweets with the input tags.  The user can then click through the returned values in an effort to navigate from #start to #finish.

How we built it

Fueled by Redbull

Challenges we ran into

Linking returned hashtags into HTML/CSS with Flask (which we'd never used before)

Accomplishments that we're proud of

We had no idea what to hack out when we arrived and in a matter of 24 LONG hours, we came up with a creative, engaging, interesting, and entertaining concept.  And we've nearly got a fully functioning product.

What we learned

Sleep deprivation affects productivity

What's next for Twitter Hashtag Race

Implement ads so we can afford the professional Twitter API and rework the gameplay/UX into there intended form.
",,http://www.github.com/pai-sho/the-race,,"twitter, api, python, flask, css, html",CU Boulder,"","","",stev2368,Stephen,Evans,stev2368@colorado.edu,University of Colorado at Boulder,1,Pai-Sho,Pai-Sho,,jackhessburg94@gmail.com
Most Random,Twitter Hashtag Race,https://hackcu-vi.devpost.com/submissions/143200-twitter-hashtag-race,How fast can you navigate from #Start_Hashtag to #End_Hashtag??,02/23/2020 13:31:35,"What it does

Queries Twitter based on 'start' / 'finish' hashtags and returns the most common hashtags included in tweets with the input tags.  The user can then click through the returned values in an effort to navigate from #start to #finish.

How we built it

Fueled by Redbull

Challenges we ran into

Linking returned hashtags into HTML/CSS with Flask (which we'd never used before)

Accomplishments that we're proud of

We had no idea what to hack out when we arrived and in a matter of 24 LONG hours, we came up with a creative, engaging, interesting, and entertaining concept.  And we've nearly got a fully functioning product.

What we learned

Sleep deprivation affects productivity

What's next for Twitter Hashtag Race

Implement ads so we can afford the professional Twitter API and rework the gameplay/UX into there intended form.
",,http://www.github.com/pai-sho/the-race,,"twitter, api, python, flask, css, html",CU Boulder,"","","",stev2368,Stephen,Evans,stev2368@colorado.edu,University of Colorado at Boulder,1,Pai-Sho,Pai-Sho,,jackhessburg94@gmail.com
Best Use of Adobe XD,Twitter Hashtag Race,https://hackcu-vi.devpost.com/submissions/143200-twitter-hashtag-race,How fast can you navigate from #Start_Hashtag to #End_Hashtag??,02/23/2020 13:31:35,"What it does

Queries Twitter based on 'start' / 'finish' hashtags and returns the most common hashtags included in tweets with the input tags.  The user can then click through the returned values in an effort to navigate from #start to #finish.

How we built it

Fueled by Redbull

Challenges we ran into

Linking returned hashtags into HTML/CSS with Flask (which we'd never used before)

Accomplishments that we're proud of

We had no idea what to hack out when we arrived and in a matter of 24 LONG hours, we came up with a creative, engaging, interesting, and entertaining concept.  And we've nearly got a fully functioning product.

What we learned

Sleep deprivation affects productivity

What's next for Twitter Hashtag Race

Implement ads so we can afford the professional Twitter API and rework the gameplay/UX into there intended form.
",,http://www.github.com/pai-sho/the-race,,"twitter, api, python, flask, css, html",CU Boulder,"","","",stev2368,Stephen,Evans,stev2368@colorado.edu,University of Colorado at Boulder,1,Pai-Sho,Pai-Sho,,jackhessburg94@gmail.com
MLH: Best Use of Google Cloud,Indian Premier League Visualizations,https://hackcu-vi.devpost.com/submissions/143201-indian-premier-league-visualizations,Visually understand the statistics of matches played in IPL,02/23/2020 13:31:39,"Inspiration

As every match played is considered important and in general, any sports team would like to know the favorable conditions which can help them to win. Here we tried to know the stats and win/loss conditions for multiple combinations ranging from the venue, teams, runs etc. These visualizations with enormous filters will help the team to chose accordingly making all the possible favorable conditions.

What it does

The final visualization in kibana, will give an overall idea among different seasons information on the number of wins, number of wickets, number of runs and each team scorecard. Thus, we can understand the holistic behavior of each team with the respective season.

How we built it

The brief description of the entire pipeline would be as follows-
The data from the local computer has been uploaded to Google Storage Bucket using Command Line Interface. Then, it was passed on to Google Pub/Sub platform using Google Cloud Dataflow which was again using the CLI platform. The content from the events as messages on Pub/Sub has been extracted using Google Cloud Functions along with integrating Google Maps API. The load balancer then handles the incoming traffic and sends it onto one of the two Google Compute Engines or the instances. These are finally computed on the Kibana platform to generate the required visualizations.

Challenges we ran into

The data that has to be uploaded from local PC to the Google Cloud Platform has been cumbersome as there were around 180000 json files that have to be sent as messages to Google Pub/Sub. So, instead of directing those files to Pub/Sub, we had to first store it on Google Storage Bucket. Even uploading files to the Bucket has not been possible using GCP Web UI and we had to switch to using Command Line Interface instead of Web UI.

Accomplishments that we're proud of

Before starting the hackathon, none of our team members were aware of the Google Cloud Platform. In a single day, all of us were able to understand the ins and outs of few of the GCP platforms that we used for the development of our project which was Google Storage, Google DataFlow, Google Pub/Sub, Google Compute Engine, Load Balancer and also using these with the help of Command Line Interface and not solely depending on the Web UI. We also were able to connect the dots of how we integrate and use each of these platforms with one another.

What we learned

We have learned to incorporate Google Cloud Platform in visualizing the stats of the player and the teams from which we can determine the accuracy of the team win.we also have learned to work collectively as team.we got to collaborate with a lot of other team members from which we have got a lot of inspiration and lot of knowledge.

What's next for Indian Premier League Visualizations

.In order, to have a better visualization. The next steps are to get the data of each player by the team. The player data will contain his strength in the game, batting style, bowling style as well as the past history of the players since the game inception in India. Based on the data, we plan to analyze each player's previous scoring history and provide the how well the player can do better based on circumstances.
",,https://github.com/AbhiniveshP/IIMO-HackCU,,"python, gcp, serverless, elasticsearch, kibana, bash, cloud, compute, google-storage, google-compute-engine, google-data-flow, google-pubsub, google-loadbalancer, google-cloud-functions",University of Colorado Boulder,"","",Google Cloud,nithinveer,Nithin Veer Reddy,Kankanti,nithinveer@iitj.ac.in,University of Colorado at Boulder,3,lokinsaimakkena,Lokin Sai,Makkena,lokinsaimakkena@gmail.com,abhiniveshpalusa,ABHINIVESH,PALUSA,abhinivesh.palusa@colorado.edu,modw1211,MOHAN,DWARAMPUDI,modw1211@colorado.edu
All Beginner,Indian Premier League Visualizations,https://hackcu-vi.devpost.com/submissions/143201-indian-premier-league-visualizations,Visually understand the statistics of matches played in IPL,02/23/2020 13:31:39,"Inspiration

As every match played is considered important and in general, any sports team would like to know the favorable conditions which can help them to win. Here we tried to know the stats and win/loss conditions for multiple combinations ranging from the venue, teams, runs etc. These visualizations with enormous filters will help the team to chose accordingly making all the possible favorable conditions.

What it does

The final visualization in kibana, will give an overall idea among different seasons information on the number of wins, number of wickets, number of runs and each team scorecard. Thus, we can understand the holistic behavior of each team with the respective season.

How we built it

The brief description of the entire pipeline would be as follows-
The data from the local computer has been uploaded to Google Storage Bucket using Command Line Interface. Then, it was passed on to Google Pub/Sub platform using Google Cloud Dataflow which was again using the CLI platform. The content from the events as messages on Pub/Sub has been extracted using Google Cloud Functions along with integrating Google Maps API. The load balancer then handles the incoming traffic and sends it onto one of the two Google Compute Engines or the instances. These are finally computed on the Kibana platform to generate the required visualizations.

Challenges we ran into

The data that has to be uploaded from local PC to the Google Cloud Platform has been cumbersome as there were around 180000 json files that have to be sent as messages to Google Pub/Sub. So, instead of directing those files to Pub/Sub, we had to first store it on Google Storage Bucket. Even uploading files to the Bucket has not been possible using GCP Web UI and we had to switch to using Command Line Interface instead of Web UI.

Accomplishments that we're proud of

Before starting the hackathon, none of our team members were aware of the Google Cloud Platform. In a single day, all of us were able to understand the ins and outs of few of the GCP platforms that we used for the development of our project which was Google Storage, Google DataFlow, Google Pub/Sub, Google Compute Engine, Load Balancer and also using these with the help of Command Line Interface and not solely depending on the Web UI. We also were able to connect the dots of how we integrate and use each of these platforms with one another.

What we learned

We have learned to incorporate Google Cloud Platform in visualizing the stats of the player and the teams from which we can determine the accuracy of the team win.we also have learned to work collectively as team.we got to collaborate with a lot of other team members from which we have got a lot of inspiration and lot of knowledge.

What's next for Indian Premier League Visualizations

.In order, to have a better visualization. The next steps are to get the data of each player by the team. The player data will contain his strength in the game, batting style, bowling style as well as the past history of the players since the game inception in India. Based on the data, we plan to analyze each player's previous scoring history and provide the how well the player can do better based on circumstances.
",,https://github.com/AbhiniveshP/IIMO-HackCU,,"python, gcp, serverless, elasticsearch, kibana, bash, cloud, compute, google-storage, google-compute-engine, google-data-flow, google-pubsub, google-loadbalancer, google-cloud-functions",University of Colorado Boulder,"","",Google Cloud,nithinveer,Nithin Veer Reddy,Kankanti,nithinveer@iitj.ac.in,University of Colorado at Boulder,3,lokinsaimakkena,Lokin Sai,Makkena,lokinsaimakkena@gmail.com,abhiniveshpalusa,ABHINIVESH,PALUSA,abhinivesh.palusa@colorado.edu,modw1211,MOHAN,DWARAMPUDI,modw1211@colorado.edu
"",Doki Doki CU Story!~,https://hackcu-vi.devpost.com/submissions/143202-doki-doki-cu-story,A dating simulator featuring some of the University of Colorado's best characters! Find the perfect dorm in this short and sweet adventure that unfolds in your first year on campus.,02/23/2020 13:33:19,"Inspiration

Test

What it does

Test

How I built it

Test

Challenges I ran into

Test

Accomplishments that I'm proud of

test

What I learned

test

What's next for Doki Doki CU Story!~

test
",,https://drive.google.com/drive/folders/1JGoJJAnhPNbQ84M2fb65j4E7srDi3MQW?usp=sharing,,"c#, unity, yarn-spinner, google-docs, photoshop, paint-tool-sai, procreate",University of Colorado: Boulder,"","","",michalbodzianowski,Michal,Bodzianowski,michal.bodzianowski@colorado.edu,University of Colorado at Boulder,0
Dish Network Challenge,Go Anonymous ,https://hackcu-vi.devpost.com/submissions/143203-go-anonymous,"Have you ever wished you could post a personal problem, question or even a classroom discussion where u can anonymously post your data u wish you want to share and seek help from other. Well here u go",02/23/2020 13:34:32,"Inspiration - inspiration from Dish Network Challenge. also, to help people who has social awkwardness and wanted others to help them being anonymous.

What it does-  asks user to input the data or a question, secondly posts the data into twitter by a anonymous user. people can see the data or question posted and can comment on it without knowing who actually asked or posted the question.

How we built it-

We used
Python flask api for hosting a webserver to consume data from user and post it anonymously on twitter using a twitter-bot. All rest calls for twitter api have been made using python tweepy api. The sentiment analysis on replies received on anonymous tweets is achieved using NLP module in python. 

Challenges we ran into-  nlp on recieved  replies on twitter. also posting web server

Accomplishments that we're proud of- sucessfully completed the objective and project

What we learned- more about nlp and data anonymization

What's next for Go Anonymous

building more efficient way of user anonymity with more security.
",https://www.youtube.com/watch?v=nT0SbW0cVAY&feature=youtu.be,https://github.com/MridulaBontha/HackCU-2020,,"c#, python, natural-language-processing",Colorado State University,"","","",rohitrohitg17,rohit,Gorle,rohit.rohitg17@gmail.com,Colorado State University,3,HariHaraKumar,,,rhariharakumar9@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com,suj1995,Suraj,Eswaran,suj1995@gmail.com
Most Creative Usage of Twitter API,Go Anonymous ,https://hackcu-vi.devpost.com/submissions/143203-go-anonymous,"Have you ever wished you could post a personal problem, question or even a classroom discussion where u can anonymously post your data u wish you want to share and seek help from other. Well here u go",02/23/2020 13:34:32,"Inspiration - inspiration from Dish Network Challenge. also, to help people who has social awkwardness and wanted others to help them being anonymous.

What it does-  asks user to input the data or a question, secondly posts the data into twitter by a anonymous user. people can see the data or question posted and can comment on it without knowing who actually asked or posted the question.

How we built it-

We used
Python flask api for hosting a webserver to consume data from user and post it anonymously on twitter using a twitter-bot. All rest calls for twitter api have been made using python tweepy api. The sentiment analysis on replies received on anonymous tweets is achieved using NLP module in python. 

Challenges we ran into-  nlp on recieved  replies on twitter. also posting web server

Accomplishments that we're proud of- sucessfully completed the objective and project

What we learned- more about nlp and data anonymization

What's next for Go Anonymous

building more efficient way of user anonymity with more security.
",https://www.youtube.com/watch?v=nT0SbW0cVAY&feature=youtu.be,https://github.com/MridulaBontha/HackCU-2020,,"c#, python, natural-language-processing",Colorado State University,"","","",rohitrohitg17,rohit,Gorle,rohit.rohitg17@gmail.com,Colorado State University,3,HariHaraKumar,,,rhariharakumar9@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com,suj1995,Suraj,Eswaran,suj1995@gmail.com
Most Random,Phone Virtual Reality Skiing! With Wii Fit Board,https://hackcu-vi.devpost.com/submissions/143204-phone-virtual-reality-skiing-with-wii-fit-board,"You can launch your phone, strap on the google vr cardboard, grab your wii fit board and shred that gnar!",02/23/2020 13:34:42,"Inspiration

We had a Wii fit board and wanted to make a snowboarding game.

What it does

So far you can ride the slopes with the wii fit board almost sending data to the phone via bluetooth.

How I built it

Built in unity.

Accomplishments that we are proud of

Having the google vr work with our set-up

What's next for Phone Virtual Reality Skiing! With Controllers

Adding more features with the wii fit board!
",,https://github.com/Zoolouie/SnoWii,,"unity, wiifitboard, phone, google-cardboard",University Of Colorado Boulder,"","","",Richard-Dudley-Ortecho,Richard Dudley,Ortecho,dudley.o@hotmail.com,University of Colorado at Boulder,1,Zoolouie,Zander,Louie,allo1877@colorado.edu
Empowering Underrepresented People in Tech,Just Caption This,https://hackcu-vi.devpost.com/submissions/143205-just-caption-this,Let us create a caption/description of any image on Twitter!,02/23/2020 13:35:08,"Inspiration

Most of the content on social media is displayed on images. Unfortunately not everybody is able to see and therefore enjoy the content that is published. Nowadays there are several screen reading solutions that allow vision-impaired individuals to listen to what is written on the web. But what about images?

We felt it was for the benefit of those individuals to create a real-time solution that allowed them to know what the image in question is about, without depending on someone else to describe it for them, increasing their independence, helping them to see. 

What it does

When our twitter bot (@JustCaptionThis) is mentioned in a publication, or a thread containing an image, it will post a reply with a written description of the image. In addition to describing the objects present in the image, the tool can also recognize when there is text present and read the text out of the image into a format that is more accessible for the visually impaired.

How we built it

We first created a Twitter profile and an app to automate the whole process.

We used Twitter's Streaming API through the Tweepy library to get a real-time feed of new tweets that mention our profile (@JustCaptionThis). We identified whether those tweets had an image, or were a response to a tweet with an image, part of a longer thread.

Using Machine Learning the image is processed and a description is generated.

That description is then posted as a response to the tweet that mentioned us (@JustCaptionThis).

Challenges we ran into

Creating and giving permission to the Twitter app to the Twitter profile @JustCaptionThis.

Identifying the image that the user requesting a caption is referring to.

Integrating the Neural Network into the python code controlling the twitter action.

Accomplishments that we're proud of

Creating something useful for people with impaired vision, we like to thinl we have been able to improve someone's life.

Working with the Twitter API and getting a bot to worksuccessfully. One of our hackers didn't even have a twitter account!

Combining Machine Learning with Social Media.

What's next for Just Caption This

Train the neural network model on Twitter data and keep it up to date with advancements in image recognition!

Add a “sing to me” extension that generates lyrics based on the caption.
",https://youtu.be/ZAD6TTpu1GI,https://ctt.ac/9kHbc,,"python, tweepy, twitter, tesseract, pandas, numpy, densecap, bot","University of Colorado Boulder, University of California Irvine","","","",joseales,Jose Alejandro,Santamaría,joseales@uci.edu,"cu boulder, University of Colorado at Boulder",3,polmes,Pol,Mesalles,pol.air1@gmail.com,Janscode,Janscode,Chang,jan.chang@colorado.edu,oscarfuentesmunoz,Oscar,Fuentes Muñoz,oscar.fuentesmunoz@colorado.edu
Most Creative Usage of Twitter API,Just Caption This,https://hackcu-vi.devpost.com/submissions/143205-just-caption-this,Let us create a caption/description of any image on Twitter!,02/23/2020 13:35:08,"Inspiration

Most of the content on social media is displayed on images. Unfortunately not everybody is able to see and therefore enjoy the content that is published. Nowadays there are several screen reading solutions that allow vision-impaired individuals to listen to what is written on the web. But what about images?

We felt it was for the benefit of those individuals to create a real-time solution that allowed them to know what the image in question is about, without depending on someone else to describe it for them, increasing their independence, helping them to see. 

What it does

When our twitter bot (@JustCaptionThis) is mentioned in a publication, or a thread containing an image, it will post a reply with a written description of the image. In addition to describing the objects present in the image, the tool can also recognize when there is text present and read the text out of the image into a format that is more accessible for the visually impaired.

How we built it

We first created a Twitter profile and an app to automate the whole process.

We used Twitter's Streaming API through the Tweepy library to get a real-time feed of new tweets that mention our profile (@JustCaptionThis). We identified whether those tweets had an image, or were a response to a tweet with an image, part of a longer thread.

Using Machine Learning the image is processed and a description is generated.

That description is then posted as a response to the tweet that mentioned us (@JustCaptionThis).

Challenges we ran into

Creating and giving permission to the Twitter app to the Twitter profile @JustCaptionThis.

Identifying the image that the user requesting a caption is referring to.

Integrating the Neural Network into the python code controlling the twitter action.

Accomplishments that we're proud of

Creating something useful for people with impaired vision, we like to thinl we have been able to improve someone's life.

Working with the Twitter API and getting a bot to worksuccessfully. One of our hackers didn't even have a twitter account!

Combining Machine Learning with Social Media.

What's next for Just Caption This

Train the neural network model on Twitter data and keep it up to date with advancements in image recognition!

Add a “sing to me” extension that generates lyrics based on the caption.
",https://youtu.be/ZAD6TTpu1GI,https://ctt.ac/9kHbc,,"python, tweepy, twitter, tesseract, pandas, numpy, densecap, bot","University of Colorado Boulder, University of California Irvine","","","",joseales,Jose Alejandro,Santamaría,joseales@uci.edu,"cu boulder, University of Colorado at Boulder",3,polmes,Pol,Mesalles,pol.air1@gmail.com,Janscode,Janscode,Chang,jan.chang@colorado.edu,oscarfuentesmunoz,Oscar,Fuentes Muñoz,oscar.fuentesmunoz@colorado.edu
Empowering Underrepresented People in Tech,ProjectCodeEmpower,https://hackcu-vi.devpost.com/submissions/143206-projectcodeempower,"ProjectEmpowerCode is a website that aims to educate children ages 8-10 about Computer Science. The target demographic is at-risk, lower-income communities and underrepresented communities in CS.",02/23/2020 13:39:17,"Inspiration
  We were inspired to complete this project after seeing that many students from underrepresented communities accross the country were not exposed to Computer Science and we wanted to change this by exposing younger kids to this field through a website.

What it does

ProjectCodeEmpower has a landing page which explains how the website works simply, an introduction to CS page which will have a video with people from nontraditional backgrounds in CS explaining how they got into CS, five lesson modules that students use to navigate the learning expirence using blockly, and four games that the kids can play after learning how code works. We also have an about us page, contact us page, and mission statement page with our values. 

How we built it
We built this website using HTML, CSS, JavaScript, and used code from Blockly to build the foundations of our website. Much of the content development was done by a psychology student for the lesson plans and another student took charge of writing the other pages. 

Challenges we ran into
 We did not know HTML, JavaScript, CSS so we needed to learn these languages. We also had to learn how to use Blockly to best target our audience. We also ran into the issue of not knowing how to write for the age group we are targeting. 

Accomplishments that we're proud of
 Being able to have something ready to present, even if it is not a finalized product.

What we learned
 We learned HTML, JavaScript, CSS, and GitHub languages as well as how to use Blockly and how to format lessons for our target audience

What's next for ProjectCodeEmpower
 Finalizing our website and getting people aware about our project as well as conducting more research on how students of this age group best learn Computer Science. We will also be doing outreach to Denver Public Schools and schools in Northern New Mexico.
",,https://github.com/AM-Mahon/ProjectCodeEmpower,,"html, javascript, css, blockly",University of Colorado at Boulder,"","","",mjk7817,mjk7817,Jammu,maigh.jammu@colorado.edu,University of Colorado at Boulder,2,Birdfeathers,Rebecca,Carr,reca9238@colorado.edu,AM-Mahon,AM-Mahon,,annmarie.mahon@colorado.edu
Best Use of TapWithUS SDK,TapWithUsHackCU,https://hackcu-vi.devpost.com/submissions/143207-tapwithushackcu,"A small game to strike a heart with the Tap. UsingTap, break hearts.",02/23/2020 13:39:49,"Inspiration

Tap was a great device and a greater motivation by itself to work with it

What it does

A game to strike and break hearts

How I built it

Web Application and a Windows form application

Challenges I ran into

A lmyriad of challanges to work with window for applications

Accomplishments that I'm proud of

Successfully worked with a new hardware and integrated it. Was succesfully able to build a Windows form application which I have never done before and had a very little idea about.

What I learned

Intergrating new hardware, working with Windows form application. Most Importantly GOOGLING

What's next for TapWithUsHackCU

Provide more and features with accuracy as well
",,,,"asp.net, asp.net-core",Colorado State University,C#,"","",vishalbangalore26,Vishal,Anandamani,vishalbangalore26@gmail.com,Colorado State University,0
Best Use of TapWithUS SDK,RUBIKS CUBE  USING TAP AIRMOUSE,https://hackcu-vi.devpost.com/submissions/143208-rubiks-cube-using-tap-airmouse,Using TAP Airmouse for  solving Rubiks cube ( 3D ),02/23/2020 13:41:47,"Inspiration

I used to solve the Rubiks cube under a minute. I always wondered how it would be to solve it virtually. This thought led to the development of this project.

What it does

This application helps users to play rubiks cube for fun virtually.

How we built it

We developed it using Unity and C#. The best part of this project is integrating it with TAP SDK.

Challenges we ran into

We had tough time as our project idea initially included integrating this project with VR. We had to change the entire project we failed in getting a VR headset.

Accomplishments that we're proud of

Learnt a new technology/ framework under 18 hrs. 

What we learned


A new SDK
Making bigger projects out of smaller ones.
## What's next for RUBIKS CUBE  USING TAP AIRMOUSE
We already tried to automate the solving procedure but given the time frame, we could achieve it only till 2 layers and so we have to rollback this feature. Adding the previous feature will be the first improvement. Also, if we can manage this project with 2 TAP devices, it will be great as we can record gestures as if we are holding a cube in hand.

",,,,"",Colorado State University,"","","",suj1995,Suraj,Eswaran,suj1995@gmail.com,Colorado State University,2,HariHaraKumar,,,rhariharakumar9@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com
Best UX/UI,RUBIKS CUBE  USING TAP AIRMOUSE,https://hackcu-vi.devpost.com/submissions/143208-rubiks-cube-using-tap-airmouse,Using TAP Airmouse for  solving Rubiks cube ( 3D ),02/23/2020 13:41:47,"Inspiration

I used to solve the Rubiks cube under a minute. I always wondered how it would be to solve it virtually. This thought led to the development of this project.

What it does

This application helps users to play rubiks cube for fun virtually.

How we built it

We developed it using Unity and C#. The best part of this project is integrating it with TAP SDK.

Challenges we ran into

We had tough time as our project idea initially included integrating this project with VR. We had to change the entire project we failed in getting a VR headset.

Accomplishments that we're proud of

Learnt a new technology/ framework under 18 hrs. 

What we learned


A new SDK
Making bigger projects out of smaller ones.
## What's next for RUBIKS CUBE  USING TAP AIRMOUSE
We already tried to automate the solving procedure but given the time frame, we could achieve it only till 2 layers and so we have to rollback this feature. Adding the previous feature will be the first improvement. Also, if we can manage this project with 2 TAP devices, it will be great as we can record gestures as if we are holding a cube in hand.

",,,,"",Colorado State University,"","","",suj1995,Suraj,Eswaran,suj1995@gmail.com,Colorado State University,2,HariHaraKumar,,,rhariharakumar9@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com
Sustainability,RUBIKS CUBE  USING TAP AIRMOUSE,https://hackcu-vi.devpost.com/submissions/143208-rubiks-cube-using-tap-airmouse,Using TAP Airmouse for  solving Rubiks cube ( 3D ),02/23/2020 13:41:47,"Inspiration

I used to solve the Rubiks cube under a minute. I always wondered how it would be to solve it virtually. This thought led to the development of this project.

What it does

This application helps users to play rubiks cube for fun virtually.

How we built it

We developed it using Unity and C#. The best part of this project is integrating it with TAP SDK.

Challenges we ran into

We had tough time as our project idea initially included integrating this project with VR. We had to change the entire project we failed in getting a VR headset.

Accomplishments that we're proud of

Learnt a new technology/ framework under 18 hrs. 

What we learned


A new SDK
Making bigger projects out of smaller ones.
## What's next for RUBIKS CUBE  USING TAP AIRMOUSE
We already tried to automate the solving procedure but given the time frame, we could achieve it only till 2 layers and so we have to rollback this feature. Adding the previous feature will be the first improvement. Also, if we can manage this project with 2 TAP devices, it will be great as we can record gestures as if we are holding a cube in hand.

",,,,"",Colorado State University,"","","",suj1995,Suraj,Eswaran,suj1995@gmail.com,Colorado State University,2,HariHaraKumar,,,rhariharakumar9@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com
"",!Backend,https://hackcu-vi.devpost.com/submissions/143209-backend,Generate your own Python API with the click of one button.,02/23/2020 13:42:12,"

Inspiration

Do you need an API? Are you tired of AWS and its complicated UI? API design tools can be confusing for beginners, so we set out to create the most simple backend deployment tool on the market - !Backend(pronounced not backend)

What it does

!Backend takes a URL to a public GitHub repository, and gives you a link to run the functions as API requests.



How it works

The service is built using Angular front-end web framework and Python Flask back-end framework. 
!Backend runs in the following steps:


Ask for URL input for GitHub public repository
 Send URL to a Python web server
Backend server converts the main.py from the GitHub repo to a Python Flask application
Web server returns API URL that can now call the functions of main.py


The result is an API that looks like this: http://notbacken.tec/r/<unique_uuid>/<your_python_function>/<comma,seperated,args>

When a request is sent, if uses the UUID generated from step 4 to access the correct flask server, and runs the method with the parameters specified



Challenges we ran into

Overall we where not very experienced with web development and javascript, so some simple tasks like updating a field from the result of an API call to take a long time. Additionally, we initially wanted to deploy each API to a docker container, or run them all together, and had a difficult time deciding on a design that would enable us to do that (specifically most of these tools only allow one instance bound to a specificity).

Accomplishments that we're proud of


Created an incredibly simple way to deploy Python APIs
Created an advanced backend with multiple stages and parts


What's next for !Backend


API generation depends on many factors - such as return types in the Python functions and structure of program
Security has to be handled very carefully whenever arbitrary code is being run on a server. Right now, security is not handled that way.

",,https://github.com/jakevossen5/backend-but-not,,"python, angular.js, github, node.js, flask","Colorado School of Mines, Colorado State University","","",Domain.com,caleb835,Caleb,Rotello,caleb@rotello.dev,Colorado School of Mines,1,jakevossen,Jacob,Vossen,jakevossen@jakevossen.codes
Best Use of TapWithUS SDK,Coding Chat,https://hackcu-vi.devpost.com/submissions/143210-coding-chat,Making computer science accessible to all!,02/23/2020 13:42:51,"Inspiration

As volunteers of out local Girls Who Code chapter, we noticed how much of a challenge transportation is for students, especially students that rely on school busing. So, we thought it would be very useful to create a virtual computer science school to teach interested people computer science concepts and programming skills. 

What it does

Coding Chat teaches users programming languages, educates about various aspects within the field, and provides an interactive environment to allow learners to collaborate and receive assistance.

How we built it

We developed objects in Blender, created the environment in Unity, and coded intractable features in C# via Visual Studios. 

Challenges we ran into

We're relatively to virtual reality so we ran into quite a few issues with learning how it works and how to use it. We were also too ambitious in the planning stages, so we got a bit carried away with Coding Chat's potential. 

Accomplishments that we're proud of

We're really proud of how the environment and how it looks. It is very detailed and thought out.

What we learned

We learned a ton about Unity, Oculus Rift, c#, and incorporating online documentation in our project.

What's next for Coding Chat

We only created one sample classroom but eventually we will create two more classrooms, a lobby with a help desk for students to get help with their code, and a lecture space to hold meetings where professionals will talk about their lives in computer science. On a more logistical note, we would love to incorporate teleportation so that the user is not physically required to move around the room. We also believe their is a lot of potential to incorporate Tap Technology as a keyboard and track pad for students. Overall, our goal is to make computer science accessible to all, particularly nontraditional computer science students and under represented students, and we believe with the increasing popularity trends with VR headsets, Coding Chat can have play a huge part in that. 
",,https://github.com/mw29/CodingChat,,"c#, unity, blender, visual-studio, oculus-gear-vr",Colorado State University,"","","",madelinechloe429,Madeline,Watts,madeline.chloe429@gmail.com,Colorado State University,1,arysaflores,Arysa,Flores,arysaflores@gmail.com
Empowering Underrepresented People in Tech,Coding Chat,https://hackcu-vi.devpost.com/submissions/143210-coding-chat,Making computer science accessible to all!,02/23/2020 13:42:51,"Inspiration

As volunteers of out local Girls Who Code chapter, we noticed how much of a challenge transportation is for students, especially students that rely on school busing. So, we thought it would be very useful to create a virtual computer science school to teach interested people computer science concepts and programming skills. 

What it does

Coding Chat teaches users programming languages, educates about various aspects within the field, and provides an interactive environment to allow learners to collaborate and receive assistance.

How we built it

We developed objects in Blender, created the environment in Unity, and coded intractable features in C# via Visual Studios. 

Challenges we ran into

We're relatively to virtual reality so we ran into quite a few issues with learning how it works and how to use it. We were also too ambitious in the planning stages, so we got a bit carried away with Coding Chat's potential. 

Accomplishments that we're proud of

We're really proud of how the environment and how it looks. It is very detailed and thought out.

What we learned

We learned a ton about Unity, Oculus Rift, c#, and incorporating online documentation in our project.

What's next for Coding Chat

We only created one sample classroom but eventually we will create two more classrooms, a lobby with a help desk for students to get help with their code, and a lecture space to hold meetings where professionals will talk about their lives in computer science. On a more logistical note, we would love to incorporate teleportation so that the user is not physically required to move around the room. We also believe their is a lot of potential to incorporate Tap Technology as a keyboard and track pad for students. Overall, our goal is to make computer science accessible to all, particularly nontraditional computer science students and under represented students, and we believe with the increasing popularity trends with VR headsets, Coding Chat can have play a huge part in that. 
",,https://github.com/mw29/CodingChat,,"c#, unity, blender, visual-studio, oculus-gear-vr",Colorado State University,"","","",madelinechloe429,Madeline,Watts,madeline.chloe429@gmail.com,Colorado State University,1,arysaflores,Arysa,Flores,arysaflores@gmail.com
MLH: Best use of MongoDB Atlas,Sustainabeanity,https://hackcu-vi.devpost.com/submissions/143211-sustainabeanity,Public facing environmental impact tracker for small businesses. We used coffee shops as a proof of concept. Includes visual representations of data. ,02/23/2020 13:44:27,"Inspiration

Global climate change is shaping up to be one of the biggest issues humanity has ever faced. Everyone is contributing to it in one way or another, and everyone can help fight it. People often focus on the biggest polluters (large corporations) or the smallest ones (an individual person), but rarely does anyone talk about the people in the middle. There are thousands and thousands of stores, offices, shops, etc. that contribute to global climate change, and it might just help the cause if we could inspire managers and employees to make a difference at their place of work, however small. We started with coffeeshops as a proof of concept, as we have some insight into that industry.

What it does

A user is able to create an account for a single store. This store is able to upload metrics about different store emissions and sources of waste. All of these metrics are graphed and visualized on a unique store page.

How we built it

We used mongodb atlas and google cloud platform to host our database and express.js/node.js website. Our frontend was coded using html, css, and EJS. We used git and github for resolving conflicts among a team of three. Regex for searching and data input formatting.

Challenges we ran into

None of us have ever fully built and deployed a website with a full backend, user accounts, sessions, databases, etc. and as a result, ran into many challenges.

Accomplishments that we're proud of

We were able to deploy a pleasant and user-friendly website, create a functional database using mongodb, integrated with google cloud, create forms for user registration with encrypted salted passwords, and provide charting that updates with the database

What we learned

We all learned a lot about version control, creating dynamic websites, teamwork, and quite a lot about carbon emissions.

What's next for Sustainabeanity

Well, we would love to do quite a bit of refactoring of certain parts of the project, for example, if your passwords don't match when you try and register an account it just sends you to the home page without telling you your account creation failed. We also would love to expand the product to include all sorts of businesses at a store or office level, we would also like to give businesses average data among other stores in their industry so they can compare and contrast.
",,https://sustainabeanity.appspot.com/,,"express.js, node.js, mongodb, google-cloud, html5, css3, javascript, github, git, ejs",CU Boulder,"","",Google Cloud,nickwroble23,Nicholas,Wroblewski,nickwroble23@gmail.com,University of Colorado at Boulder,2,bouldercoder9,Alex,Mazur,alma9011@colorado.edu,jmox0351,jmox0351,,jamo7563@colorado.edu
MLH: Best Use of Google Cloud,Sustainabeanity,https://hackcu-vi.devpost.com/submissions/143211-sustainabeanity,Public facing environmental impact tracker for small businesses. We used coffee shops as a proof of concept. Includes visual representations of data. ,02/23/2020 13:44:27,"Inspiration

Global climate change is shaping up to be one of the biggest issues humanity has ever faced. Everyone is contributing to it in one way or another, and everyone can help fight it. People often focus on the biggest polluters (large corporations) or the smallest ones (an individual person), but rarely does anyone talk about the people in the middle. There are thousands and thousands of stores, offices, shops, etc. that contribute to global climate change, and it might just help the cause if we could inspire managers and employees to make a difference at their place of work, however small. We started with coffeeshops as a proof of concept, as we have some insight into that industry.

What it does

A user is able to create an account for a single store. This store is able to upload metrics about different store emissions and sources of waste. All of these metrics are graphed and visualized on a unique store page.

How we built it

We used mongodb atlas and google cloud platform to host our database and express.js/node.js website. Our frontend was coded using html, css, and EJS. We used git and github for resolving conflicts among a team of three. Regex for searching and data input formatting.

Challenges we ran into

None of us have ever fully built and deployed a website with a full backend, user accounts, sessions, databases, etc. and as a result, ran into many challenges.

Accomplishments that we're proud of

We were able to deploy a pleasant and user-friendly website, create a functional database using mongodb, integrated with google cloud, create forms for user registration with encrypted salted passwords, and provide charting that updates with the database

What we learned

We all learned a lot about version control, creating dynamic websites, teamwork, and quite a lot about carbon emissions.

What's next for Sustainabeanity

Well, we would love to do quite a bit of refactoring of certain parts of the project, for example, if your passwords don't match when you try and register an account it just sends you to the home page without telling you your account creation failed. We also would love to expand the product to include all sorts of businesses at a store or office level, we would also like to give businesses average data among other stores in their industry so they can compare and contrast.
",,https://sustainabeanity.appspot.com/,,"express.js, node.js, mongodb, google-cloud, html5, css3, javascript, github, git, ejs",CU Boulder,"","",Google Cloud,nickwroble23,Nicholas,Wroblewski,nickwroble23@gmail.com,University of Colorado at Boulder,2,bouldercoder9,Alex,Mazur,alma9011@colorado.edu,jmox0351,jmox0351,,jamo7563@colorado.edu
Sustainability,Sustainabeanity,https://hackcu-vi.devpost.com/submissions/143211-sustainabeanity,Public facing environmental impact tracker for small businesses. We used coffee shops as a proof of concept. Includes visual representations of data. ,02/23/2020 13:44:27,"Inspiration

Global climate change is shaping up to be one of the biggest issues humanity has ever faced. Everyone is contributing to it in one way or another, and everyone can help fight it. People often focus on the biggest polluters (large corporations) or the smallest ones (an individual person), but rarely does anyone talk about the people in the middle. There are thousands and thousands of stores, offices, shops, etc. that contribute to global climate change, and it might just help the cause if we could inspire managers and employees to make a difference at their place of work, however small. We started with coffeeshops as a proof of concept, as we have some insight into that industry.

What it does

A user is able to create an account for a single store. This store is able to upload metrics about different store emissions and sources of waste. All of these metrics are graphed and visualized on a unique store page.

How we built it

We used mongodb atlas and google cloud platform to host our database and express.js/node.js website. Our frontend was coded using html, css, and EJS. We used git and github for resolving conflicts among a team of three. Regex for searching and data input formatting.

Challenges we ran into

None of us have ever fully built and deployed a website with a full backend, user accounts, sessions, databases, etc. and as a result, ran into many challenges.

Accomplishments that we're proud of

We were able to deploy a pleasant and user-friendly website, create a functional database using mongodb, integrated with google cloud, create forms for user registration with encrypted salted passwords, and provide charting that updates with the database

What we learned

We all learned a lot about version control, creating dynamic websites, teamwork, and quite a lot about carbon emissions.

What's next for Sustainabeanity

Well, we would love to do quite a bit of refactoring of certain parts of the project, for example, if your passwords don't match when you try and register an account it just sends you to the home page without telling you your account creation failed. We also would love to expand the product to include all sorts of businesses at a store or office level, we would also like to give businesses average data among other stores in their industry so they can compare and contrast.
",,https://sustainabeanity.appspot.com/,,"express.js, node.js, mongodb, google-cloud, html5, css3, javascript, github, git, ejs",CU Boulder,"","",Google Cloud,nickwroble23,Nicholas,Wroblewski,nickwroble23@gmail.com,University of Colorado at Boulder,2,bouldercoder9,Alex,Mazur,alma9011@colorado.edu,jmox0351,jmox0351,,jamo7563@colorado.edu
Best Use of TapWithUS SDK,Tap Invaders,https://hackcu-vi.devpost.com/submissions/143213-tap-invaders,Tap Invaders uses the Tap Wearable Keyboard for an augmented game of Space Invaders displayed on an LED matrix. ,02/23/2020 13:45:03,"Inspiration for Tap Invaders

We played Star Wars Jedi Knight: Jedi Academy using the Tap Wearable Keyboard whilst brainstorming for ideas. This inspired us to create a space shooter game with which we could use the Tap. Since we wanted to also make a custom interface, we decided to create a game of Space Invaders.

What it does

Tap Invaders uses the Tap Keyboard. The user must shoot at the aliens which appear on a 7x7 LED matrix.

How we built it

The project consists of three aspects which we divided amongst the group members:

• The Space Invaders Game
• The LED matrix
• The Tap Keyboard

The Game

This game of space invaders was created with the Tap in mind (the game is much slower paced than the actual one). The game utilizes a state machine to keep track of game progress.
The aliens descend 10 seconds at a time between each row, giving the user the time to shoot. If the player successfully destroys an alien, the LED associated with it turns off. If the player destroys all of them, they emerge victorious. However, if all aliens descend before the player can hit them all, the game is lost.  

The LED matrix

The matrix is made of a 7x7 grid of NeoPixel LEDs which can be individually controlled. It is driven by an Arduino Uno which receives commands from the serial terminal on the computer which in turn receives inputs from the Tap. Since these are RGB LEDs, the aliens are represented by red LEDs that are all in line. The player is represented by a single green LED which can move across the first row. When the player shoots, a single LED moves up across the matrix towards the aliens.

The Tap Keyboard

The Tap Keyboard was developed in Visual Studio 2019 using its SDK. The keyboard uses the IDE's debugger in which it outputs characters depending on the user's gestures. This is then sent to the Arduino terminal which interprets the command. The different gestures that are used are:
-Swipe left/right: this makes the user move on their row
-Point and move up: this acts as the shoot

Challenges we ran into

Our main challenge that we ran into was familiarizing ourselves with the Tap Keyboard, since this is a device that we had never used before. We also didn't know exactly how to use Visual Studio 2019 which had a learning curve. However, after using over the past day, we became more confident in our actions and made significant progress in our code.

Accomplishments that we are proud of

We are proud of having been able to figure out how to make the Tap Keyboard interface with the Arduino to control the game of Space Invaders. We are also proud of having been able to write the the logic for the Space Invaders state machine

What we learned

Since this project used not only a hardware interface but a software one as well, we learned a lot about how to make the two work together, which was something that we hadn't worked much on before. We also refined our skills in areas such as state machines, and hardware debugging, which both have applications in many areas.

What's next for Tap Invaders

We hope to create a bigger matrix for Tap Invaders and maybe incorporate other games for it.
",,,,"c#, arduino, c++, tapstrap, visual-studio, neopixel, leds",University of Colorado at Boulder,"","","",PSCurlin,Phaedra,Curlin,phaedra.curlin@outlook.fr,"University of Colorado at Boulder, Tunxis Community College",2,sialia,Giselle,Koo,gisellegk@gmail.com,atharvanandanwar,Atharva,Nandanwar,atharva.nandanwar@colorado.edu
MLH: Best Domain Registered with Domain.com,Hacks For Health,https://hackcu-vi.devpost.com/submissions/143214-hacks-for-health,"A program that tracks disease outbreaks for hospitals and doctors in hopes of preventing future outbreaks, along with informing the public in hopes that preventative measures will be taken.",02/23/2020 13:45:16,"Inspiration

Surprisingly this idea was not inspired by the 2019 novel Corona virus but rather seeing many small outbreaks of of old, but very preventable disease such as chicken pox, measles and the flu. These diseases hurt and kill more people than the Corona virus but are not given as much attention. We thought this project could bring attention to these other illnesses again.

What it does

Our project was designed to help hospitals and doctors track infectious diseases in their patients. Our website is designed for doctors to enter patients’ information (the disease, how long they have had it, and the city/cities they have been to).  This data will be converted to a text file and then processed and summarized.  The summary of the data which includes the city, the list of diseases within that city, and the total number of sick people is sent to the GUI which displays the general information to the public to show what diseases there are and hopefully raise awareness.  The cities we chose to display are based around our team members’ hometowns.

How I built it

We divided work load into front end and back end. Eileen and Edge worked on the front end and Megan and Maggie worked on the back in.
There was a lot of collaboration about how we would share the data, what data needed to be collected from the user, and how the data should be processed to get to the viewers end.
Maggie and Megan's back end was given patient focused data from Eileen's Doctor portal, the back end then processed this data to be location focused so it could be shared with Edge's public app. This way the private patient data is protected from being seen by the public but the public is still aware of health threats in their area.
During our time at hackCU we failed to actually connect the front and back ends but this problem will be worked on in the future.

Challenges we ran into

Some challenges we ran into were linking the front end to the back end.
Another issue was when developing the back end we had to keep in mind that the data input would be coming from a doctor who was focusing on an individual, but this input format was not the most convenient for the information we wanted to display. So we had to reprocess the data into different structures that were better for our output display.

Accomplishments that I'm proud of

We are proud of ourselves for going out of our comfort zones and skill levels. We worked together as a team unit and supported one another. We managed to create a project of our own idea that is bigger than anything we've created before.

What I learned

Eileen learned a lot about web development such as HTML, JavaScript, and CSS. She also grew her knowledge of GitHub.
Maggie researched about databases and API's, she had fun exploring this new topic that none of us were brave to explore ourselves.
Edge learned how to use swing GUI variables in netBeans IDE, how to incorporate threads in swing variable implementation. Overall he explored how to develop a UI for the user experience.
Megan worked on her critical thinking and problem solving skills when planning how each part of the project would be tied together. She developed her skills with object oriented programming and algorithms.

What's next for Hacks For Health

Long term and on a large scale, the data would be entered and stored in database A (patient info) for doctors and hospitals to look at and track.  The hope is that the hospitals and doctors can use this data to better prevent disease outbreaks in real time.  The data in database A will then be summarized and condensed to the total number of infected people and the lists of diseases for each city.  This is then sent to database B (reduced, public data) for our GUI read from and display.  When a doctor adds a new patient to database A, database B would be updated to include the new patient in the overall summary for that patient’s city.  The GUI will then display the newly calculated data.  We hope that our project will raise awareness about different diseases and inspire people to take preventative measures.
",,,,"java, html5, javascript, css3",Colorado State University,hackforhealth.tech,"",Domain.com,MaggieFunston,Maggie,Funston,maggie.funston@gmail.com,Colorado State University,0
All Beginner,Hacks For Health,https://hackcu-vi.devpost.com/submissions/143214-hacks-for-health,"A program that tracks disease outbreaks for hospitals and doctors in hopes of preventing future outbreaks, along with informing the public in hopes that preventative measures will be taken.",02/23/2020 13:45:16,"Inspiration

Surprisingly this idea was not inspired by the 2019 novel Corona virus but rather seeing many small outbreaks of of old, but very preventable disease such as chicken pox, measles and the flu. These diseases hurt and kill more people than the Corona virus but are not given as much attention. We thought this project could bring attention to these other illnesses again.

What it does

Our project was designed to help hospitals and doctors track infectious diseases in their patients. Our website is designed for doctors to enter patients’ information (the disease, how long they have had it, and the city/cities they have been to).  This data will be converted to a text file and then processed and summarized.  The summary of the data which includes the city, the list of diseases within that city, and the total number of sick people is sent to the GUI which displays the general information to the public to show what diseases there are and hopefully raise awareness.  The cities we chose to display are based around our team members’ hometowns.

How I built it

We divided work load into front end and back end. Eileen and Edge worked on the front end and Megan and Maggie worked on the back in.
There was a lot of collaboration about how we would share the data, what data needed to be collected from the user, and how the data should be processed to get to the viewers end.
Maggie and Megan's back end was given patient focused data from Eileen's Doctor portal, the back end then processed this data to be location focused so it could be shared with Edge's public app. This way the private patient data is protected from being seen by the public but the public is still aware of health threats in their area.
During our time at hackCU we failed to actually connect the front and back ends but this problem will be worked on in the future.

Challenges we ran into

Some challenges we ran into were linking the front end to the back end.
Another issue was when developing the back end we had to keep in mind that the data input would be coming from a doctor who was focusing on an individual, but this input format was not the most convenient for the information we wanted to display. So we had to reprocess the data into different structures that were better for our output display.

Accomplishments that I'm proud of

We are proud of ourselves for going out of our comfort zones and skill levels. We worked together as a team unit and supported one another. We managed to create a project of our own idea that is bigger than anything we've created before.

What I learned

Eileen learned a lot about web development such as HTML, JavaScript, and CSS. She also grew her knowledge of GitHub.
Maggie researched about databases and API's, she had fun exploring this new topic that none of us were brave to explore ourselves.
Edge learned how to use swing GUI variables in netBeans IDE, how to incorporate threads in swing variable implementation. Overall he explored how to develop a UI for the user experience.
Megan worked on her critical thinking and problem solving skills when planning how each part of the project would be tied together. She developed her skills with object oriented programming and algorithms.

What's next for Hacks For Health

Long term and on a large scale, the data would be entered and stored in database A (patient info) for doctors and hospitals to look at and track.  The hope is that the hospitals and doctors can use this data to better prevent disease outbreaks in real time.  The data in database A will then be summarized and condensed to the total number of infected people and the lists of diseases for each city.  This is then sent to database B (reduced, public data) for our GUI read from and display.  When a doctor adds a new patient to database A, database B would be updated to include the new patient in the overall summary for that patient’s city.  The GUI will then display the newly calculated data.  We hope that our project will raise awareness about different diseases and inspire people to take preventative measures.
",,,,"java, html5, javascript, css3",Colorado State University,hackforhealth.tech,"",Domain.com,MaggieFunston,Maggie,Funston,maggie.funston@gmail.com,Colorado State University,0
MLH: Best use of MongoDB Atlas,Catscan,https://hackcu-vi.devpost.com/submissions/143216-catscan,"A fun game where you earn points by taking pictures, cats are worth the most! Compete with your friends to get the top (or bottom) score!",02/23/2020 13:46:53,"Inspiration

We wanted to incorporate computer vision into an app and the first idea was just taking pictures of cats.

What it does

Catscan is a fun game where users take pictures of whatever they want and are given points based on what the subject of the picture is.

Challenges we ran into

Integrating the front and back ends, using MongoDB which 2 of us were unfamiliar with.

Accomplishments that we're proud of

Creating a fun game based on a random idea

What's next for Catscan

Assigning point values to other types of pictures
",,,,"mongodb, react-native, node.js, pymongo","CU Boulder, Colorado School of Mines","","",Google Cloud,desimmonscsm,desimmonscsm,Simmons,desimmons@mines.edu,"Colorado School of Mines, University of Colorado at Boulder",2,andymitch,Andrew,Mitchell,andymitch559@gmail.com,RoastedPecans,Connor,Thompson,connorthompson915@icloud.com
Most Random,Catscan,https://hackcu-vi.devpost.com/submissions/143216-catscan,"A fun game where you earn points by taking pictures, cats are worth the most! Compete with your friends to get the top (or bottom) score!",02/23/2020 13:46:53,"Inspiration

We wanted to incorporate computer vision into an app and the first idea was just taking pictures of cats.

What it does

Catscan is a fun game where users take pictures of whatever they want and are given points based on what the subject of the picture is.

Challenges we ran into

Integrating the front and back ends, using MongoDB which 2 of us were unfamiliar with.

Accomplishments that we're proud of

Creating a fun game based on a random idea

What's next for Catscan

Assigning point values to other types of pictures
",,,,"mongodb, react-native, node.js, pymongo","CU Boulder, Colorado School of Mines","","",Google Cloud,desimmonscsm,desimmonscsm,Simmons,desimmons@mines.edu,"Colorado School of Mines, University of Colorado at Boulder",2,andymitch,Andrew,Mitchell,andymitch559@gmail.com,RoastedPecans,Connor,Thompson,connorthompson915@icloud.com
MLH: Best Use of Google Cloud,Catscan,https://hackcu-vi.devpost.com/submissions/143216-catscan,"A fun game where you earn points by taking pictures, cats are worth the most! Compete with your friends to get the top (or bottom) score!",02/23/2020 13:46:53,"Inspiration

We wanted to incorporate computer vision into an app and the first idea was just taking pictures of cats.

What it does

Catscan is a fun game where users take pictures of whatever they want and are given points based on what the subject of the picture is.

Challenges we ran into

Integrating the front and back ends, using MongoDB which 2 of us were unfamiliar with.

Accomplishments that we're proud of

Creating a fun game based on a random idea

What's next for Catscan

Assigning point values to other types of pictures
",,,,"mongodb, react-native, node.js, pymongo","CU Boulder, Colorado School of Mines","","",Google Cloud,desimmonscsm,desimmonscsm,Simmons,desimmons@mines.edu,"Colorado School of Mines, University of Colorado at Boulder",2,andymitch,Andrew,Mitchell,andymitch559@gmail.com,RoastedPecans,Connor,Thompson,connorthompson915@icloud.com
"",Getloc Poster using Adobe XD,https://hackcu-vi.devpost.com/submissions/143217-getloc-poster-using-adobe-xd,Simple presentation of Getloc Project on Adobe XD,02/23/2020 13:48:52,"Inspiration

As we got to learn Abode XD from HACKCU 2020, thus we thought it would be great to showcase our project.

What it does

How we built it

We built it with the Abode xd.

Challenges we ran into

The challenges that we faced is to implement animations on it.

Accomplishments that we're proud of

What we learned

We learnt how to create an innovative poster with the help of Abode XD.

What's next for Getloc Poster using Adobe XD
",,,,abode,Colorado State University,"","","",HariHaraKumar,,,rhariharakumar9@gmail.com,Colorado State University,2,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com,suj1995,Suraj,Eswaran,suj1995@gmail.com
Best Use of TapWithUS SDK,TapPiano,https://hackcu-vi.devpost.com/submissions/143218-tappiano,Uses Tap to simulate a piano like game.,02/23/2020 13:49:42,"Inspiration

We were super interested in working with Tap and trying to make a game with it for users.

What it does

Currently, TapPiano only works with 4 keys. It takes input from both the Tap device and the keyboard.

How we built it

We decided to use Unity as a form of input. We struggled to work with the SDK so we used the Tap device as keyboard inputs instead.

Challenges we ran into

One of our biggest challenges was learning Unity as two of us had never worked with Unity before. We also had to learn how to use the device and all of its configurations.

Accomplishments that we proud of

We are super proud of being able to make a functioning game that takes input from the device as well as having learned enough Unity with the small time frame we were given.

What we learned

We learned to cooperate and use Unity Collaborate as well as quickly develop an idea where each of us could work on a different aspect of it.

What's next for TapPiano

We have the main menu, but it needs to be implemented. We would like to add in more keys as well as varying difficulties. Sound would also be a nice addition, however, we would like to go one step at a time.
",,https://drive.google.com/file/d/14OC3OWjh8yQOwpSfcQXQBUFene_ckX--/view,,"unity, c#","CU Boulder, FGCU","","","",Jgar157,Jgar157,Garciga,jgarciga0822@eagle.fgcu.edu,Florida Gulf Coast University,2,zsett131,zsett131,,zdsetterquist9926@eagle.fgcu.edu,inma0355,Insar,Magadeev,inma0355@colorado.edu
All Beginner,TapPiano,https://hackcu-vi.devpost.com/submissions/143218-tappiano,Uses Tap to simulate a piano like game.,02/23/2020 13:49:42,"Inspiration

We were super interested in working with Tap and trying to make a game with it for users.

What it does

Currently, TapPiano only works with 4 keys. It takes input from both the Tap device and the keyboard.

How we built it

We decided to use Unity as a form of input. We struggled to work with the SDK so we used the Tap device as keyboard inputs instead.

Challenges we ran into

One of our biggest challenges was learning Unity as two of us had never worked with Unity before. We also had to learn how to use the device and all of its configurations.

Accomplishments that we proud of

We are super proud of being able to make a functioning game that takes input from the device as well as having learned enough Unity with the small time frame we were given.

What we learned

We learned to cooperate and use Unity Collaborate as well as quickly develop an idea where each of us could work on a different aspect of it.

What's next for TapPiano

We have the main menu, but it needs to be implemented. We would like to add in more keys as well as varying difficulties. Sound would also be a nice addition, however, we would like to go one step at a time.
",,https://drive.google.com/file/d/14OC3OWjh8yQOwpSfcQXQBUFene_ckX--/view,,"unity, c#","CU Boulder, FGCU","","","",Jgar157,Jgar157,Garciga,jgarciga0822@eagle.fgcu.edu,Florida Gulf Coast University,2,zsett131,zsett131,,zdsetterquist9926@eagle.fgcu.edu,inma0355,Insar,Magadeev,inma0355@colorado.edu
MLH: Best use of MongoDB Atlas,cyberhood,https://hackcu-vi.devpost.com/submissions/143219-cyberhood,wifi network watcher,02/23/2020 13:50:22,"Inspiration

Keeping networks secure and free of malicious intent

What it does

This is a wifi sniffing program and is a proof of concept. Ideally the kismet script would be run on something like a raspberry pi that just sends all of its data to a mongo db from which a google cloud service runs analysis on the data and displays that data on a web server. We look for things such as deauth packages, people running Kali or Arch, pineapple, etc. to determine if shady people were using the network. From this we can alert users on the network. 

How I built it

In this version here, we have the script that is run on a local computer which pipes that data to the mongo db. From there we display charts from mongo db atlas to a website hosted at https://sidhantpuntambekar.github.io/page/index.html . We also utilized mongo db compass to display the data in a more informative way on one of our machines.

Challenges I ran into

making the google cloud into a rest api

Accomplishments that I'm proud of

We made a fully working mongo db that can be accessed from the google cloud

What I learned

We learned google cloud and mongo db, parts of java, how to create mongo db rest api's, as well as hosting on git hub pages

What's next for cyberhood

developing a rest api with google cloud to communicate with the mongo db
",,https://github.com/k2zylstra/team-cyberhood,,"mongodb, python, html5, javascript, css, kismet, api","University of Colorado, Boulder","","",MongoDB,k2zylstra,Kieran,Zylstra,kieran.zylstra@colorado.edu,University of Colorado at Boulder,3,SidhantPuntambekar,Sidhant,Puntambekar,sidhantnp@yahoo.com,Larjun,Arjun,Lakshmi Narasimhan,larjun01@gmail.com,Slyracoon23,Slyracoon23,,earl.potters@gmail.com
Social Impact,cyberhood,https://hackcu-vi.devpost.com/submissions/143219-cyberhood,wifi network watcher,02/23/2020 13:50:22,"Inspiration

Keeping networks secure and free of malicious intent

What it does

This is a wifi sniffing program and is a proof of concept. Ideally the kismet script would be run on something like a raspberry pi that just sends all of its data to a mongo db from which a google cloud service runs analysis on the data and displays that data on a web server. We look for things such as deauth packages, people running Kali or Arch, pineapple, etc. to determine if shady people were using the network. From this we can alert users on the network. 

How I built it

In this version here, we have the script that is run on a local computer which pipes that data to the mongo db. From there we display charts from mongo db atlas to a website hosted at https://sidhantpuntambekar.github.io/page/index.html . We also utilized mongo db compass to display the data in a more informative way on one of our machines.

Challenges I ran into

making the google cloud into a rest api

Accomplishments that I'm proud of

We made a fully working mongo db that can be accessed from the google cloud

What I learned

We learned google cloud and mongo db, parts of java, how to create mongo db rest api's, as well as hosting on git hub pages

What's next for cyberhood

developing a rest api with google cloud to communicate with the mongo db
",,https://github.com/k2zylstra/team-cyberhood,,"mongodb, python, html5, javascript, css, kismet, api","University of Colorado, Boulder","","",MongoDB,k2zylstra,Kieran,Zylstra,kieran.zylstra@colorado.edu,University of Colorado at Boulder,3,SidhantPuntambekar,Sidhant,Puntambekar,sidhantnp@yahoo.com,Larjun,Arjun,Lakshmi Narasimhan,larjun01@gmail.com,Slyracoon23,Slyracoon23,,earl.potters@gmail.com
Social Impact,Sleepy Driver Detect,https://hackcu-vi.devpost.com/submissions/143220-sleepy-driver-detect,detecting a sleepy driver and alerts the driver,02/23/2020 13:50:52,"Inspiration

To avoid any accidental conditions where driver might loose control due to drowsiness. 

What it does

Constantly monitor's driver's eye movement and alerts them with an alarm if eyes seem to be closed for longer time.

How we built it

Using python facial features detector algorithm and identifying whether eyes are open or closed

Challenges we ran into

installing and configuring the setup ( libraries for building the project )

Accomplishments that we're proud of

Quite a precise identification of opened and closed eyes.'

What we learned

An fun way for contributing to social cause.

What's next for Sleepy Driver Detect

Integrate it in car using hardware such as raspberrypi and also extend this application to other use cases.
",https://www.youtube.com/watch?v=TjZpJbrMAIw&feature=youtu.be,,,python,Colorado State University,"","","",rohitrohitg17,rohit,Gorle,rohit.rohitg17@gmail.com,Colorado State University,3,HariHaraKumar,,,rhariharakumar9@gmail.com,MridulaBontha,Mridula,Bontha,mridula.bvs@gmail.com,suj1995,Suraj,Eswaran,suj1995@gmail.com
Best UX/UI,Stop Motion (AR enhanced),https://hackcu-vi.devpost.com/submissions/143221-stop-motion-ar-enhanced,Inspiring the next gerenartion of young filmmaker with AR and Stop Motion. ,02/23/2020 13:51:06,"Inspiration

In our brainstorming, we were interested how Augmented Reality could impact the world of artistic expression. Ultimately, we came together on the idea of making Stop Motion more accessible. Stop Motion has inspired many young filmmakers and the creation of classic films like Rudolf and the Nightmare before Christmas.  Our app makes Stop Motion open to a new generation of creative artists.

What it does

We created an Andriod App that uses AR to guide the filmmaker (user) in positioning their phone's camera to the same location as they used to take the previous images. In addition to providing visual aid in repositioning, it also uses the phone's camera to automatically take a picture when it is properly aligned.

How we built it

To build this ambitious app we used the Kotlin Languages, Android Studio, and AR-Core to interface with the phone's technologies and features. 

Challenges we ran into

As most of us have not used Kotlin or Android-Studio before, it became one of our biggest challenges. We were entering a new framework that required a shift in mindset that allows for powerful event-based programming.

Accomplishments that we're proud of

One accomplishment was going from 0-60 in our skills of Kotlin and Android studio. We also Integrated AR-Core, Camera API, file systems, UI and UX design into a cohesive app in 24 hours!

What we learned

Whenever one of us was stuck or in a rut, someone else could step in and pair program with them. This was critical to our success and taught us to be more appreciative of pair programming. 

What's next for Stop Motion (AR enhanced)

In the short term, we want to add a way to organize and share projects and further refining the photo trigger point. In the long term, we want to expand to more platforms beyond high-end Android phones.
",,https://github.com/jhgarner/StopMotion,,"kotlin, android-studio, android:-arcore",Colorado School of Mines,"","","",JaredLincenberg,Jared,Lincenberg,jaredlincenberg@gmail.com,Colorado School of Mines,3,jhgarner,Jackson,Garner,jkrmnj465@gmail.com,jrrobel,Jonathon,Robel,jrrobel@mymail.mines.edu,rykerfish,rykerfish,,facepallm16@gmail.com
Most Creative Usage of Twitter API,Gander,https://hackcu-vi.devpost.com/submissions/143222-gander,A Smart Photo Booth that can track and recognize its users.,02/23/2020 13:51:13,"Inspiration

Our team is excited about robotics and computer vision. We heard about the twitter API at the beginning session and thought it would be unique to integrate twitter into a robotics hack.

What it does

A photo booth that tracks its users and makes sure they are center in frame. Then it can recognize people it has taken pictures of and tweet at them. The photo booth keeps track of who it has already seen and will remember their twitter tags. 
The program first starts off by finding a person in a frame and rotating the camera so a person is center in the frame. Then a facial detection algorithm takes over and detects if the person is known or unknown. If the person is unknown, we ask them who they are. Once we know who they are, we can tweet and tag them in the picture(@TeamGoose3). This program will remember everyone it has seen. 

How I built it

We used a Keysight raspberry pi and a screen along with a servo attached to a Logitech camera. We also used some tape to hold everything together. The software portion uses cv along with a facial recognition library that can both recognize and classify faces. The servo is moved using a special hardware timer servo library.

Challenges I ran into

To access the files on the pi we had to setup a hotspot so we could ssh into the pi. However, it was so slow. So we decided to do all coding off of the pi and then deploy very sparingly. 

The camera mount was not that great so we decided for the time being that we would have to elevate the rig for it to work. 

Accomplishments that I'm proud of

Implementing face recognition smoothly was very good. Working with so many different aspects of technology and the project still working was amazing. We also made the project look pretty good. It was a success in many different aspects. 

What I learned

This was our first time working together as a team, so it really gave us the chance to explore our strengths and get out of our comfort zone. For this project, we had to learn many new skills including Python GUI design, Raspberry Pi OpenCV integration, Twitter API implementation, and how to build a complex computer vision-based project in 24 hours. These are skills that we will be able to carry into the real world, and we can't wait to show them off!

What's next for Gander

More features are coming for Gander! We intend on first implementing a new model that detects side profiles of faces, to better the accuracy of our tracking. Then we want to add multi-face tracking so that you and all your friends are able to share the fun of taking pictures with Gander!
",,https://github.com/rocketrice/HackCU2020,,"python, raspberry-pi, cv2, face-recognt, servo, cardboard, twitter",University of Colorado Colorado Springs,"",Raspberry Pi,"",tedlasai,Sai,Tedla,tedlasai@gmail.com,University of Colorado at Colorado Springs,3,rocketrice,Rice,Province,provincerice@gmail.com,hnang,Hunter,Nang,hnang@uccs.edu,oceanconnectionmedia,Jason,Alexander,oceanconnectionmedia@gmail.com
Best UX/UI,Gander,https://hackcu-vi.devpost.com/submissions/143222-gander,A Smart Photo Booth that can track and recognize its users.,02/23/2020 13:51:13,"Inspiration

Our team is excited about robotics and computer vision. We heard about the twitter API at the beginning session and thought it would be unique to integrate twitter into a robotics hack.

What it does

A photo booth that tracks its users and makes sure they are center in frame. Then it can recognize people it has taken pictures of and tweet at them. The photo booth keeps track of who it has already seen and will remember their twitter tags. 
The program first starts off by finding a person in a frame and rotating the camera so a person is center in the frame. Then a facial detection algorithm takes over and detects if the person is known or unknown. If the person is unknown, we ask them who they are. Once we know who they are, we can tweet and tag them in the picture(@TeamGoose3). This program will remember everyone it has seen. 

How I built it

We used a Keysight raspberry pi and a screen along with a servo attached to a Logitech camera. We also used some tape to hold everything together. The software portion uses cv along with a facial recognition library that can both recognize and classify faces. The servo is moved using a special hardware timer servo library.

Challenges I ran into

To access the files on the pi we had to setup a hotspot so we could ssh into the pi. However, it was so slow. So we decided to do all coding off of the pi and then deploy very sparingly. 

The camera mount was not that great so we decided for the time being that we would have to elevate the rig for it to work. 

Accomplishments that I'm proud of

Implementing face recognition smoothly was very good. Working with so many different aspects of technology and the project still working was amazing. We also made the project look pretty good. It was a success in many different aspects. 

What I learned

This was our first time working together as a team, so it really gave us the chance to explore our strengths and get out of our comfort zone. For this project, we had to learn many new skills including Python GUI design, Raspberry Pi OpenCV integration, Twitter API implementation, and how to build a complex computer vision-based project in 24 hours. These are skills that we will be able to carry into the real world, and we can't wait to show them off!

What's next for Gander

More features are coming for Gander! We intend on first implementing a new model that detects side profiles of faces, to better the accuracy of our tracking. Then we want to add multi-face tracking so that you and all your friends are able to share the fun of taking pictures with Gander!
",,https://github.com/rocketrice/HackCU2020,,"python, raspberry-pi, cv2, face-recognt, servo, cardboard, twitter",University of Colorado Colorado Springs,"",Raspberry Pi,"",tedlasai,Sai,Tedla,tedlasai@gmail.com,University of Colorado at Colorado Springs,3,rocketrice,Rice,Province,provincerice@gmail.com,hnang,Hunter,Nang,hnang@uccs.edu,oceanconnectionmedia,Jason,Alexander,oceanconnectionmedia@gmail.com
Most Random,Gander,https://hackcu-vi.devpost.com/submissions/143222-gander,A Smart Photo Booth that can track and recognize its users.,02/23/2020 13:51:13,"Inspiration

Our team is excited about robotics and computer vision. We heard about the twitter API at the beginning session and thought it would be unique to integrate twitter into a robotics hack.

What it does

A photo booth that tracks its users and makes sure they are center in frame. Then it can recognize people it has taken pictures of and tweet at them. The photo booth keeps track of who it has already seen and will remember their twitter tags. 
The program first starts off by finding a person in a frame and rotating the camera so a person is center in the frame. Then a facial detection algorithm takes over and detects if the person is known or unknown. If the person is unknown, we ask them who they are. Once we know who they are, we can tweet and tag them in the picture(@TeamGoose3). This program will remember everyone it has seen. 

How I built it

We used a Keysight raspberry pi and a screen along with a servo attached to a Logitech camera. We also used some tape to hold everything together. The software portion uses cv along with a facial recognition library that can both recognize and classify faces. The servo is moved using a special hardware timer servo library.

Challenges I ran into

To access the files on the pi we had to setup a hotspot so we could ssh into the pi. However, it was so slow. So we decided to do all coding off of the pi and then deploy very sparingly. 

The camera mount was not that great so we decided for the time being that we would have to elevate the rig for it to work. 

Accomplishments that I'm proud of

Implementing face recognition smoothly was very good. Working with so many different aspects of technology and the project still working was amazing. We also made the project look pretty good. It was a success in many different aspects. 

What I learned

This was our first time working together as a team, so it really gave us the chance to explore our strengths and get out of our comfort zone. For this project, we had to learn many new skills including Python GUI design, Raspberry Pi OpenCV integration, Twitter API implementation, and how to build a complex computer vision-based project in 24 hours. These are skills that we will be able to carry into the real world, and we can't wait to show them off!

What's next for Gander

More features are coming for Gander! We intend on first implementing a new model that detects side profiles of faces, to better the accuracy of our tracking. Then we want to add multi-face tracking so that you and all your friends are able to share the fun of taking pictures with Gander!
",,https://github.com/rocketrice/HackCU2020,,"python, raspberry-pi, cv2, face-recognt, servo, cardboard, twitter",University of Colorado Colorado Springs,"",Raspberry Pi,"",tedlasai,Sai,Tedla,tedlasai@gmail.com,University of Colorado at Colorado Springs,3,rocketrice,Rice,Province,provincerice@gmail.com,hnang,Hunter,Nang,hnang@uccs.edu,oceanconnectionmedia,Jason,Alexander,oceanconnectionmedia@gmail.com
All Beginner,Gander,https://hackcu-vi.devpost.com/submissions/143222-gander,A Smart Photo Booth that can track and recognize its users.,02/23/2020 13:51:13,"Inspiration

Our team is excited about robotics and computer vision. We heard about the twitter API at the beginning session and thought it would be unique to integrate twitter into a robotics hack.

What it does

A photo booth that tracks its users and makes sure they are center in frame. Then it can recognize people it has taken pictures of and tweet at them. The photo booth keeps track of who it has already seen and will remember their twitter tags. 
The program first starts off by finding a person in a frame and rotating the camera so a person is center in the frame. Then a facial detection algorithm takes over and detects if the person is known or unknown. If the person is unknown, we ask them who they are. Once we know who they are, we can tweet and tag them in the picture(@TeamGoose3). This program will remember everyone it has seen. 

How I built it

We used a Keysight raspberry pi and a screen along with a servo attached to a Logitech camera. We also used some tape to hold everything together. The software portion uses cv along with a facial recognition library that can both recognize and classify faces. The servo is moved using a special hardware timer servo library.

Challenges I ran into

To access the files on the pi we had to setup a hotspot so we could ssh into the pi. However, it was so slow. So we decided to do all coding off of the pi and then deploy very sparingly. 

The camera mount was not that great so we decided for the time being that we would have to elevate the rig for it to work. 

Accomplishments that I'm proud of

Implementing face recognition smoothly was very good. Working with so many different aspects of technology and the project still working was amazing. We also made the project look pretty good. It was a success in many different aspects. 

What I learned

This was our first time working together as a team, so it really gave us the chance to explore our strengths and get out of our comfort zone. For this project, we had to learn many new skills including Python GUI design, Raspberry Pi OpenCV integration, Twitter API implementation, and how to build a complex computer vision-based project in 24 hours. These are skills that we will be able to carry into the real world, and we can't wait to show them off!

What's next for Gander

More features are coming for Gander! We intend on first implementing a new model that detects side profiles of faces, to better the accuracy of our tracking. Then we want to add multi-face tracking so that you and all your friends are able to share the fun of taking pictures with Gander!
",,https://github.com/rocketrice/HackCU2020,,"python, raspberry-pi, cv2, face-recognt, servo, cardboard, twitter",University of Colorado Colorado Springs,"",Raspberry Pi,"",tedlasai,Sai,Tedla,tedlasai@gmail.com,University of Colorado at Colorado Springs,3,rocketrice,Rice,Province,provincerice@gmail.com,hnang,Hunter,Nang,hnang@uccs.edu,oceanconnectionmedia,Jason,Alexander,oceanconnectionmedia@gmail.com
Best UX/UI,FlyQR,https://hackcu-vi.devpost.com/submissions/143223-flyqr,Predictive analytics for your campus posters! Stop wasting paper and know exactly how to reach your campus audience.,02/23/2020 13:51:41,"FlyQR

Predictive analytics for your campus posters! Stop wasting paper and know exactly how to reach your campus audience.

Perfect for student organizations. We predict the best place to hang up your poster, just based on the type of club/organization you run.

How it works (ease of use!)


Create a poster in your favorite poster-making tool.
Upload your poster via our mobile app.
We'll stick unique QR codes on your poster and give you a download link so you can print unique, trackable posters.


How it works (beneficial analytics!)


Hang up your uniquely tracked posters around campus, and scan the QR on each one as you go. When you scan them, we'll keep track of the building and floor number you put it at.
Wait for people to come by and scan your poster...
Hooray! You now know a lot more about your campus audience via our app's analytics dashboard.


Technology

Prototype built and wired together in Adobe XD
View the live project here: https://xd.adobe.com/view/7a88fbb7-516b-4b92-5cdb-7a6b17bf7c6f-0cb9/

XD was incredibly useful in helping us realize our ideas way ahead of when we could actually implement them. It is really easy to learn and has great tools allowing for unfettered creativity. Building features in the mobile app took at least 4x longer than it did to prototype them in XD first. This helped us iterate shockingly fast.

Mobile prototype built in Expo / React Native
Connects to Flask backend API and uses a MySQL database to relate Organizations to Campaigns and individual Flyers.

What we learned

Our team developed a greater ability to rapidly prototype apps. Our project had a very large scope and this caused for long hours to be spent getting all the moving parts to work. Of course it's nowhere near perfect now, but we were able to achieve a solid minimum viable product with real potential to help campus organizations.

The backend team overcomplicated a lot and too much time was spent trying to get the database working, so in the future we will be more prepared to mock requests and setup testing as early as possible.
",,https://github.com/evanram/flyqr,,"javascript, python, flask, expo.io, react-native, mysql, docker, google-cloud, redis, adobe-xd",University of Colorado Boulder,"","","",evanram,Evan,Ram,evan@evanram.com,University of Colorado at Boulder,3,hdesh7,Harsh,Deshpande,hade7393@colorado.edu,jess2187,Jessica,Sanborn,jessica.sanborn10@gmail.com,WillNess210,Will,Ness,willness210@gmail.com
Best Use of Adobe XD,FlyQR,https://hackcu-vi.devpost.com/submissions/143223-flyqr,Predictive analytics for your campus posters! Stop wasting paper and know exactly how to reach your campus audience.,02/23/2020 13:51:41,"FlyQR

Predictive analytics for your campus posters! Stop wasting paper and know exactly how to reach your campus audience.

Perfect for student organizations. We predict the best place to hang up your poster, just based on the type of club/organization you run.

How it works (ease of use!)


Create a poster in your favorite poster-making tool.
Upload your poster via our mobile app.
We'll stick unique QR codes on your poster and give you a download link so you can print unique, trackable posters.


How it works (beneficial analytics!)


Hang up your uniquely tracked posters around campus, and scan the QR on each one as you go. When you scan them, we'll keep track of the building and floor number you put it at.
Wait for people to come by and scan your poster...
Hooray! You now know a lot more about your campus audience via our app's analytics dashboard.


Technology

Prototype built and wired together in Adobe XD
View the live project here: https://xd.adobe.com/view/7a88fbb7-516b-4b92-5cdb-7a6b17bf7c6f-0cb9/

XD was incredibly useful in helping us realize our ideas way ahead of when we could actually implement them. It is really easy to learn and has great tools allowing for unfettered creativity. Building features in the mobile app took at least 4x longer than it did to prototype them in XD first. This helped us iterate shockingly fast.

Mobile prototype built in Expo / React Native
Connects to Flask backend API and uses a MySQL database to relate Organizations to Campaigns and individual Flyers.

What we learned

Our team developed a greater ability to rapidly prototype apps. Our project had a very large scope and this caused for long hours to be spent getting all the moving parts to work. Of course it's nowhere near perfect now, but we were able to achieve a solid minimum viable product with real potential to help campus organizations.

The backend team overcomplicated a lot and too much time was spent trying to get the database working, so in the future we will be more prepared to mock requests and setup testing as early as possible.
",,https://github.com/evanram/flyqr,,"javascript, python, flask, expo.io, react-native, mysql, docker, google-cloud, redis, adobe-xd",University of Colorado Boulder,"","","",evanram,Evan,Ram,evan@evanram.com,University of Colorado at Boulder,3,hdesh7,Harsh,Deshpande,hade7393@colorado.edu,jess2187,Jessica,Sanborn,jessica.sanborn10@gmail.com,WillNess210,Will,Ness,willness210@gmail.com
Best UX/UI,Plate Gate,https://hackcu-vi.devpost.com/submissions/143224-plate-gate,"Plate Gate is a system that uses mobile-based machine learning to locate and identify parking infractions in real time, using an integrated web management and database service.",02/23/2020 13:52:04,"Inspiration

When one of the developers of this app was at the airport several days ago, he noticed a lone officer walking around the parking lot, carrying a computer.  The officer had evidently been tasked with locating parking violations, and was stopping at each vehicle to manually type in its license plate so that he could determine if the car was incorrectly parked.  With thousands of vehicles at an average airport, and a minimum of 20 seconds required to record and look up each car's information, this task could literally take up days worth of man hours. 

On a personal note, we have been impacted by personnel parking incorrectly on our own military installation, leading to delays and routine inconvenience.  The primary reason that our unit has not been able to maintain control over the parking privileges is because of the amount of time that it takes to conduct parking enforcement, and the ease of copying or sharing parking passes.

We challenged ourselves to come up with a better solution.  By combining the power of machine learning with the instant availability and versatility of the cloud, we created a product which automates a significant portion of the parking enforcement task cycle, allowing parking regulations to be enforced with a fraction of the time and effort.

What it does

Plate Gate is a system that uses mobile-based machine learning to locate and identify parking infractions in real time, using an integrated web management and database service.  It uses a trained object detection model to recognize license plates and parse their data.  It then passes this data back to the cloud-based API system, which interfaces with a back-end database to determine whether each vehicle is approved to be parked in that location.  This database is managed through a web interface, allowing efficient management through CSV file uploads and simple item deletion.  All elements of the API and app are authenticated, ensuring that no outside parties are able to gain access to personal data.  It also maintains separate databases for all users, allowing many different sessions and endpoints to operate concurrently.

How we built it

The mobile app is built using Swift, and uses a simple and clear user interface for ease of use in the field.  The API and management server is running on a Google Cloud Linux Virtual Machine, and is running Apache as its web server.  It relies on extensive JavaScript and PHP scripting, and interfaces with a mySQL database in the backend.  The mobile app communicates to the API via HTTP GET requests, first authenticating to receive an access token and then passing license plate data to determine whether each license plate is approved for that location.  Because all enforcement checks occur on the server, updates to the database are instantaneously reflected on all clients.  The front end for the web management interface was initially built using Webflow and exported into the cloud environment. The machine learning model for classifying the license plate numbers was built using a service called Turi, and trained using a data set we gathered.

Challenges we ran into

The biggest challenge that we faced was that neither of us had experience with mobile app development, creating a steep learning curve for coding in Swift.  This was consistently the biggest hurdle, but we also faced a series of challenges with implementing the web interface and allowing it to communicate with the mobile app. We also struggled to get the optimal sensitivity of the machine learning model to get the highest accuracy. 

Accomplishments that we're proud of

We are extremely proud of the full integration of the mobile app with the web interface.  The level of accuracy of the machine learning model surprised us, especially under adverse conditions.  We conducted testing during all levels of light, and the system was able to correctly identify the majority of license plates even in the middle of the night.  This was also the first project that either of us have built using a machine learning model, which we trained ourselves.  We were able to accomplish all of the primary goals for the project which we determined at the start, and are extremely happy with the end product.

What we learned

We learned the many nuances of integrating a full stack web interface with a mobile application.  Over the course of this project, we learned almost all of the skills in Swift that were needed to build it, coming from almost no experience.  At first, we planned on using a pre-built machine learning model, (Google's TensorFlow), but decided to stretch ourselves and instead write our own.  We learned the importance of troubleshooting on the lowest level first, and gained significant experience in debugging web-based API systems.

What's next for Plate Gate

We plan on continuing the development of Plate Gate, and implementing it at our own institution.  We hope that it will reduce parking congestion, and decrease the load on parking enforcement.  We are excited to see where this project will turn into, and thank Hack CU for giving us the opportunity to develop it.
",https://youtu.be/Xw8KZFd4fhc,http://plategate.tech,,"swift, php, html, google-cloud, turi, avkit, vision-kit, javascript, css, ios, ajax, mysql, apache, webflow, jquery",United States Air Force Academy,plategate.tech,"",Google Cloud,kishanhbpatel,Kishan,Patel,kishanhbpatel@gmail.com,"Air Force Academy, United States Air Force Academy",1,kernelstearns,kernelstearns,,stearns.josiah@gmail.com
Most Random,Nothing But Net,https://hackcu-vi.devpost.com/submissions/143225-nothing-but-net,"To the end user, the internet is only what you can browse to. So, we Nothing but Net built an ""application"" that ensures users only access a browser, reminding them when they forget.",02/23/2020 13:53:28,"Inspiration

We were working on a more boring network monitoring project when, around midnight, inspiration struck. Jay thought of a new team name, ""nothing but net."" Then a silly idea came into our heads. What if we could ban a user from accessing anything but browser websites, playing a silly sound every time they tried to circumvent the firewall? They would be able to access nothing but the net. Jacob suggested that perhaps we could use IPtables to set up rules and update a log when the rules were violated. We were off!

What it does

The program blocks all traffic from anything but internet browsers. It mocks the user if they try to use anything but the net.

How we built it

We set up IPtables rules to block any interaction unless it comes from an HTTP URL or Google's DNS. We set up a log file that adds a warning every time the user attempts an interaction that violates the rules. Whenever the log is updated with one of the nothingButNet warnings, a Bash script plays the Jurassic Park ""ah ah ah, you didn't say the magic word"" sound.

Challenges we ran into

We had a hard time figuring out how to allow DNS from a browser but block other types of traffic. We ended up creating a workaround with the IP address of google, blocking everything except that. 

Accomplishments that we're proud of

We were having trouble coming up with an interesting idea, but even after changing course halfway into the hackathon, we made something funny that works.

What we learned

Most of us have never used IPtables before, and two of us were inexperienced in Bash before this. We learned about using a raspberry pi, accessing it remotely, and using Linux. Our team is made up of people with a variety of coding experience, and we spent a lot of time just exploring things we hadn't done before. We learned a lot from each other's skill sets in the past 24 hours. 

What's next for Nothing But Net

Perhaps Nothing But Net will troll more than just a raspberry pi someday. The team is thinking of making a desktop application or a browser extension out of our project. This would make a good April Fools joke!
",,,,"raspberry-pi, network-analysis-tools-(neat), bash, ssh, scp, speaker",University of Colorado Boulder,"","","",graceedwards-1,Grace,Edwards,grace.edwards-1@colorado.edu,University of Colorado at Boulder,3,jayhayward,Jay,Hayward,justin.hayward@colorado.edu,mlay0797,Matthew,Lay,mlay0797@gmail.com,pcx436,Jacob,M,pcx436@yahoo.com
Social Impact,TravelwithN application prototype,https://hackcu-vi.devpost.com/submissions/143226-travelwithn-application-prototype,This is the application to help reduce energy consumption by traveling N number of people together. It can share a trip with neighborhood and get the rewards by making impact to your local society.,02/23/2020 13:55:15,"Inspiration

What it does

It can share a trip with neighborhood and get the rewards by making impact to your local society.

How we built it

We used AdobeXD to build our deme application 

Challenges we ran into

This is our first time to do application so it is quite difficult to learn and visualize our idea. At first, we want to do an API to detect the location from social media since our group are all beginner who have passion in techonology.

Accomplishments that we're proud of

What we learned

What's next for TravelwithN application prototype
",,https://xd.adobe.com/view/92d31f77-c822-4eee-4271-c87c19c676b0-e4e2/,,"adobexd, adobe, uikit, uikits",University of colorado boulder,"","","",ruvi8122,Nay,Vichitpunt,ruvi8122@colorado.edu,University of Colorado at Boulder,1,SuphawitDuangphumek,Suphawit,Duangphumek,supawit_stang@hotmail.com
Best UX/UI,TravelwithN application prototype,https://hackcu-vi.devpost.com/submissions/143226-travelwithn-application-prototype,This is the application to help reduce energy consumption by traveling N number of people together. It can share a trip with neighborhood and get the rewards by making impact to your local society.,02/23/2020 13:55:15,"Inspiration

What it does

It can share a trip with neighborhood and get the rewards by making impact to your local society.

How we built it

We used AdobeXD to build our deme application 

Challenges we ran into

This is our first time to do application so it is quite difficult to learn and visualize our idea. At first, we want to do an API to detect the location from social media since our group are all beginner who have passion in techonology.

Accomplishments that we're proud of

What we learned

What's next for TravelwithN application prototype
",,https://xd.adobe.com/view/92d31f77-c822-4eee-4271-c87c19c676b0-e4e2/,,"adobexd, adobe, uikit, uikits",University of colorado boulder,"","","",ruvi8122,Nay,Vichitpunt,ruvi8122@colorado.edu,University of Colorado at Boulder,1,SuphawitDuangphumek,Suphawit,Duangphumek,supawit_stang@hotmail.com
Most Random,TravelwithN application prototype,https://hackcu-vi.devpost.com/submissions/143226-travelwithn-application-prototype,This is the application to help reduce energy consumption by traveling N number of people together. It can share a trip with neighborhood and get the rewards by making impact to your local society.,02/23/2020 13:55:15,"Inspiration

What it does

It can share a trip with neighborhood and get the rewards by making impact to your local society.

How we built it

We used AdobeXD to build our deme application 

Challenges we ran into

This is our first time to do application so it is quite difficult to learn and visualize our idea. At first, we want to do an API to detect the location from social media since our group are all beginner who have passion in techonology.

Accomplishments that we're proud of

What we learned

What's next for TravelwithN application prototype
",,https://xd.adobe.com/view/92d31f77-c822-4eee-4271-c87c19c676b0-e4e2/,,"adobexd, adobe, uikit, uikits",University of colorado boulder,"","","",ruvi8122,Nay,Vichitpunt,ruvi8122@colorado.edu,University of Colorado at Boulder,1,SuphawitDuangphumek,Suphawit,Duangphumek,supawit_stang@hotmail.com
All Beginner,TravelwithN application prototype,https://hackcu-vi.devpost.com/submissions/143226-travelwithn-application-prototype,This is the application to help reduce energy consumption by traveling N number of people together. It can share a trip with neighborhood and get the rewards by making impact to your local society.,02/23/2020 13:55:15,"Inspiration

What it does

It can share a trip with neighborhood and get the rewards by making impact to your local society.

How we built it

We used AdobeXD to build our deme application 

Challenges we ran into

This is our first time to do application so it is quite difficult to learn and visualize our idea. At first, we want to do an API to detect the location from social media since our group are all beginner who have passion in techonology.

Accomplishments that we're proud of

What we learned

What's next for TravelwithN application prototype
",,https://xd.adobe.com/view/92d31f77-c822-4eee-4271-c87c19c676b0-e4e2/,,"adobexd, adobe, uikit, uikits",University of colorado boulder,"","","",ruvi8122,Nay,Vichitpunt,ruvi8122@colorado.edu,University of Colorado at Boulder,1,SuphawitDuangphumek,Suphawit,Duangphumek,supawit_stang@hotmail.com
Sustainability,TravelwithN application prototype,https://hackcu-vi.devpost.com/submissions/143226-travelwithn-application-prototype,This is the application to help reduce energy consumption by traveling N number of people together. It can share a trip with neighborhood and get the rewards by making impact to your local society.,02/23/2020 13:55:15,"Inspiration

What it does

It can share a trip with neighborhood and get the rewards by making impact to your local society.

How we built it

We used AdobeXD to build our deme application 

Challenges we ran into

This is our first time to do application so it is quite difficult to learn and visualize our idea. At first, we want to do an API to detect the location from social media since our group are all beginner who have passion in techonology.

Accomplishments that we're proud of

What we learned

What's next for TravelwithN application prototype
",,https://xd.adobe.com/view/92d31f77-c822-4eee-4271-c87c19c676b0-e4e2/,,"adobexd, adobe, uikit, uikits",University of colorado boulder,"","","",ruvi8122,Nay,Vichitpunt,ruvi8122@colorado.edu,University of Colorado at Boulder,1,SuphawitDuangphumek,Suphawit,Duangphumek,supawit_stang@hotmail.com
Best Use of Adobe XD,TravelwithN application prototype,https://hackcu-vi.devpost.com/submissions/143226-travelwithn-application-prototype,This is the application to help reduce energy consumption by traveling N number of people together. It can share a trip with neighborhood and get the rewards by making impact to your local society.,02/23/2020 13:55:15,"Inspiration

What it does

It can share a trip with neighborhood and get the rewards by making impact to your local society.

How we built it

We used AdobeXD to build our deme application 

Challenges we ran into

This is our first time to do application so it is quite difficult to learn and visualize our idea. At first, we want to do an API to detect the location from social media since our group are all beginner who have passion in techonology.

Accomplishments that we're proud of

What we learned

What's next for TravelwithN application prototype
",,https://xd.adobe.com/view/92d31f77-c822-4eee-4271-c87c19c676b0-e4e2/,,"adobexd, adobe, uikit, uikits",University of colorado boulder,"","","",ruvi8122,Nay,Vichitpunt,ruvi8122@colorado.edu,University of Colorado at Boulder,1,SuphawitDuangphumek,Suphawit,Duangphumek,supawit_stang@hotmail.com
Dish Network Challenge,DroPin,https://hackcu-vi.devpost.com/submissions/143227-dropin,A ios app that allows users to see what types of activities are going on in their area.  The app gives the the ability to commit to different activities that are in their area too.,02/23/2020 13:55:46,"Inspiration

What inspired our group was that we all love to play sports such as basketball and soccer and it can be hard to find people to play with.  This is how we came up with the idea for DroPin because we wanted a solution for finding people to do different types of activities.

What it does

DroPin is an ios application that brings the community together by allowing it's users to see what types of activities are happening in their community.  You are able to drop a pin on the map with your location and a description of what you are going to be doing such as playing pick up basketball or studying and the number of people they need for the activity.  The app allows other users to commit to these events to allow the user who made the application to know how many people are going to come to their event.

How I built it

The app was built using Swift for the ios application and Java Servlets for the backend with MySql for the database.

Challenges I ran into

Some of the challenges we ran into were just our over-ambition and not being able to sleep in the 24 hours of the competition.  One of our groupmates Jack Lambert had never programmed in Swift before and it was a great learning experience for him as well.

Accomplishments that I'm proud of

Some accomplishments that we are proud of is that we were able to finish everything that we had planned on finishing for the application.  Another big accomplishment was just being able to develop an entire mobile application in 24 hours!

What I learned

The whole group learned how to work as a cohesive group and communicate effectively to efficiently develop this application.

What's next for DroPin

We are going to continue to work on the application after the competition is over and make it better.
",,https://github.com/georgemax99/HackCU2020,,"swift, java, mysql",University of Colorado Boulder,"","","",georgemax99,georgemax99,Young,gmyoungwps@gmail.com,University of Colorado at Boulder,2,jala5335,jala5335,,jala5335@colorado.edu,shao_oscar,Oscar,Shao,shao_oscar@yahoo.com
Social Impact,DroPin,https://hackcu-vi.devpost.com/submissions/143227-dropin,A ios app that allows users to see what types of activities are going on in their area.  The app gives the the ability to commit to different activities that are in their area too.,02/23/2020 13:55:46,"Inspiration

What inspired our group was that we all love to play sports such as basketball and soccer and it can be hard to find people to play with.  This is how we came up with the idea for DroPin because we wanted a solution for finding people to do different types of activities.

What it does

DroPin is an ios application that brings the community together by allowing it's users to see what types of activities are happening in their community.  You are able to drop a pin on the map with your location and a description of what you are going to be doing such as playing pick up basketball or studying and the number of people they need for the activity.  The app allows other users to commit to these events to allow the user who made the application to know how many people are going to come to their event.

How I built it

The app was built using Swift for the ios application and Java Servlets for the backend with MySql for the database.

Challenges I ran into

Some of the challenges we ran into were just our over-ambition and not being able to sleep in the 24 hours of the competition.  One of our groupmates Jack Lambert had never programmed in Swift before and it was a great learning experience for him as well.

Accomplishments that I'm proud of

Some accomplishments that we are proud of is that we were able to finish everything that we had planned on finishing for the application.  Another big accomplishment was just being able to develop an entire mobile application in 24 hours!

What I learned

The whole group learned how to work as a cohesive group and communicate effectively to efficiently develop this application.

What's next for DroPin

We are going to continue to work on the application after the competition is over and make it better.
",,https://github.com/georgemax99/HackCU2020,,"swift, java, mysql",University of Colorado Boulder,"","","",georgemax99,georgemax99,Young,gmyoungwps@gmail.com,University of Colorado at Boulder,2,jala5335,jala5335,,jala5335@colorado.edu,shao_oscar,Oscar,Shao,shao_oscar@yahoo.com
Best UX/UI,DroPin,https://hackcu-vi.devpost.com/submissions/143227-dropin,A ios app that allows users to see what types of activities are going on in their area.  The app gives the the ability to commit to different activities that are in their area too.,02/23/2020 13:55:46,"Inspiration

What inspired our group was that we all love to play sports such as basketball and soccer and it can be hard to find people to play with.  This is how we came up with the idea for DroPin because we wanted a solution for finding people to do different types of activities.

What it does

DroPin is an ios application that brings the community together by allowing it's users to see what types of activities are happening in their community.  You are able to drop a pin on the map with your location and a description of what you are going to be doing such as playing pick up basketball or studying and the number of people they need for the activity.  The app allows other users to commit to these events to allow the user who made the application to know how many people are going to come to their event.

How I built it

The app was built using Swift for the ios application and Java Servlets for the backend with MySql for the database.

Challenges I ran into

Some of the challenges we ran into were just our over-ambition and not being able to sleep in the 24 hours of the competition.  One of our groupmates Jack Lambert had never programmed in Swift before and it was a great learning experience for him as well.

Accomplishments that I'm proud of

Some accomplishments that we are proud of is that we were able to finish everything that we had planned on finishing for the application.  Another big accomplishment was just being able to develop an entire mobile application in 24 hours!

What I learned

The whole group learned how to work as a cohesive group and communicate effectively to efficiently develop this application.

What's next for DroPin

We are going to continue to work on the application after the competition is over and make it better.
",,https://github.com/georgemax99/HackCU2020,,"swift, java, mysql",University of Colorado Boulder,"","","",georgemax99,georgemax99,Young,gmyoungwps@gmail.com,University of Colorado at Boulder,2,jala5335,jala5335,,jala5335@colorado.edu,shao_oscar,Oscar,Shao,shao_oscar@yahoo.com
Most Random,DroPin,https://hackcu-vi.devpost.com/submissions/143227-dropin,A ios app that allows users to see what types of activities are going on in their area.  The app gives the the ability to commit to different activities that are in their area too.,02/23/2020 13:55:46,"Inspiration

What inspired our group was that we all love to play sports such as basketball and soccer and it can be hard to find people to play with.  This is how we came up with the idea for DroPin because we wanted a solution for finding people to do different types of activities.

What it does

DroPin is an ios application that brings the community together by allowing it's users to see what types of activities are happening in their community.  You are able to drop a pin on the map with your location and a description of what you are going to be doing such as playing pick up basketball or studying and the number of people they need for the activity.  The app allows other users to commit to these events to allow the user who made the application to know how many people are going to come to their event.

How I built it

The app was built using Swift for the ios application and Java Servlets for the backend with MySql for the database.

Challenges I ran into

Some of the challenges we ran into were just our over-ambition and not being able to sleep in the 24 hours of the competition.  One of our groupmates Jack Lambert had never programmed in Swift before and it was a great learning experience for him as well.

Accomplishments that I'm proud of

Some accomplishments that we are proud of is that we were able to finish everything that we had planned on finishing for the application.  Another big accomplishment was just being able to develop an entire mobile application in 24 hours!

What I learned

The whole group learned how to work as a cohesive group and communicate effectively to efficiently develop this application.

What's next for DroPin

We are going to continue to work on the application after the competition is over and make it better.
",,https://github.com/georgemax99/HackCU2020,,"swift, java, mysql",University of Colorado Boulder,"","","",georgemax99,georgemax99,Young,gmyoungwps@gmail.com,University of Colorado at Boulder,2,jala5335,jala5335,,jala5335@colorado.edu,shao_oscar,Oscar,Shao,shao_oscar@yahoo.com
All Beginner,DroPin,https://hackcu-vi.devpost.com/submissions/143227-dropin,A ios app that allows users to see what types of activities are going on in their area.  The app gives the the ability to commit to different activities that are in their area too.,02/23/2020 13:55:46,"Inspiration

What inspired our group was that we all love to play sports such as basketball and soccer and it can be hard to find people to play with.  This is how we came up with the idea for DroPin because we wanted a solution for finding people to do different types of activities.

What it does

DroPin is an ios application that brings the community together by allowing it's users to see what types of activities are happening in their community.  You are able to drop a pin on the map with your location and a description of what you are going to be doing such as playing pick up basketball or studying and the number of people they need for the activity.  The app allows other users to commit to these events to allow the user who made the application to know how many people are going to come to their event.

How I built it

The app was built using Swift for the ios application and Java Servlets for the backend with MySql for the database.

Challenges I ran into

Some of the challenges we ran into were just our over-ambition and not being able to sleep in the 24 hours of the competition.  One of our groupmates Jack Lambert had never programmed in Swift before and it was a great learning experience for him as well.

Accomplishments that I'm proud of

Some accomplishments that we are proud of is that we were able to finish everything that we had planned on finishing for the application.  Another big accomplishment was just being able to develop an entire mobile application in 24 hours!

What I learned

The whole group learned how to work as a cohesive group and communicate effectively to efficiently develop this application.

What's next for DroPin

We are going to continue to work on the application after the competition is over and make it better.
",,https://github.com/georgemax99/HackCU2020,,"swift, java, mysql",University of Colorado Boulder,"","","",georgemax99,georgemax99,Young,gmyoungwps@gmail.com,University of Colorado at Boulder,2,jala5335,jala5335,,jala5335@colorado.edu,shao_oscar,Oscar,Shao,shao_oscar@yahoo.com
MLH: Best use of MongoDB Atlas,Copy Once Past Anywhere- COPA,https://hackcu-vi.devpost.com/submissions/143228-copy-once-past-anywhere-copa,Copy Once Past Anywhere,02/23/2020 13:56:11,"Inspiration

Copy Once Past Anywhere

What it does

This is an app that helps users to copy text from mobile to desktop in a simple and easy manner. Whenever the user copies any text to clipboard in the mobile, it gets copied to the clipboard in the desktop or laptop. Similarly, if users copy any text to clipboard in the desktop, it gets automatically copied to the Mobile clipboard. Users should have both Android app (installed in their mobile) and Desktop app installed. 

How I built it

We used Java for Android app development, electron.js for cross-platform Desktop app. The backend services are written in Node.js, using MongoDB as our database. The services and database are deployed on Google Cloud platform using Docker.

Challenges I ran into

We used websockets for sending clipboard data to mobile from desktop and vice versa. We faced challenges in ensuring proper working of this feature using websockets, which was very important from the performance point of view. Apart from this, we faced challenges in integrating different service and apps.

Accomplishments that I'm proud of

What I learned

What's next for Copy Once Past Anywhere- COPA

Following would be the future improvements:


Authentication feature
Building iOS app

",,https://github.com/rajchandak/HackCU,,"",University of Colorado Boulder,"","",Google Cloud,vishy_kulk,vishwanath,kulkarni,vishwa.kulkarni@gmail.com,"MSRIT, University of Colorado at Boulder",2,maai8912,Madhusudhan,Aithal Mahabhaleshwara,maai8912@colorado.edu,rajchandak,Raj,Chandak,raj.chandak@colorado.edu
Best UX/UI,Copy Once Past Anywhere- COPA,https://hackcu-vi.devpost.com/submissions/143228-copy-once-past-anywhere-copa,Copy Once Past Anywhere,02/23/2020 13:56:11,"Inspiration

Copy Once Past Anywhere

What it does

This is an app that helps users to copy text from mobile to desktop in a simple and easy manner. Whenever the user copies any text to clipboard in the mobile, it gets copied to the clipboard in the desktop or laptop. Similarly, if users copy any text to clipboard in the desktop, it gets automatically copied to the Mobile clipboard. Users should have both Android app (installed in their mobile) and Desktop app installed. 

How I built it

We used Java for Android app development, electron.js for cross-platform Desktop app. The backend services are written in Node.js, using MongoDB as our database. The services and database are deployed on Google Cloud platform using Docker.

Challenges I ran into

We used websockets for sending clipboard data to mobile from desktop and vice versa. We faced challenges in ensuring proper working of this feature using websockets, which was very important from the performance point of view. Apart from this, we faced challenges in integrating different service and apps.

Accomplishments that I'm proud of

What I learned

What's next for Copy Once Past Anywhere- COPA

Following would be the future improvements:


Authentication feature
Building iOS app

",,https://github.com/rajchandak/HackCU,,"",University of Colorado Boulder,"","",Google Cloud,vishy_kulk,vishwanath,kulkarni,vishwa.kulkarni@gmail.com,"MSRIT, University of Colorado at Boulder",2,maai8912,Madhusudhan,Aithal Mahabhaleshwara,maai8912@colorado.edu,rajchandak,Raj,Chandak,raj.chandak@colorado.edu
Most Random,Copy Once Past Anywhere- COPA,https://hackcu-vi.devpost.com/submissions/143228-copy-once-past-anywhere-copa,Copy Once Past Anywhere,02/23/2020 13:56:11,"Inspiration

Copy Once Past Anywhere

What it does

This is an app that helps users to copy text from mobile to desktop in a simple and easy manner. Whenever the user copies any text to clipboard in the mobile, it gets copied to the clipboard in the desktop or laptop. Similarly, if users copy any text to clipboard in the desktop, it gets automatically copied to the Mobile clipboard. Users should have both Android app (installed in their mobile) and Desktop app installed. 

How I built it

We used Java for Android app development, electron.js for cross-platform Desktop app. The backend services are written in Node.js, using MongoDB as our database. The services and database are deployed on Google Cloud platform using Docker.

Challenges I ran into

We used websockets for sending clipboard data to mobile from desktop and vice versa. We faced challenges in ensuring proper working of this feature using websockets, which was very important from the performance point of view. Apart from this, we faced challenges in integrating different service and apps.

Accomplishments that I'm proud of

What I learned

What's next for Copy Once Past Anywhere- COPA

Following would be the future improvements:


Authentication feature
Building iOS app

",,https://github.com/rajchandak/HackCU,,"",University of Colorado Boulder,"","",Google Cloud,vishy_kulk,vishwanath,kulkarni,vishwa.kulkarni@gmail.com,"MSRIT, University of Colorado at Boulder",2,maai8912,Madhusudhan,Aithal Mahabhaleshwara,maai8912@colorado.edu,rajchandak,Raj,Chandak,raj.chandak@colorado.edu
MLH: Best Use of Google Cloud,Copy Once Past Anywhere- COPA,https://hackcu-vi.devpost.com/submissions/143228-copy-once-past-anywhere-copa,Copy Once Past Anywhere,02/23/2020 13:56:11,"Inspiration

Copy Once Past Anywhere

What it does

This is an app that helps users to copy text from mobile to desktop in a simple and easy manner. Whenever the user copies any text to clipboard in the mobile, it gets copied to the clipboard in the desktop or laptop. Similarly, if users copy any text to clipboard in the desktop, it gets automatically copied to the Mobile clipboard. Users should have both Android app (installed in their mobile) and Desktop app installed. 

How I built it

We used Java for Android app development, electron.js for cross-platform Desktop app. The backend services are written in Node.js, using MongoDB as our database. The services and database are deployed on Google Cloud platform using Docker.

Challenges I ran into

We used websockets for sending clipboard data to mobile from desktop and vice versa. We faced challenges in ensuring proper working of this feature using websockets, which was very important from the performance point of view. Apart from this, we faced challenges in integrating different service and apps.

Accomplishments that I'm proud of

What I learned

What's next for Copy Once Past Anywhere- COPA

Following would be the future improvements:


Authentication feature
Building iOS app

",,https://github.com/rajchandak/HackCU,,"",University of Colorado Boulder,"","",Google Cloud,vishy_kulk,vishwanath,kulkarni,vishwa.kulkarni@gmail.com,"MSRIT, University of Colorado at Boulder",2,maai8912,Madhusudhan,Aithal Mahabhaleshwara,maai8912@colorado.edu,rajchandak,Raj,Chandak,raj.chandak@colorado.edu
Empowering Underrepresented People in Tech,CS[U]mentoring,https://hackcu-vi.devpost.com/submissions/143229-cs-u-mentoring,Mentor Database,02/23/2020 13:56:18,"hackCU2020

Mentor Database
",,https://github.com/ashlynrlee/hackCU2020,,python,Colorado State University,"","","",ashlynrlee,ashlynrlee,Lee,alee13@rams.colostate.edu,Colorado State University,0
Best UX/UI,Catch-Taboo,https://hackcu-vi.devpost.com/submissions/143230-catch-taboo,A fun chaotic mobile game to play with friends. Catch-Taboo incorporates elements from both the game catchphrase and taboo.,02/23/2020 13:56:25,"A super fun game to play with friends.
",,https://github.com/LEL-15/Catch-Taboo,,"java, android-studio, firebase",University of Colorado at Boulder,"","","",JosephineMartin,Josephine,Martin,joma1927@colorado.edu,University of Colorado at Boulder,1,LEL-15,Elly,Landrum,elly.landrum@colorado.edu
Most Random,Catch-Taboo,https://hackcu-vi.devpost.com/submissions/143230-catch-taboo,A fun chaotic mobile game to play with friends. Catch-Taboo incorporates elements from both the game catchphrase and taboo.,02/23/2020 13:56:25,"A super fun game to play with friends.
",,https://github.com/LEL-15/Catch-Taboo,,"java, android-studio, firebase",University of Colorado at Boulder,"","","",JosephineMartin,Josephine,Martin,joma1927@colorado.edu,University of Colorado at Boulder,1,LEL-15,Elly,Landrum,elly.landrum@colorado.edu
Empowering Underrepresented People in Tech,Simp Detector,https://hackcu-vi.devpost.com/submissions/143231-simp-detector,We are preventing girls from getting simped so we created a bot to detect simps and then we empower women to learn computer science by tweeting codecademy.org,02/23/2020 13:56:29,"Inspiration

too many simps on twitter

What it does

detects simps

How I built it

with tweepy, python

Challenges I ran into

duplicate simps

Accomplishments that I'm proud of

we got some simps to delete their tweets

What I learned

simps are everywhere

What's next for Simp Detector

Machine learning, Markov Decision Processes
",,https://github.com/etka4463/simp-detector-hack-cu.git,,"python, tweepy",University of Colorado Boulder,"","","",etka4463,etka4463,Kalra,etka4463@colorado.edu,University of Colorado at Boulder,0
Most Creative Usage of Twitter API,Simp Detector,https://hackcu-vi.devpost.com/submissions/143231-simp-detector,We are preventing girls from getting simped so we created a bot to detect simps and then we empower women to learn computer science by tweeting codecademy.org,02/23/2020 13:56:29,"Inspiration

too many simps on twitter

What it does

detects simps

How I built it

with tweepy, python

Challenges I ran into

duplicate simps

Accomplishments that I'm proud of

we got some simps to delete their tweets

What I learned

simps are everywhere

What's next for Simp Detector

Machine learning, Markov Decision Processes
",,https://github.com/etka4463/simp-detector-hack-cu.git,,"python, tweepy",University of Colorado Boulder,"","","",etka4463,etka4463,Kalra,etka4463@colorado.edu,University of Colorado at Boulder,0
Social Impact,Simp Detector,https://hackcu-vi.devpost.com/submissions/143231-simp-detector,We are preventing girls from getting simped so we created a bot to detect simps and then we empower women to learn computer science by tweeting codecademy.org,02/23/2020 13:56:29,"Inspiration

too many simps on twitter

What it does

detects simps

How I built it

with tweepy, python

Challenges I ran into

duplicate simps

Accomplishments that I'm proud of

we got some simps to delete their tweets

What I learned

simps are everywhere

What's next for Simp Detector

Machine learning, Markov Decision Processes
",,https://github.com/etka4463/simp-detector-hack-cu.git,,"python, tweepy",University of Colorado Boulder,"","","",etka4463,etka4463,Kalra,etka4463@colorado.edu,University of Colorado at Boulder,0
Best UX/UI,Simp Detector,https://hackcu-vi.devpost.com/submissions/143231-simp-detector,We are preventing girls from getting simped so we created a bot to detect simps and then we empower women to learn computer science by tweeting codecademy.org,02/23/2020 13:56:29,"Inspiration

too many simps on twitter

What it does

detects simps

How I built it

with tweepy, python

Challenges I ran into

duplicate simps

Accomplishments that I'm proud of

we got some simps to delete their tweets

What I learned

simps are everywhere

What's next for Simp Detector

Machine learning, Markov Decision Processes
",,https://github.com/etka4463/simp-detector-hack-cu.git,,"python, tweepy",University of Colorado Boulder,"","","",etka4463,etka4463,Kalra,etka4463@colorado.edu,University of Colorado at Boulder,0
Most Random,Simp Detector,https://hackcu-vi.devpost.com/submissions/143231-simp-detector,We are preventing girls from getting simped so we created a bot to detect simps and then we empower women to learn computer science by tweeting codecademy.org,02/23/2020 13:56:29,"Inspiration

too many simps on twitter

What it does

detects simps

How I built it

with tweepy, python

Challenges I ran into

duplicate simps

Accomplishments that I'm proud of

we got some simps to delete their tweets

What I learned

simps are everywhere

What's next for Simp Detector

Machine learning, Markov Decision Processes
",,https://github.com/etka4463/simp-detector-hack-cu.git,,"python, tweepy",University of Colorado Boulder,"","","",etka4463,etka4463,Kalra,etka4463@colorado.edu,University of Colorado at Boulder,0
All Beginner,Simp Detector,https://hackcu-vi.devpost.com/submissions/143231-simp-detector,We are preventing girls from getting simped so we created a bot to detect simps and then we empower women to learn computer science by tweeting codecademy.org,02/23/2020 13:56:29,"Inspiration

too many simps on twitter

What it does

detects simps

How I built it

with tweepy, python

Challenges I ran into

duplicate simps

Accomplishments that I'm proud of

we got some simps to delete their tweets

What I learned

simps are everywhere

What's next for Simp Detector

Machine learning, Markov Decision Processes
",,https://github.com/etka4463/simp-detector-hack-cu.git,,"python, tweepy",University of Colorado Boulder,"","","",etka4463,etka4463,Kalra,etka4463@colorado.edu,University of Colorado at Boulder,0
Best Use of TapWithUS SDK,Robot controlled via Tap Strap,https://hackcu-vi.devpost.com/submissions/143232-robot-controlled-via-tap-strap,The device is envisioned as a controller for robots or rovers in situations where the use of an actual remote controller may imply operational risks. ,02/23/2020 13:56:36,"Inspiration

Space exploration is nowadays one of the biggest priorities of humanity. It poses lots of technological challenges that we, as a society, will need to overcome. In this context, robots will become crucial to conduct many tasks within the hostile environment that is the space. That inspired us to design a tool to control such devices, like robotic arms in the vacuum of space or rovers in the surface of a planet, without the need of an actual controller. We saw in Tap Strap a potential tool to do so, and we have proved it is indeed the perfect instrument.  

What it does

With 5 easy and different gestures, you can order a robot to perform tasks rather than using a flamboyant controller.

How I built it

We created an interface with C# which enables the user to translate the gestures of the TAP Strap device into inputs that the robot firmware, designed with Arduino, can interpret. 

Challenges I ran into

It has been hard to understand the code the TAP tool was based on. Specifically, it has been hard to get raw data from the 7 sensors of the device. This has been challenging, but succeeding on it has been extremely rewarding and an amazing learning experience.

Accomplishments that I'm proud of

Getting to see the robot acting accordingly to the gestures performed by the user.

What I learned

It has been a HUGE learning experience. Both in terms of coding and understanding the complex data sent by the accelerometers. 

What's next for Robot controlled via Tap Strap

Again, we see outstanding capabilities in the Tap Strap device within the control environment.

The project is available: https://github.com/eudald-alex/Hackcu_robot_tap
",,https://github.com/eudald-alex/Hackcu_robot_tap,,"visual-studio, c#, xaml, .net, arduino",University of Colorado Colorado Springs,"",Arduino 101,"",eudald-alex,eudald-alex,Sangenis,eudald.sangenis@gmail.com,University of Colorado at Colorado Springs,3,lluisumbert,lluisumbert,Umbert Amat,lluisumbert3@gmail.com,hpascualh,Héctor,Pascual Herrero,hpascualh@gmail.com,gcornella,,,gcornella15@gmail.com
MLH: Best use of MongoDB Atlas,Job Tracker,https://hackcu-vi.devpost.com/submissions/143233-job-tracker,Keep track of all of your appliations in once place. ,02/23/2020 13:56:51,"Inspiration

After some time, job searches can become tedious. You see the same listing over and over and eventually all the job titles and company names begin to blur together. 

What it does

We created a website the keeps all the places you have applied for in a neat table and added graphics so you can visualize your progress.

How we built it


MongoDB was used as our database
We used Flask as our web framework. 
The front-end was styled using Bootstrap. 
Google charts was responsible for our data visualizations.


Challenges we ran into

Neither of us had ever worked with MongoDB before. The only databases we have used before used SQL queries, so MongoDB was a very different to work with than what we were used to. 

Accomplishments that we're proud of

Something is working! :D

What we learned

We learned how to use MongoDB

What's next for Job Tracker
",,https://github.com/leungtw/hackcu_vi,,"python, bootstrap, html5, css3, flask, beautiful-soup, mongodb, jinja",2,"","","",tanyawleung,Tanya,Leung,tanya.wleung@gmail.com,"",0
Best UX/UI,Job Tracker,https://hackcu-vi.devpost.com/submissions/143233-job-tracker,Keep track of all of your appliations in once place. ,02/23/2020 13:56:51,"Inspiration

After some time, job searches can become tedious. You see the same listing over and over and eventually all the job titles and company names begin to blur together. 

What it does

We created a website the keeps all the places you have applied for in a neat table and added graphics so you can visualize your progress.

How we built it


MongoDB was used as our database
We used Flask as our web framework. 
The front-end was styled using Bootstrap. 
Google charts was responsible for our data visualizations.


Challenges we ran into

Neither of us had ever worked with MongoDB before. The only databases we have used before used SQL queries, so MongoDB was a very different to work with than what we were used to. 

Accomplishments that we're proud of

Something is working! :D

What we learned

We learned how to use MongoDB

What's next for Job Tracker
",,https://github.com/leungtw/hackcu_vi,,"python, bootstrap, html5, css3, flask, beautiful-soup, mongodb, jinja",2,"","","",tanyawleung,Tanya,Leung,tanya.wleung@gmail.com,"",0
Empowering Underrepresented People in Tech,ChefAR,https://hackcu-vi.devpost.com/submissions/143234-chefar,Learn to cook in just minutes using mixed reality,02/23/2020 13:56:56,"Inspiration

Learning to cook can be difficult. Even more so, deciding on the right recipe with your limited ingredients can be a chore. This is where ChefAR comes in. 

What it does

ChefAR is a mixed reality platform that recommends recipes to users. Users take an image of their pantry / fridge / ingredients, and ChefAR will recommend recipes to them. This will allow users to learn about recipes they may not have previously considered, and narrow down their options to a recipe they want to make. 

How we built it

Our back-end is built using the Google API Cloud platform. We take an image on our MagicLeap AR headset, send that image via an HTTP request to the Google API Cloud platform, and receive JSON text back about all the detected objects in the image. We parse this text to display all determined ingredients on the screen. Currently, we are showing all objects - including non-food items. In the future, we would only show food items to the user.

We currently have a very basic backend working that determines if specific food ingredients are contained in the parsed text. For example, if a pineapple is found in the text but not a banana, we will recommend pineapple juice. If a banana is found and not a pineapple, we will recommend a banana smoothie. In the future, we hope to expand this product to pull recipes from the web and make actual recipe recommendations to the user. Also, we would hope to implement a scroll bar that allows users to actually scroll through recipes rather than only having a single recipe generated.

For the front-end, we used the UI components contained in Unity. We built a menu screen that then opens into the main screen. This main screen has a ""Go back"" button, a ""Take picture"" button to send a picture to the Google API, and a ""Select Recipe"" button, which shows a recipe based on the found ingredients in the scene.

Challenges we ran into

Our biggest challenge was sending an image from MagicLeap to some platform to generate the items found in the image. We first explored three paths: 

1.) Sending the image to Python and running the YOLO (open-source state-of-the-art, real-time object detection system) platform to classify objects 

2.) Sending an HTTP request to Microsoft Azure Computer Vision and 

3.) Sending an HTTP request to the Google API directly from MagicLeap. 

Because we ran out of credits with option 2, we ended up pursuing option 3. We pursued this over option 1 since it took less processing time to classify objects in the image. 

Accomplishments that we're proud of

We're very proud we overcame the obstacle of classifying objects on the MagicLeap. We were concerned this would not work because it is not easy to send images from the MagicLeap to other sources. Furthermore, we are proud of our front-end design at its current state.

What we learned

We learned about how to better connect the MagicLeap between other platforms. Much of the documentation for MagicLeap is only interacting between Unity and the headset. In this project, we were able to connect to Python, Microsoft Azure, and the Google API. This is very promising for the future of AR and continuing to build on other platforms.

We also learned more about game development and UI's within Unity. We learned more about the flow of scenes, how to create and interact with buttons, and how to add augmented overlays. 

What's next for ChefAR

Our next big step will be to add a menu of recipes rather than generating a singular recipe for the user. This will allow them options to choose from that they can scroll through, and then they can select the desired recipe. Once selected, the required ingredients will be given in the usual textbox. In extending this, we would plan to generate a whole new scene that the user would move to and would allow them to scroll through recipes. We would add a  ""select recipe"" button for them to choose. 
",,,,"magicleap, unity, google, yolo",Colorado School of Mines,"","",Google Cloud,megatran,Nhan,Tran,nhantrantnt@gmail.com,Colorado School of Mines,3,aorden,Orden,Aitchedji,oaitchedji@mines.edu,nataliekalin,Natalie,Kalin,nataliekalin@mymail.mines.edu,chatwitherica,Erica,West,chatwitherica@gmail.com
Social Impact,ChefAR,https://hackcu-vi.devpost.com/submissions/143234-chefar,Learn to cook in just minutes using mixed reality,02/23/2020 13:56:56,"Inspiration

Learning to cook can be difficult. Even more so, deciding on the right recipe with your limited ingredients can be a chore. This is where ChefAR comes in. 

What it does

ChefAR is a mixed reality platform that recommends recipes to users. Users take an image of their pantry / fridge / ingredients, and ChefAR will recommend recipes to them. This will allow users to learn about recipes they may not have previously considered, and narrow down their options to a recipe they want to make. 

How we built it

Our back-end is built using the Google API Cloud platform. We take an image on our MagicLeap AR headset, send that image via an HTTP request to the Google API Cloud platform, and receive JSON text back about all the detected objects in the image. We parse this text to display all determined ingredients on the screen. Currently, we are showing all objects - including non-food items. In the future, we would only show food items to the user.

We currently have a very basic backend working that determines if specific food ingredients are contained in the parsed text. For example, if a pineapple is found in the text but not a banana, we will recommend pineapple juice. If a banana is found and not a pineapple, we will recommend a banana smoothie. In the future, we hope to expand this product to pull recipes from the web and make actual recipe recommendations to the user. Also, we would hope to implement a scroll bar that allows users to actually scroll through recipes rather than only having a single recipe generated.

For the front-end, we used the UI components contained in Unity. We built a menu screen that then opens into the main screen. This main screen has a ""Go back"" button, a ""Take picture"" button to send a picture to the Google API, and a ""Select Recipe"" button, which shows a recipe based on the found ingredients in the scene.

Challenges we ran into

Our biggest challenge was sending an image from MagicLeap to some platform to generate the items found in the image. We first explored three paths: 

1.) Sending the image to Python and running the YOLO (open-source state-of-the-art, real-time object detection system) platform to classify objects 

2.) Sending an HTTP request to Microsoft Azure Computer Vision and 

3.) Sending an HTTP request to the Google API directly from MagicLeap. 

Because we ran out of credits with option 2, we ended up pursuing option 3. We pursued this over option 1 since it took less processing time to classify objects in the image. 

Accomplishments that we're proud of

We're very proud we overcame the obstacle of classifying objects on the MagicLeap. We were concerned this would not work because it is not easy to send images from the MagicLeap to other sources. Furthermore, we are proud of our front-end design at its current state.

What we learned

We learned about how to better connect the MagicLeap between other platforms. Much of the documentation for MagicLeap is only interacting between Unity and the headset. In this project, we were able to connect to Python, Microsoft Azure, and the Google API. This is very promising for the future of AR and continuing to build on other platforms.

We also learned more about game development and UI's within Unity. We learned more about the flow of scenes, how to create and interact with buttons, and how to add augmented overlays. 

What's next for ChefAR

Our next big step will be to add a menu of recipes rather than generating a singular recipe for the user. This will allow them options to choose from that they can scroll through, and then they can select the desired recipe. Once selected, the required ingredients will be given in the usual textbox. In extending this, we would plan to generate a whole new scene that the user would move to and would allow them to scroll through recipes. We would add a  ""select recipe"" button for them to choose. 
",,,,"magicleap, unity, google, yolo",Colorado School of Mines,"","",Google Cloud,megatran,Nhan,Tran,nhantrantnt@gmail.com,Colorado School of Mines,3,aorden,Orden,Aitchedji,oaitchedji@mines.edu,nataliekalin,Natalie,Kalin,nataliekalin@mymail.mines.edu,chatwitherica,Erica,West,chatwitherica@gmail.com
Best UX/UI,ChefAR,https://hackcu-vi.devpost.com/submissions/143234-chefar,Learn to cook in just minutes using mixed reality,02/23/2020 13:56:56,"Inspiration

Learning to cook can be difficult. Even more so, deciding on the right recipe with your limited ingredients can be a chore. This is where ChefAR comes in. 

What it does

ChefAR is a mixed reality platform that recommends recipes to users. Users take an image of their pantry / fridge / ingredients, and ChefAR will recommend recipes to them. This will allow users to learn about recipes they may not have previously considered, and narrow down their options to a recipe they want to make. 

How we built it

Our back-end is built using the Google API Cloud platform. We take an image on our MagicLeap AR headset, send that image via an HTTP request to the Google API Cloud platform, and receive JSON text back about all the detected objects in the image. We parse this text to display all determined ingredients on the screen. Currently, we are showing all objects - including non-food items. In the future, we would only show food items to the user.

We currently have a very basic backend working that determines if specific food ingredients are contained in the parsed text. For example, if a pineapple is found in the text but not a banana, we will recommend pineapple juice. If a banana is found and not a pineapple, we will recommend a banana smoothie. In the future, we hope to expand this product to pull recipes from the web and make actual recipe recommendations to the user. Also, we would hope to implement a scroll bar that allows users to actually scroll through recipes rather than only having a single recipe generated.

For the front-end, we used the UI components contained in Unity. We built a menu screen that then opens into the main screen. This main screen has a ""Go back"" button, a ""Take picture"" button to send a picture to the Google API, and a ""Select Recipe"" button, which shows a recipe based on the found ingredients in the scene.

Challenges we ran into

Our biggest challenge was sending an image from MagicLeap to some platform to generate the items found in the image. We first explored three paths: 

1.) Sending the image to Python and running the YOLO (open-source state-of-the-art, real-time object detection system) platform to classify objects 

2.) Sending an HTTP request to Microsoft Azure Computer Vision and 

3.) Sending an HTTP request to the Google API directly from MagicLeap. 

Because we ran out of credits with option 2, we ended up pursuing option 3. We pursued this over option 1 since it took less processing time to classify objects in the image. 

Accomplishments that we're proud of

We're very proud we overcame the obstacle of classifying objects on the MagicLeap. We were concerned this would not work because it is not easy to send images from the MagicLeap to other sources. Furthermore, we are proud of our front-end design at its current state.

What we learned

We learned about how to better connect the MagicLeap between other platforms. Much of the documentation for MagicLeap is only interacting between Unity and the headset. In this project, we were able to connect to Python, Microsoft Azure, and the Google API. This is very promising for the future of AR and continuing to build on other platforms.

We also learned more about game development and UI's within Unity. We learned more about the flow of scenes, how to create and interact with buttons, and how to add augmented overlays. 

What's next for ChefAR

Our next big step will be to add a menu of recipes rather than generating a singular recipe for the user. This will allow them options to choose from that they can scroll through, and then they can select the desired recipe. Once selected, the required ingredients will be given in the usual textbox. In extending this, we would plan to generate a whole new scene that the user would move to and would allow them to scroll through recipes. We would add a  ""select recipe"" button for them to choose. 
",,,,"magicleap, unity, google, yolo",Colorado School of Mines,"","",Google Cloud,megatran,Nhan,Tran,nhantrantnt@gmail.com,Colorado School of Mines,3,aorden,Orden,Aitchedji,oaitchedji@mines.edu,nataliekalin,Natalie,Kalin,nataliekalin@mymail.mines.edu,chatwitherica,Erica,West,chatwitherica@gmail.com
Most Random,ChefAR,https://hackcu-vi.devpost.com/submissions/143234-chefar,Learn to cook in just minutes using mixed reality,02/23/2020 13:56:56,"Inspiration

Learning to cook can be difficult. Even more so, deciding on the right recipe with your limited ingredients can be a chore. This is where ChefAR comes in. 

What it does

ChefAR is a mixed reality platform that recommends recipes to users. Users take an image of their pantry / fridge / ingredients, and ChefAR will recommend recipes to them. This will allow users to learn about recipes they may not have previously considered, and narrow down their options to a recipe they want to make. 

How we built it

Our back-end is built using the Google API Cloud platform. We take an image on our MagicLeap AR headset, send that image via an HTTP request to the Google API Cloud platform, and receive JSON text back about all the detected objects in the image. We parse this text to display all determined ingredients on the screen. Currently, we are showing all objects - including non-food items. In the future, we would only show food items to the user.

We currently have a very basic backend working that determines if specific food ingredients are contained in the parsed text. For example, if a pineapple is found in the text but not a banana, we will recommend pineapple juice. If a banana is found and not a pineapple, we will recommend a banana smoothie. In the future, we hope to expand this product to pull recipes from the web and make actual recipe recommendations to the user. Also, we would hope to implement a scroll bar that allows users to actually scroll through recipes rather than only having a single recipe generated.

For the front-end, we used the UI components contained in Unity. We built a menu screen that then opens into the main screen. This main screen has a ""Go back"" button, a ""Take picture"" button to send a picture to the Google API, and a ""Select Recipe"" button, which shows a recipe based on the found ingredients in the scene.

Challenges we ran into

Our biggest challenge was sending an image from MagicLeap to some platform to generate the items found in the image. We first explored three paths: 

1.) Sending the image to Python and running the YOLO (open-source state-of-the-art, real-time object detection system) platform to classify objects 

2.) Sending an HTTP request to Microsoft Azure Computer Vision and 

3.) Sending an HTTP request to the Google API directly from MagicLeap. 

Because we ran out of credits with option 2, we ended up pursuing option 3. We pursued this over option 1 since it took less processing time to classify objects in the image. 

Accomplishments that we're proud of

We're very proud we overcame the obstacle of classifying objects on the MagicLeap. We were concerned this would not work because it is not easy to send images from the MagicLeap to other sources. Furthermore, we are proud of our front-end design at its current state.

What we learned

We learned about how to better connect the MagicLeap between other platforms. Much of the documentation for MagicLeap is only interacting between Unity and the headset. In this project, we were able to connect to Python, Microsoft Azure, and the Google API. This is very promising for the future of AR and continuing to build on other platforms.

We also learned more about game development and UI's within Unity. We learned more about the flow of scenes, how to create and interact with buttons, and how to add augmented overlays. 

What's next for ChefAR

Our next big step will be to add a menu of recipes rather than generating a singular recipe for the user. This will allow them options to choose from that they can scroll through, and then they can select the desired recipe. Once selected, the required ingredients will be given in the usual textbox. In extending this, we would plan to generate a whole new scene that the user would move to and would allow them to scroll through recipes. We would add a  ""select recipe"" button for them to choose. 
",,,,"magicleap, unity, google, yolo",Colorado School of Mines,"","",Google Cloud,megatran,Nhan,Tran,nhantrantnt@gmail.com,Colorado School of Mines,3,aorden,Orden,Aitchedji,oaitchedji@mines.edu,nataliekalin,Natalie,Kalin,nataliekalin@mymail.mines.edu,chatwitherica,Erica,West,chatwitherica@gmail.com
MLH: Best Use of Google Cloud,ChefAR,https://hackcu-vi.devpost.com/submissions/143234-chefar,Learn to cook in just minutes using mixed reality,02/23/2020 13:56:56,"Inspiration

Learning to cook can be difficult. Even more so, deciding on the right recipe with your limited ingredients can be a chore. This is where ChefAR comes in. 

What it does

ChefAR is a mixed reality platform that recommends recipes to users. Users take an image of their pantry / fridge / ingredients, and ChefAR will recommend recipes to them. This will allow users to learn about recipes they may not have previously considered, and narrow down their options to a recipe they want to make. 

How we built it

Our back-end is built using the Google API Cloud platform. We take an image on our MagicLeap AR headset, send that image via an HTTP request to the Google API Cloud platform, and receive JSON text back about all the detected objects in the image. We parse this text to display all determined ingredients on the screen. Currently, we are showing all objects - including non-food items. In the future, we would only show food items to the user.

We currently have a very basic backend working that determines if specific food ingredients are contained in the parsed text. For example, if a pineapple is found in the text but not a banana, we will recommend pineapple juice. If a banana is found and not a pineapple, we will recommend a banana smoothie. In the future, we hope to expand this product to pull recipes from the web and make actual recipe recommendations to the user. Also, we would hope to implement a scroll bar that allows users to actually scroll through recipes rather than only having a single recipe generated.

For the front-end, we used the UI components contained in Unity. We built a menu screen that then opens into the main screen. This main screen has a ""Go back"" button, a ""Take picture"" button to send a picture to the Google API, and a ""Select Recipe"" button, which shows a recipe based on the found ingredients in the scene.

Challenges we ran into

Our biggest challenge was sending an image from MagicLeap to some platform to generate the items found in the image. We first explored three paths: 

1.) Sending the image to Python and running the YOLO (open-source state-of-the-art, real-time object detection system) platform to classify objects 

2.) Sending an HTTP request to Microsoft Azure Computer Vision and 

3.) Sending an HTTP request to the Google API directly from MagicLeap. 

Because we ran out of credits with option 2, we ended up pursuing option 3. We pursued this over option 1 since it took less processing time to classify objects in the image. 

Accomplishments that we're proud of

We're very proud we overcame the obstacle of classifying objects on the MagicLeap. We were concerned this would not work because it is not easy to send images from the MagicLeap to other sources. Furthermore, we are proud of our front-end design at its current state.

What we learned

We learned about how to better connect the MagicLeap between other platforms. Much of the documentation for MagicLeap is only interacting between Unity and the headset. In this project, we were able to connect to Python, Microsoft Azure, and the Google API. This is very promising for the future of AR and continuing to build on other platforms.

We also learned more about game development and UI's within Unity. We learned more about the flow of scenes, how to create and interact with buttons, and how to add augmented overlays. 

What's next for ChefAR

Our next big step will be to add a menu of recipes rather than generating a singular recipe for the user. This will allow them options to choose from that they can scroll through, and then they can select the desired recipe. Once selected, the required ingredients will be given in the usual textbox. In extending this, we would plan to generate a whole new scene that the user would move to and would allow them to scroll through recipes. We would add a  ""select recipe"" button for them to choose. 
",,,,"magicleap, unity, google, yolo",Colorado School of Mines,"","",Google Cloud,megatran,Nhan,Tran,nhantrantnt@gmail.com,Colorado School of Mines,3,aorden,Orden,Aitchedji,oaitchedji@mines.edu,nataliekalin,Natalie,Kalin,nataliekalin@mymail.mines.edu,chatwitherica,Erica,West,chatwitherica@gmail.com
Sustainability,ChefAR,https://hackcu-vi.devpost.com/submissions/143234-chefar,Learn to cook in just minutes using mixed reality,02/23/2020 13:56:56,"Inspiration

Learning to cook can be difficult. Even more so, deciding on the right recipe with your limited ingredients can be a chore. This is where ChefAR comes in. 

What it does

ChefAR is a mixed reality platform that recommends recipes to users. Users take an image of their pantry / fridge / ingredients, and ChefAR will recommend recipes to them. This will allow users to learn about recipes they may not have previously considered, and narrow down their options to a recipe they want to make. 

How we built it

Our back-end is built using the Google API Cloud platform. We take an image on our MagicLeap AR headset, send that image via an HTTP request to the Google API Cloud platform, and receive JSON text back about all the detected objects in the image. We parse this text to display all determined ingredients on the screen. Currently, we are showing all objects - including non-food items. In the future, we would only show food items to the user.

We currently have a very basic backend working that determines if specific food ingredients are contained in the parsed text. For example, if a pineapple is found in the text but not a banana, we will recommend pineapple juice. If a banana is found and not a pineapple, we will recommend a banana smoothie. In the future, we hope to expand this product to pull recipes from the web and make actual recipe recommendations to the user. Also, we would hope to implement a scroll bar that allows users to actually scroll through recipes rather than only having a single recipe generated.

For the front-end, we used the UI components contained in Unity. We built a menu screen that then opens into the main screen. This main screen has a ""Go back"" button, a ""Take picture"" button to send a picture to the Google API, and a ""Select Recipe"" button, which shows a recipe based on the found ingredients in the scene.

Challenges we ran into

Our biggest challenge was sending an image from MagicLeap to some platform to generate the items found in the image. We first explored three paths: 

1.) Sending the image to Python and running the YOLO (open-source state-of-the-art, real-time object detection system) platform to classify objects 

2.) Sending an HTTP request to Microsoft Azure Computer Vision and 

3.) Sending an HTTP request to the Google API directly from MagicLeap. 

Because we ran out of credits with option 2, we ended up pursuing option 3. We pursued this over option 1 since it took less processing time to classify objects in the image. 

Accomplishments that we're proud of

We're very proud we overcame the obstacle of classifying objects on the MagicLeap. We were concerned this would not work because it is not easy to send images from the MagicLeap to other sources. Furthermore, we are proud of our front-end design at its current state.

What we learned

We learned about how to better connect the MagicLeap between other platforms. Much of the documentation for MagicLeap is only interacting between Unity and the headset. In this project, we were able to connect to Python, Microsoft Azure, and the Google API. This is very promising for the future of AR and continuing to build on other platforms.

We also learned more about game development and UI's within Unity. We learned more about the flow of scenes, how to create and interact with buttons, and how to add augmented overlays. 

What's next for ChefAR

Our next big step will be to add a menu of recipes rather than generating a singular recipe for the user. This will allow them options to choose from that they can scroll through, and then they can select the desired recipe. Once selected, the required ingredients will be given in the usual textbox. In extending this, we would plan to generate a whole new scene that the user would move to and would allow them to scroll through recipes. We would add a  ""select recipe"" button for them to choose. 
",,,,"magicleap, unity, google, yolo",Colorado School of Mines,"","",Google Cloud,megatran,Nhan,Tran,nhantrantnt@gmail.com,Colorado School of Mines,3,aorden,Orden,Aitchedji,oaitchedji@mines.edu,nataliekalin,Natalie,Kalin,nataliekalin@mymail.mines.edu,chatwitherica,Erica,West,chatwitherica@gmail.com
Most Creative Usage of Twitter API,Political Hacks,https://hackcu-vi.devpost.com/submissions/143235-political-hacks,Political-Hacks predicts election results and voter turnout by analyzing political tweet frequency and sentiment.,02/23/2020 13:57:01,"Inspiration: Current political events taking place and analyzing the conversation people were having on Twitter, and if that is a reliable indicator of how people vote.

What it does: The web application continuously displays real-time sentiment analysis of political tweets of people with respect to their location. The backend pipeline is ingesting the twitter API and performing sentiment analysis on the tweets that filter it as political.

How I built it: The application pulls the real-time data with the Twitter APIs, filters the data on some keywords to identify if the tweets fall into the political category. This data is then further analyzed and sent to Google's inference API, which uses Natural Language Processing and performs the sentiment analysis to classify the tweets in four categories: Red+, Red-, Blue+, Blue-. This data is then pushed to the relational database called big query to perform analytics. The web application continuously queries the database to fetch the aggregated sentiment results for each state and displays it at the interval of every 3 seconds. The entire application is deployed using the Kubernetes engine of the Google Cloud Platform. The application when runs, displays the d3 Map of the United States, continuously fetching the real-time data, processing it and displaying the sentiments of the people of different states.

Challenges I ran into - Deploying the service on Kubernetes was one of the challenges we faced. Also, handling a lot of data from the live stream generated as a call to the twitter API was a challenge.

Accomplishments that I'm proud of: The application helps in identifying the real-time data and helps us to understand how people in different locations follow politics and have an opinion about different political parties.

What I learned: Learned technologies that made coding, integrating and collaborating a lot easier. With the help of the google cloud platform, where we had everything in one place, from databases to application deployments overcoming all the dependencies, it became a lot easier to build the application.

What's next for Political Hacks:  We could scale our application to display the data where the statistics of individual cities are also shown along with the statistics of the state.
",https://youtu.be/f5QpvPnVbFs,https://github.com/CUBigDataClass/political-hacks,,"javascript, python, docker, kubernetes, google-bigquery, natural-language-processing, flask, d3.js, twitter",University of Colorado Boulder,politicalhacks.tech,"",Google Cloud,anushagupta26,Anusha,Gupta,anusha.gupta@colorado.edu,University of Colorado at Boulder,2,duanweifan,Duan-Wei,Fan,duanwei.fan@colorado.edu,anirudhrathore,Anirudh,Rathore,anirudh.rathore@colorado.edu
Social Impact,Political Hacks,https://hackcu-vi.devpost.com/submissions/143235-political-hacks,Political-Hacks predicts election results and voter turnout by analyzing political tweet frequency and sentiment.,02/23/2020 13:57:01,"Inspiration: Current political events taking place and analyzing the conversation people were having on Twitter, and if that is a reliable indicator of how people vote.

What it does: The web application continuously displays real-time sentiment analysis of political tweets of people with respect to their location. The backend pipeline is ingesting the twitter API and performing sentiment analysis on the tweets that filter it as political.

How I built it: The application pulls the real-time data with the Twitter APIs, filters the data on some keywords to identify if the tweets fall into the political category. This data is then further analyzed and sent to Google's inference API, which uses Natural Language Processing and performs the sentiment analysis to classify the tweets in four categories: Red+, Red-, Blue+, Blue-. This data is then pushed to the relational database called big query to perform analytics. The web application continuously queries the database to fetch the aggregated sentiment results for each state and displays it at the interval of every 3 seconds. The entire application is deployed using the Kubernetes engine of the Google Cloud Platform. The application when runs, displays the d3 Map of the United States, continuously fetching the real-time data, processing it and displaying the sentiments of the people of different states.

Challenges I ran into - Deploying the service on Kubernetes was one of the challenges we faced. Also, handling a lot of data from the live stream generated as a call to the twitter API was a challenge.

Accomplishments that I'm proud of: The application helps in identifying the real-time data and helps us to understand how people in different locations follow politics and have an opinion about different political parties.

What I learned: Learned technologies that made coding, integrating and collaborating a lot easier. With the help of the google cloud platform, where we had everything in one place, from databases to application deployments overcoming all the dependencies, it became a lot easier to build the application.

What's next for Political Hacks:  We could scale our application to display the data where the statistics of individual cities are also shown along with the statistics of the state.
",https://youtu.be/f5QpvPnVbFs,https://github.com/CUBigDataClass/political-hacks,,"javascript, python, docker, kubernetes, google-bigquery, natural-language-processing, flask, d3.js, twitter",University of Colorado Boulder,politicalhacks.tech,"",Google Cloud,anushagupta26,Anusha,Gupta,anusha.gupta@colorado.edu,University of Colorado at Boulder,2,duanweifan,Duan-Wei,Fan,duanwei.fan@colorado.edu,anirudhrathore,Anirudh,Rathore,anirudh.rathore@colorado.edu
MLH: Best Use of Google Cloud,Political Hacks,https://hackcu-vi.devpost.com/submissions/143235-political-hacks,Political-Hacks predicts election results and voter turnout by analyzing political tweet frequency and sentiment.,02/23/2020 13:57:01,"Inspiration: Current political events taking place and analyzing the conversation people were having on Twitter, and if that is a reliable indicator of how people vote.

What it does: The web application continuously displays real-time sentiment analysis of political tweets of people with respect to their location. The backend pipeline is ingesting the twitter API and performing sentiment analysis on the tweets that filter it as political.

How I built it: The application pulls the real-time data with the Twitter APIs, filters the data on some keywords to identify if the tweets fall into the political category. This data is then further analyzed and sent to Google's inference API, which uses Natural Language Processing and performs the sentiment analysis to classify the tweets in four categories: Red+, Red-, Blue+, Blue-. This data is then pushed to the relational database called big query to perform analytics. The web application continuously queries the database to fetch the aggregated sentiment results for each state and displays it at the interval of every 3 seconds. The entire application is deployed using the Kubernetes engine of the Google Cloud Platform. The application when runs, displays the d3 Map of the United States, continuously fetching the real-time data, processing it and displaying the sentiments of the people of different states.

Challenges I ran into - Deploying the service on Kubernetes was one of the challenges we faced. Also, handling a lot of data from the live stream generated as a call to the twitter API was a challenge.

Accomplishments that I'm proud of: The application helps in identifying the real-time data and helps us to understand how people in different locations follow politics and have an opinion about different political parties.

What I learned: Learned technologies that made coding, integrating and collaborating a lot easier. With the help of the google cloud platform, where we had everything in one place, from databases to application deployments overcoming all the dependencies, it became a lot easier to build the application.

What's next for Political Hacks:  We could scale our application to display the data where the statistics of individual cities are also shown along with the statistics of the state.
",https://youtu.be/f5QpvPnVbFs,https://github.com/CUBigDataClass/political-hacks,,"javascript, python, docker, kubernetes, google-bigquery, natural-language-processing, flask, d3.js, twitter",University of Colorado Boulder,politicalhacks.tech,"",Google Cloud,anushagupta26,Anusha,Gupta,anusha.gupta@colorado.edu,University of Colorado at Boulder,2,duanweifan,Duan-Wei,Fan,duanwei.fan@colorado.edu,anirudhrathore,Anirudh,Rathore,anirudh.rathore@colorado.edu
Social Impact,Word Stories,https://hackcu-vi.devpost.com/submissions/143236-word-stories,Word stories uses AI to generate stories around the words you enter to help you learn the words of a new language,02/23/2020 13:57:23,"Inspiration

When I am learning new languages I am always frustrated and bored by lists of vocab. If only i could create fun contexts to help me memorize those words. And that is what our project tries to do!

What it does

Builds a story around the words that you enter into it. It shows you those words in another language to help you learn that language

How we built it

Python backed using the natural language processing library. We put it on the web using Flask.

Challenges we ran into

Finding good corpus to train language model on, finding balance between efficiency and performance, finding open source dictionary; Using flask to put everything online, none of us had done much with it before

Accomplishments that we're proud of

Generating semi-realistic ultra-poetic sentences with the words embedded into them. Well functioning webpage, everything connected!

What we learned

How to use flask to make a web app; embedding words in text generation

What's next for Word Stories

Improving language model, use web crawling to access webpage dictionaries
",,https://github.com/JazKarit/learn_languages,,"flask, python, heroku, nltk, html",University of Colorado Boulder,"","","",jaskritsingh,Jaskrit,Singh,jaskrit.singh@colorado.edu,University of Colorado at Boulder,1,hlhanhl,hlhanhl,,huilin.han@colorado.edu
Most Random,Word Stories,https://hackcu-vi.devpost.com/submissions/143236-word-stories,Word stories uses AI to generate stories around the words you enter to help you learn the words of a new language,02/23/2020 13:57:23,"Inspiration

When I am learning new languages I am always frustrated and bored by lists of vocab. If only i could create fun contexts to help me memorize those words. And that is what our project tries to do!

What it does

Builds a story around the words that you enter into it. It shows you those words in another language to help you learn that language

How we built it

Python backed using the natural language processing library. We put it on the web using Flask.

Challenges we ran into

Finding good corpus to train language model on, finding balance between efficiency and performance, finding open source dictionary; Using flask to put everything online, none of us had done much with it before

Accomplishments that we're proud of

Generating semi-realistic ultra-poetic sentences with the words embedded into them. Well functioning webpage, everything connected!

What we learned

How to use flask to make a web app; embedding words in text generation

What's next for Word Stories

Improving language model, use web crawling to access webpage dictionaries
",,https://github.com/JazKarit/learn_languages,,"flask, python, heroku, nltk, html",University of Colorado Boulder,"","","",jaskritsingh,Jaskrit,Singh,jaskrit.singh@colorado.edu,University of Colorado at Boulder,1,hlhanhl,hlhanhl,,huilin.han@colorado.edu
All Beginner,Scientific Calculator (Chrome Extension),https://hackcu-vi.devpost.com/submissions/143237-scientific-calculator-chrome-extension,"When you need to use a calculator, opening a separate page to do so is slow and inefficient. Our Chrome extension allows the use of an intuitive and powerful calculator without switching tabs.",02/23/2020 13:57:57,"Inspiration

The idea for this extension came from personal struggles.
Google Chrome allows for calculations to be done in the address bar, but its system is crude and hard to work with. https://www.desmos.com/scientific offers a better calculator, but loading up a website in a new tab is not ideal if you're trying to work quickly.
We wanted to be able to input a keyboard shortcut, have the calculator pop up right away, type in our equation(s), and close the calculator just by clicking away. The Chrome Extension format is ideal for this.

What it does

Once the extension is installed, it can be opened by clicking on its icon or with the keyboard shortcut Ctrl+M (Ctrl+Cmd+C for Mac). This will load the Desmos scientific calculator in the upper right hand corner of the screen, where a wide variety of operations can be performed: anything from simple computation to algebra to geometry.

How we built it

We attended the Chrome Extension workshop at HackCU to get some background on building an extension. We then visited the Desmos website and acquired their API, which is what is used to run the extension.

Challenges we ran into

Google Chrome does not allow most APIs to be used in extensions. Our solution was to download the API and include it as part of the extension file.

Accomplishments that we're proud of

The extension works beautifully and is something we actually want to use in our daily lives.

What we learned

We learned how to use HTML and JavaScript in a different context, and gained more familiarity working with APIs.

What's next for Calculator Chrome Extension

Hopefully we can get this added to the Chrome Web Store so it can easily be installed.
",,https://github.com/Devlintj/Scientific_Calculator-Chrome-Extension-,,"html, javascript, desmos-api",University of Colorado Boulder,"","","",nathanwilson1232,Nate,Wilson,nathan.wilson1232@gmail.com,University of Colorado at Boulder,1,tyde9651,Tyler,Devlin,tyde9651@colorado.edu
Social Impact,Get RECt,https://hackcu-vi.devpost.com/submissions/143238-get-rect,Never REC alone!,02/23/2020 13:58:31,"Inspiration

Students often find it difficult to find friends who share a common interest, especially in activities like playing sports or working out. 

What it does

Get RECt aims to connect students with shared interests in sports - particularly those that can be played in the Rec Center and matches them based on their preferences and skill level.

How we built it

We used Flutter for building the app, and Django for the backend APIs. 

Challenges we ran into

We were learning Flutter from scratch and it took us a long time to get a hang of it. Ultimately time was the biggest challenge.

Accomplishments that we're proud of

We got a fairly decent UI up and running on Flutter. The backend APIs were ready however the UI work took time to finish the integrations. 

What we learned

We mainly learnt how to leverage Flutter and Django to build an app.

What's next for Get RECt

We have a few more feature ideas in mind, which we feel are good to have and would greatly improve the app's capabilities. 
",,,,"django, flutter, sql, dart",CU Boulder,"","","",shreesubburaj,Shree Krishna,Subburaj,shree.subburaj@colorado.edu,"University of Colorado at Boulder, CU Boudler",2,vignesh2108,vignesh2108,,vignesh2108@gmail.com,arjun-rao,Arjun,Rao,mailarjunrao@gmail.com
Best UX/UI,Get RECt,https://hackcu-vi.devpost.com/submissions/143238-get-rect,Never REC alone!,02/23/2020 13:58:31,"Inspiration

Students often find it difficult to find friends who share a common interest, especially in activities like playing sports or working out. 

What it does

Get RECt aims to connect students with shared interests in sports - particularly those that can be played in the Rec Center and matches them based on their preferences and skill level.

How we built it

We used Flutter for building the app, and Django for the backend APIs. 

Challenges we ran into

We were learning Flutter from scratch and it took us a long time to get a hang of it. Ultimately time was the biggest challenge.

Accomplishments that we're proud of

We got a fairly decent UI up and running on Flutter. The backend APIs were ready however the UI work took time to finish the integrations. 

What we learned

We mainly learnt how to leverage Flutter and Django to build an app.

What's next for Get RECt

We have a few more feature ideas in mind, which we feel are good to have and would greatly improve the app's capabilities. 
",,,,"django, flutter, sql, dart",CU Boulder,"","","",shreesubburaj,Shree Krishna,Subburaj,shree.subburaj@colorado.edu,"University of Colorado at Boulder, CU Boudler",2,vignesh2108,vignesh2108,,vignesh2108@gmail.com,arjun-rao,Arjun,Rao,mailarjunrao@gmail.com
All Beginner,Get RECt,https://hackcu-vi.devpost.com/submissions/143238-get-rect,Never REC alone!,02/23/2020 13:58:31,"Inspiration

Students often find it difficult to find friends who share a common interest, especially in activities like playing sports or working out. 

What it does

Get RECt aims to connect students with shared interests in sports - particularly those that can be played in the Rec Center and matches them based on their preferences and skill level.

How we built it

We used Flutter for building the app, and Django for the backend APIs. 

Challenges we ran into

We were learning Flutter from scratch and it took us a long time to get a hang of it. Ultimately time was the biggest challenge.

Accomplishments that we're proud of

We got a fairly decent UI up and running on Flutter. The backend APIs were ready however the UI work took time to finish the integrations. 

What we learned

We mainly learnt how to leverage Flutter and Django to build an app.

What's next for Get RECt

We have a few more feature ideas in mind, which we feel are good to have and would greatly improve the app's capabilities. 
",,,,"django, flutter, sql, dart",CU Boulder,"","","",shreesubburaj,Shree Krishna,Subburaj,shree.subburaj@colorado.edu,"University of Colorado at Boulder, CU Boudler",2,vignesh2108,vignesh2108,,vignesh2108@gmail.com,arjun-rao,Arjun,Rao,mailarjunrao@gmail.com
Social Impact,Consume,https://hackcu-vi.devpost.com/submissions/143239-consume,"Our app connects restaurants and grocery stores with food banks in order to solve the global battle against food waste, help the environment, and provide access to food to those who need it most.",02/23/2020 13:58:37,"Inspiration

While brainstorming for this hackathon, a member of our team made a remark about how much food is wasted at our university dinning hall. This conversation continued, and we discussed that restaurants, grocery stores and other food outlets have a similar problem. Another member of the team commented that when they used to work a restaurant, the restaurant had perfectly safe, clean, and edible food at the end of the day, but the owners did not know what outlets existed for donating the extra food to people in need. There are millions of food insecure people in need, and extra food available that is being thrown away. Our team feels awful about the global food waste problem exists, and this inspired us to create a solution in order to fix this injustice.

What it does

Our app connects restaurants, schools, hotels, hospitals, and grocery stores with food banks in order to solve the global battle against food waste, help the environment, and provide access to food to those who need it most. Food suppliers (restaurants, schools, hotels, hospitals, and grocery stores) and food banks can go to our website, create a profile, and then schedule deliveries and pickups for extra food. Our goal with this application is to make the process of donating and receiving extra food as seamless as possible. Once food suppliers and food banks provide information such as the food they have, the food they need, and when they are open to donate and receive food, our app takes care of the rest. We developed an advanced algorithm to determine the most efficient routes for drivers to pick up food from food suppliers, and deliver them to food banks. The drivers for our platform are crowd sourced volunteers similar to Uber and Lyft. The driver is presented with the route they need to drive, and the food suppliers and food banks do not have to expel any additional effort.

How We built it

The graph algorithm approximates the Traveling Salesman algorithm. It separates different nodes of the graph into source and sink elements, estimates an ideal drop off for each food shelter, and then uses a preorder traversal of a minimum spanning tree to create the truck route. It's written in c++ with the Boost Graph api. We use JSON to define our data the algorithm runs on, and write another JSON file to be read and displayed in the website.  

What We learned

Our team learned that coming across annoying challenges and bugs are typical to the development process. We expanded our experience with full-stack development. In addition to this, we heavily researched global food waste, and the amount of food wasted, and people in need is devastating. Completing this project really opened our team's eyes into this problem and we are all more conscious about thew amount of food we eat and are more grateful for what we have. 

What's next for Consume - Food Waste Solution

Our team wants to improve Consume to work on mobile devices so that it is more accessible and easier to use for more people.
",,https://github.com/lnestelroad/HackCU2020.git,,"flask, python, sql, google-maps, c++, boost, json, bash, postgresql, docker, javascript, bootstrap",University of Colorado at Boulder,"","",Google Cloud,adampchehadi,Adam Powell,Chehadi,adampchehadi@gmail.com,"",0
Social Impact,HackCU2021,https://hackcu-vi.devpost.com/submissions/143240-hackcu2021,Hack CU website for 2021,02/23/2020 13:59:48,"Inspiration

After escaping our gated community (prison) the night before the competition and arriving early the day of, we not able to check-in due to the building being at ""maximum capacity"".  Since we pre-registered for the event weeks in advance and drove hours the night before, this experience inspired us to create a website for next year's HackCU. We then migrated to the nearest Starbucks and worked for the next 6 hours until doors opened again at 6 pm. 

What it does

This website allows users to register for the 2021 HackCU competition and ensures that those who register are guaranteed a spot at HackCU, because it decrements the number of available registration spots each time a competitor registers.  It then populates a database with the user's name, email, etc.. The website also notifies the user that registration is a first come, first serve basis. 

How we built it


This project was built completely using command line text editors and geeks for geeks


Challenges we ran into


Using Starbucks' wifi for 6 hours
doman.com's customer service (our domain still hasn't propagated)


Accomplishments that we're proud of


making a sql statement that runs
removing 100% of the vulnerabilities associated with Windows XP. 


What we learned


Arrive to HackCU 2 hours earlier next year.
mysql and php 


What's next for HackCU2021


hackcu2022.org

",,http://54.200.128.170/,,"php, mysql, html, vim, nano, emacs, echo, cows, ascii, love",Pikes Peak COmmunityCollege,hackcu2021.org,"",Domain.com,c21jodidalton,Jodi,Dalton,c21jodi.dalton@usafa.edu,"Pikes Peak Community College, United States Air Force Academy, usafa",3,Error401-Unauthorized,Error401-Unauthorized,,arw0399@gmail.com,noahmanter,Hunter,Manter,noahmanter@gmail.com,caelanmbrown,Caelan,Brown,caelanmbrown@gmail.com
Best UX/UI,HackCU2021,https://hackcu-vi.devpost.com/submissions/143240-hackcu2021,Hack CU website for 2021,02/23/2020 13:59:48,"Inspiration

After escaping our gated community (prison) the night before the competition and arriving early the day of, we not able to check-in due to the building being at ""maximum capacity"".  Since we pre-registered for the event weeks in advance and drove hours the night before, this experience inspired us to create a website for next year's HackCU. We then migrated to the nearest Starbucks and worked for the next 6 hours until doors opened again at 6 pm. 

What it does

This website allows users to register for the 2021 HackCU competition and ensures that those who register are guaranteed a spot at HackCU, because it decrements the number of available registration spots each time a competitor registers.  It then populates a database with the user's name, email, etc.. The website also notifies the user that registration is a first come, first serve basis. 

How we built it


This project was built completely using command line text editors and geeks for geeks


Challenges we ran into


Using Starbucks' wifi for 6 hours
doman.com's customer service (our domain still hasn't propagated)


Accomplishments that we're proud of


making a sql statement that runs
removing 100% of the vulnerabilities associated with Windows XP. 


What we learned


Arrive to HackCU 2 hours earlier next year.
mysql and php 


What's next for HackCU2021


hackcu2022.org

",,http://54.200.128.170/,,"php, mysql, html, vim, nano, emacs, echo, cows, ascii, love",Pikes Peak COmmunityCollege,hackcu2021.org,"",Domain.com,c21jodidalton,Jodi,Dalton,c21jodi.dalton@usafa.edu,"Pikes Peak Community College, United States Air Force Academy, usafa",3,Error401-Unauthorized,Error401-Unauthorized,,arw0399@gmail.com,noahmanter,Hunter,Manter,noahmanter@gmail.com,caelanmbrown,Caelan,Brown,caelanmbrown@gmail.com
Most Random,HackCU2021,https://hackcu-vi.devpost.com/submissions/143240-hackcu2021,Hack CU website for 2021,02/23/2020 13:59:48,"Inspiration

After escaping our gated community (prison) the night before the competition and arriving early the day of, we not able to check-in due to the building being at ""maximum capacity"".  Since we pre-registered for the event weeks in advance and drove hours the night before, this experience inspired us to create a website for next year's HackCU. We then migrated to the nearest Starbucks and worked for the next 6 hours until doors opened again at 6 pm. 

What it does

This website allows users to register for the 2021 HackCU competition and ensures that those who register are guaranteed a spot at HackCU, because it decrements the number of available registration spots each time a competitor registers.  It then populates a database with the user's name, email, etc.. The website also notifies the user that registration is a first come, first serve basis. 

How we built it


This project was built completely using command line text editors and geeks for geeks


Challenges we ran into


Using Starbucks' wifi for 6 hours
doman.com's customer service (our domain still hasn't propagated)


Accomplishments that we're proud of


making a sql statement that runs
removing 100% of the vulnerabilities associated with Windows XP. 


What we learned


Arrive to HackCU 2 hours earlier next year.
mysql and php 


What's next for HackCU2021


hackcu2022.org

",,http://54.200.128.170/,,"php, mysql, html, vim, nano, emacs, echo, cows, ascii, love",Pikes Peak COmmunityCollege,hackcu2021.org,"",Domain.com,c21jodidalton,Jodi,Dalton,c21jodi.dalton@usafa.edu,"Pikes Peak Community College, United States Air Force Academy, usafa",3,Error401-Unauthorized,Error401-Unauthorized,,arw0399@gmail.com,noahmanter,Hunter,Manter,noahmanter@gmail.com,caelanmbrown,Caelan,Brown,caelanmbrown@gmail.com
MLH: Best Domain Registered with Domain.com,HackCU2021,https://hackcu-vi.devpost.com/submissions/143240-hackcu2021,Hack CU website for 2021,02/23/2020 13:59:48,"Inspiration

After escaping our gated community (prison) the night before the competition and arriving early the day of, we not able to check-in due to the building being at ""maximum capacity"".  Since we pre-registered for the event weeks in advance and drove hours the night before, this experience inspired us to create a website for next year's HackCU. We then migrated to the nearest Starbucks and worked for the next 6 hours until doors opened again at 6 pm. 

What it does

This website allows users to register for the 2021 HackCU competition and ensures that those who register are guaranteed a spot at HackCU, because it decrements the number of available registration spots each time a competitor registers.  It then populates a database with the user's name, email, etc.. The website also notifies the user that registration is a first come, first serve basis. 

How we built it


This project was built completely using command line text editors and geeks for geeks


Challenges we ran into


Using Starbucks' wifi for 6 hours
doman.com's customer service (our domain still hasn't propagated)


Accomplishments that we're proud of


making a sql statement that runs
removing 100% of the vulnerabilities associated with Windows XP. 


What we learned


Arrive to HackCU 2 hours earlier next year.
mysql and php 


What's next for HackCU2021


hackcu2022.org

",,http://54.200.128.170/,,"php, mysql, html, vim, nano, emacs, echo, cows, ascii, love",Pikes Peak COmmunityCollege,hackcu2021.org,"",Domain.com,c21jodidalton,Jodi,Dalton,c21jodi.dalton@usafa.edu,"Pikes Peak Community College, United States Air Force Academy, usafa",3,Error401-Unauthorized,Error401-Unauthorized,,arw0399@gmail.com,noahmanter,Hunter,Manter,noahmanter@gmail.com,caelanmbrown,Caelan,Brown,caelanmbrown@gmail.com
Most Random,Project Vido,https://hackcu-vi.devpost.com/submissions/143242-project-vido,Vido: like video but shorter,02/23/2020 14:00:52,"What it does

Vido takes your long video and transforms it into easily consumable content. It uses a dynamic programming algorithm to determine which parts of a video have the most relevance. It highlights those parts and cuts out the rest so you get a video that addresses the parts of most concern.

How we built it

Vido is built upon a chain of data translations. We start with a source video file, extract the audio, and then pass that through Google's speech-to-text. We map those words to sentences and pass those through a text summarizer specially built to return video. Finally, we use the timestamps provided by the summarizer to edit the old video which gets served up by the web app.

Challenges we ran into

Text parsing is difficult, and videos are not easy to work with. Reactjs integrated with our Flask server, but not easily. 

Accomplishments that we're proud of

This project was a success in many ways. This is not an easy feat, and many of the technologies we used were new to all of us. The project worked much better than expected, and the summaries are more comprehensive and smooth. The web integration was also a success. Our team communicated well, and apart from some minor complications, we completed each of our goals with minimal git issues.

What we learned

All of the aspects of our project were new to the team member who worked on it. This project was a large departure from everything else we've done. 

What's next for Project Vido

We'll be at HackCU VII.
",,https://github.com/ZackJorquera/Vido,,"python, react, flask, ffmpeg, google-cloud, google-web-speech-api, youtube",University Of Colorado Boulder,vid-o.tech,"",Google Cloud,ZackJorquera,Zack,Jorquera,jorquerazack@gmail.com,University of Colorado at Boulder,3,jorqueraian,jorqueraian,,jorqueraian@gmail.com,riathakkar,riathakkar,,riathakkar16@gmail.com,Borab3,Borab3,,nadivge@gmail.com
MLH: Best Use of Google Cloud,Project Vido,https://hackcu-vi.devpost.com/submissions/143242-project-vido,Vido: like video but shorter,02/23/2020 14:00:52,"What it does

Vido takes your long video and transforms it into easily consumable content. It uses a dynamic programming algorithm to determine which parts of a video have the most relevance. It highlights those parts and cuts out the rest so you get a video that addresses the parts of most concern.

How we built it

Vido is built upon a chain of data translations. We start with a source video file, extract the audio, and then pass that through Google's speech-to-text. We map those words to sentences and pass those through a text summarizer specially built to return video. Finally, we use the timestamps provided by the summarizer to edit the old video which gets served up by the web app.

Challenges we ran into

Text parsing is difficult, and videos are not easy to work with. Reactjs integrated with our Flask server, but not easily. 

Accomplishments that we're proud of

This project was a success in many ways. This is not an easy feat, and many of the technologies we used were new to all of us. The project worked much better than expected, and the summaries are more comprehensive and smooth. The web integration was also a success. Our team communicated well, and apart from some minor complications, we completed each of our goals with minimal git issues.

What we learned

All of the aspects of our project were new to the team member who worked on it. This project was a large departure from everything else we've done. 

What's next for Project Vido

We'll be at HackCU VII.
",,https://github.com/ZackJorquera/Vido,,"python, react, flask, ffmpeg, google-cloud, google-web-speech-api, youtube",University Of Colorado Boulder,vid-o.tech,"",Google Cloud,ZackJorquera,Zack,Jorquera,jorquerazack@gmail.com,University of Colorado at Boulder,3,jorqueraian,jorqueraian,,jorqueraian@gmail.com,riathakkar,riathakkar,,riathakkar16@gmail.com,Borab3,Borab3,,nadivge@gmail.com
MLH: Best Domain Registered with Domain.com,Project Vido,https://hackcu-vi.devpost.com/submissions/143242-project-vido,Vido: like video but shorter,02/23/2020 14:00:52,"What it does

Vido takes your long video and transforms it into easily consumable content. It uses a dynamic programming algorithm to determine which parts of a video have the most relevance. It highlights those parts and cuts out the rest so you get a video that addresses the parts of most concern.

How we built it

Vido is built upon a chain of data translations. We start with a source video file, extract the audio, and then pass that through Google's speech-to-text. We map those words to sentences and pass those through a text summarizer specially built to return video. Finally, we use the timestamps provided by the summarizer to edit the old video which gets served up by the web app.

Challenges we ran into

Text parsing is difficult, and videos are not easy to work with. Reactjs integrated with our Flask server, but not easily. 

Accomplishments that we're proud of

This project was a success in many ways. This is not an easy feat, and many of the technologies we used were new to all of us. The project worked much better than expected, and the summaries are more comprehensive and smooth. The web integration was also a success. Our team communicated well, and apart from some minor complications, we completed each of our goals with minimal git issues.

What we learned

All of the aspects of our project were new to the team member who worked on it. This project was a large departure from everything else we've done. 

What's next for Project Vido

We'll be at HackCU VII.
",,https://github.com/ZackJorquera/Vido,,"python, react, flask, ffmpeg, google-cloud, google-web-speech-api, youtube",University Of Colorado Boulder,vid-o.tech,"",Google Cloud,ZackJorquera,Zack,Jorquera,jorquerazack@gmail.com,University of Colorado at Boulder,3,jorqueraian,jorqueraian,,jorqueraian@gmail.com,riathakkar,riathakkar,,riathakkar16@gmail.com,Borab3,Borab3,,nadivge@gmail.com
Best Use of Adobe XD,Project Vido,https://hackcu-vi.devpost.com/submissions/143242-project-vido,Vido: like video but shorter,02/23/2020 14:00:52,"What it does

Vido takes your long video and transforms it into easily consumable content. It uses a dynamic programming algorithm to determine which parts of a video have the most relevance. It highlights those parts and cuts out the rest so you get a video that addresses the parts of most concern.

How we built it

Vido is built upon a chain of data translations. We start with a source video file, extract the audio, and then pass that through Google's speech-to-text. We map those words to sentences and pass those through a text summarizer specially built to return video. Finally, we use the timestamps provided by the summarizer to edit the old video which gets served up by the web app.

Challenges we ran into

Text parsing is difficult, and videos are not easy to work with. Reactjs integrated with our Flask server, but not easily. 

Accomplishments that we're proud of

This project was a success in many ways. This is not an easy feat, and many of the technologies we used were new to all of us. The project worked much better than expected, and the summaries are more comprehensive and smooth. The web integration was also a success. Our team communicated well, and apart from some minor complications, we completed each of our goals with minimal git issues.

What we learned

All of the aspects of our project were new to the team member who worked on it. This project was a large departure from everything else we've done. 

What's next for Project Vido

We'll be at HackCU VII.
",,https://github.com/ZackJorquera/Vido,,"python, react, flask, ffmpeg, google-cloud, google-web-speech-api, youtube",University Of Colorado Boulder,vid-o.tech,"",Google Cloud,ZackJorquera,Zack,Jorquera,jorquerazack@gmail.com,University of Colorado at Boulder,3,jorqueraian,jorqueraian,,jorqueraian@gmail.com,riathakkar,riathakkar,,riathakkar16@gmail.com,Borab3,Borab3,,nadivge@gmail.com
All Beginner,SafeCheck,https://hackcu-vi.devpost.com/submissions/143244-safecheck,SafeCheck is a new way of feeling more comfortable about your sexual life. SafeCheck is a new way of feeling more comfortable about your sexual life. This app opens doors for knowind what STD's/STI..,02/23/2020 14:02:46," Hackathon Project  
 


  


Safe Check

SafeCheck is a new way of feeling more comfortable about your sexual life. This app opens doors for knowind what STD's/STI's that you might possibly have from past sexual partners. This is all done anonymously as well, making sure you feel secure with knowing whether or not you should get checked and comfortable with knowing.
",,https://github.com/abdullaha360/hackathon,,"html, css, javascript, google-cloud","University of Colorado, Colorado Springs",safecheck.tech,"",Domain.com,metcalfe12998,Jacob,Metcalfe,metcalfe12998@gmail.com,University of Colorado at Colorado Springs,0
Sustainability,Invasive Species Reporter,https://hackcu-vi.devpost.com/submissions/143245-invasive-species-reporter,Invasive species take an in credible toll on the economy and ecology of Colorado. Our project makes it easier to file a report than it has ever been and also includes a prototype mobile app.,02/23/2020 14:03:06,"Inspiration

We were inspired by our love for the outdoors to build this project. As avid fly fishermen, we have seen the toll that invasive species have had on our home waters. Currently There are no ways currently to easily report sightings and help an overwhelmed Colorado Parks and Wildlife team. Creating an easy way for outdoorsmen to report sightings on invasive species will make tracking of nuisance species easier and assist local government in figuring out how to best control them.

What it does

Our project allows users to report sightings of invasive species on a mobile app, or our web application. Our mobile app would automatically drop a pin in the location where the user made the spotting. From there they can view a map to see sightings in the area and access an informational library on invasive species of Colorado. Our web application performs similar functions. 

How I built it

We used google Firebase as our database and the google Firebase API as our interface between the site and the database. We built an HTML5 bootstrap front end and styled with CSS. We used Adobe XD to mock up the app.

Challenges I ran into

We ran into multiple challenges while developing this project. When we first began development, we struggled with merging our local branches into the master without coding conflicts. As time went on we began to develop a more seamless process of merging our branches and learned how to communicate better. Another challenge we ran into was hosting our website. At first we tried to us Heroku but came to realize the code languages we used were not supported on that platform. We then decided to use GitHub pages. Overall we learned a lot from the expereince

Accomplishments that I'm proud of

We are proud of how we managed to build an app and have it ready for an early deployment within 24 hours. This time crunch was a new challenge.

What I learned

We learned a lot from developing this project. Firstly, we learned how to use Adobe XD, a technology that neither of us had ever used before. Second, we learned how to communicate better and work on local branches more efficiently. Finally, we sharpened our full stack development skills overall.

What's next for Invasive Species Reporter

We plan on contacting Colorado parks and wildlife, and we hope to continue developing our technology so that it can be a useful tool to help handle invasive species in Colorado.
",,https://github.com/LincolnRychecky/Hack-CU,,"javascript, html5, firebase, css, adobexd",University of Colorado Boulder,"","","",LincolnRychecky,Lincoln,Rychecky,liry9073@colorado.edu,University of Colorado at Boulder,0
Best Use of Adobe XD,Invasive Species Reporter,https://hackcu-vi.devpost.com/submissions/143245-invasive-species-reporter,Invasive species take an in credible toll on the economy and ecology of Colorado. Our project makes it easier to file a report than it has ever been and also includes a prototype mobile app.,02/23/2020 14:03:06,"Inspiration

We were inspired by our love for the outdoors to build this project. As avid fly fishermen, we have seen the toll that invasive species have had on our home waters. Currently There are no ways currently to easily report sightings and help an overwhelmed Colorado Parks and Wildlife team. Creating an easy way for outdoorsmen to report sightings on invasive species will make tracking of nuisance species easier and assist local government in figuring out how to best control them.

What it does

Our project allows users to report sightings of invasive species on a mobile app, or our web application. Our mobile app would automatically drop a pin in the location where the user made the spotting. From there they can view a map to see sightings in the area and access an informational library on invasive species of Colorado. Our web application performs similar functions. 

How I built it

We used google Firebase as our database and the google Firebase API as our interface between the site and the database. We built an HTML5 bootstrap front end and styled with CSS. We used Adobe XD to mock up the app.

Challenges I ran into

We ran into multiple challenges while developing this project. When we first began development, we struggled with merging our local branches into the master without coding conflicts. As time went on we began to develop a more seamless process of merging our branches and learned how to communicate better. Another challenge we ran into was hosting our website. At first we tried to us Heroku but came to realize the code languages we used were not supported on that platform. We then decided to use GitHub pages. Overall we learned a lot from the expereince

Accomplishments that I'm proud of

We are proud of how we managed to build an app and have it ready for an early deployment within 24 hours. This time crunch was a new challenge.

What I learned

We learned a lot from developing this project. Firstly, we learned how to use Adobe XD, a technology that neither of us had ever used before. Second, we learned how to communicate better and work on local branches more efficiently. Finally, we sharpened our full stack development skills overall.

What's next for Invasive Species Reporter

We plan on contacting Colorado parks and wildlife, and we hope to continue developing our technology so that it can be a useful tool to help handle invasive species in Colorado.
",,https://github.com/LincolnRychecky/Hack-CU,,"javascript, html5, firebase, css, adobexd",University of Colorado Boulder,"","","",LincolnRychecky,Lincoln,Rychecky,liry9073@colorado.edu,University of Colorado at Boulder,0

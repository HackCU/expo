Submission Title,Submission Url,Plain Description,Video,Website,File Url,Desired Prizes,Built With,Mlh Points,Mlh Hardware Lab,Submitter Screen Name,College/Universities Of Team Members,Team Member 1 Screen Name,...
Aria: Your Personal Smart Home Butler,http://hackcu3.devpost.com/submissions/72056-aria-your-personal-smart-home-butler,"Check it out at http://tanaykothari.com/aria-voice

Inspiration

I walk into my room with a girl I have a big crush on - we're working on homework together.

""Alexa, tell Aria to impress the lady"". Spotify plays You're Beautiful by Maroon 5, and turns on ambient lighting on the light strip that goes along my entire room. My heart stops beating for a second as she smiles at me. I'm grinning like an idiot. Today's going to be a beautiful day. 

I wake up from my day dream. I switch on my lights from the switchboard and wait patiently for my phone to connect to my speakers. Well those days are over. 

Smart home technologies have not been growing at the speeds as we expect them to. With the number of services, fast internet speeds, and reduced cost of technology we have at this date, smart home needs to be much more integrated. Sure, the Nest Thermostat can control the temperature and send you notifications when it drops too low - but we want to move to a more integrated system where all these different services can work in unison and give you a wholesome experience. You shouldn't need five ecosystems to control one home. Clearly, just pink-purple transitioning lights wouldn't have impressed any girl just by itself. 

What it does

Aria takes existing smart home devices and ecosystems and merges them all into one. Currently powered by an Amazon Alexa, Aria takes in voice input and turns it into commands for various smart home devices. With IFTTT integration, Aria can do even more. IFTTT allows Aria to control most current smart home products seamlessly, as well as utilize any webhook service or api. Aria is here to make your life easier, and to bring the smart home a reality for many.

""Alexa, tell Aria its party time""

""Alexa, tell Aria to turn on the blue lights""

How we built it

Your voice <-> Alexa Skill <-> AWS Lambda <-> AWS IoT <-> Node Red <-> Raspberry Pi <-> Your devices

Our Alexa skill takes in your commands and sends the processed information to AWS Lambda. 

Based on the intent and your current conversation with the Alexa, Lambda sends a request to AWS IoT and controls the Alexa replies. 

AWS IoT connects the devices to the Lambda function for near-instantaneous transmission of intents to the Raspberry Pi. The Pi runs an instance of Node-Red which takes in the raw intent information and converts that into GPIO signals which control the hardware connected to the Pi. 

In addition, some controls of the Pi run through Node-Red, for example, when the lighting is low, the Pi automatically turns on its night lights. 

Challenges we ran into

One of our largest challenges was setting up the entire integration between our devices and AWS. We initially had issues transferring data from the AWS IoT to the Raspberry-Pi, and then after that we ran into a large road block with sending information from our code in the AWS Lambda to the Raspberry-Pi. A few hundred google queries later and tens of man-hours later, we finally overcame those issues. From then on out, we've been setting up multiple integrations and brainstorming ideas as we go!

Accomplishments that we're proud of


We learnt a lot from the stack we used to create this project and from each other.
We worked as a team cohesively through the 24 hours, learning from each other, each exploiting their core skill set to make immense contributions to the team and our project. 
We were able to setup the immensely complicated infrastructure in a relatively short period of time.


What we learned


We all learnt to work with a Raspberry Pi 
We learnt how to make Alexa Skills 
We learnt Node.js and worked with it to create the skills and write the backend code to connect AWS Lambda to AWS IoT. 
We learnt to setup servers on AWS and create a multi-stage communication channel between the Alexa and the hardware components


What's next for Aria


Support for other smart home devices (like the Philips Hue, Wemo switches, Nest thermostat) to connect to our hub and make it easy for everyone to transition to Aria. 
APIs to allow users to create IFTTT Applets using Aria
Kickstarter campaign to get funding to manufacture the first round of devices for beta testing and allowing third-party developers to build with Aria


""Alexa, tell Aria to impress the lady - and the judges of course."" 
",,https://github.com/Tanay1998/Aria,,"Best domain name registered with Domain.com, Best use of Amazon Web Services","aws-iot, raspberry-pi, python, amazon-alexa, node.js, amazon-web-services, sensors, hardware, node-red","Stanford University, UC Boulder, UC Boulder, University of Washington",Amazon Echo,tanay1998,University of Colorado Boulder,wow1881,SumeetBatra
ShortWormMemory,http://hackcu3.devpost.com/submissions/72090-shortwormmemory,"Inspiration

It was just Earth Day, the most important holiday of the year, so we wanted to celebrate by creating something that could help our planet

What it does

It helps learn about what objects you need to trash, recycle, compost, etc... ShortWormMemory is a fast paced game involving choosing the correct location for the waste after seeing it on the side bar.  With echoes of tetris, llama or duck, and Clippy, this game is sure to be fun while casually helping educate players about which waste items go where. 

How we built it

We built the project in Java, using processing for our front end stuff and java for the backend stuff for the application. 

Challenges we ran into

We hadn't worked with GUI or images before in java, so we had a lot to look up.  After many hours looking into Swings GUI implementation with JLabels, we ended up trying to switch to 2Dgraphics, but since we were getting crunched for time, we opted for a hopefully quicker method; using processing. 

Due to this, we were able to get all of the back stuff tied together, but when it came to synthesizing the game engine, we couldn't get it to tie together well. 

Accomplishments that we're proud of

What we learned

We learned valuable lessons about which different libraries to use for different projects.  We also learned how to properly structure a game in java better, if we choose to do that again in the future. 

What's next for ShortWormMemory

Hopefully getting all of the images together and into a coherent game, and then after that trying to expand to include levels that involve composting, metal recycling, and even certain plastics. 
",,https://shortwormmemory.com,,Best domain name registered with Domain.com,"java, processing","University of Wisconsin Madison, Madison Area Technical College","",rosalindstengle,Madison Area Technical College,klare,UmHelloSir
Alteryx submission by team Marmathor,http://hackcu3.devpost.com/submissions/72094-alteryx-submission-by-team-marmathor,"You asked us to do this and we did! We didn't use any clues, just the initial handout. This submission was done at 7:40 pm on Saturday!
",,,https://s3.amazonaws.com/challengepost/zip_files/production/23085/zip_files/marmathor.zip,Alteryx,"alteryx, languages, code, cats","University of Colorado, Boulder","",apccurtiss,"University of Colorado, University of Colorado at Boulder",aowsenek,joshuaanderson-2,izwe5504
"Alteryx Blob Decryption (Bri, Wes, Alex, Matt)",http://hackcu3.devpost.com/submissions/72104-alteryx-blob-decryption-bri-wes-alex-matt,"Inspiration

Learning at our first Hackathon and excelling in our application of Alteryx software.

What it does do

Our program decrypts the given secret message and translates it into common English from Pig Latin.

How we built it

To decrypt this message, Alteryx was the sole software used in analyzing the data and finding the secret message. First, two-character pairs were identified, as well as their frequencies, to find and further their translations. After a directory was built to identify the different code pairings, the linguistic structure of Pig Latin was coded into multiple formula nodes so that Pig Latin terms could be translated successfully to English, regardless of the normality of the word.

Challenges we ran into

How to break the code up: before getting the instructions, we spent a lot of time mapping the different possibilities of how to start identifying patterns.

How to translate into English from Pig Latin: trying to construct global functions that would transform any and all Pig Latin words into English was rather hard, but after researching consonant clusters, our code became much more efficient in successfully translating the words to English.

Accomplishments that we're proud of

Discovering and building out the directory of translations from two-character codes to single English characters.

What we learned

How to decrypt messages!

How to approach a new problem with strategic thinking!

Using the find/replace tool instead of attempting to the join the data initially.

Utilizing crosstab and transpose tools to translate single words in a column to joined words in a single row.

What's next for Alteryx Blob Decryption (Bri, Wes, Alex, Matt)

Perfecting syntax decryption and translation accuracy... and a long night's sleep :)
",,https://www.dropbox.com/s/6fzzliimckf2de0/AlteryxChallenge_AMidHackacthonsNightDreamV3%20%282%29.zip?dl=0,,"","",University of Colorado Boulder,"",brianabutler,"University of Colorado, University of Colorado at Boulder",alextruesdale,matt855,westonballard
noiamyourfather.net,http://hackcu3.devpost.com/submissions/72116-noiamyourfather-net,"In the center of Cloud City, Luke Skywalker, battered and bruised, confronts Darth Vader about his father Anakin.
NOTE devpost isn't registering that the domain is valid so here it is: noiamyourfather.com
",,http://www.noiamyourfather.net,,Best domain name registered with Domain.com,"html, domain.com, youtube",Miami University,"",ezapanta,Miami University
CrashBoulder,http://hackcu3.devpost.com/submissions/72128-crashboulder,"Inspiration

Like many new visitors such as CU freshmen before and after me, I am completely new to the great State of Colorado, specifically to the great city of Boulder, where a lot of bold people live in a rather bold fashion. I wished I know all the good spot around Boulder, but my knowledge limited to a few recommendations from a few locals. Just look at those beautiful mountains, such natural beauties. It would be great if one can know more about Boulder, so I just build a web app on that.  

What it does

Help users to crash around Boulder in a bolder fashion. Get a lot bolder in NodeJS.

How I built it

I used a lot of MapQuest APIs. NodeJS. AngularJS.

Challenges I ran into

Going solo. Going solo is definitely a challenge. Get register for crashboulder.com. It is trying to do a 4 people project with just ten fingers. APIs from MapQuest APIs has a lot of varieties. MapQuest.io and developer.MapQuest.com is very different. And of course, use only NodeJS SDK for MapQuest.io because NodeJS is the only real dev language.

Accomplishments that I'm proud of

NodeJS. Using both MapQuest.io and developer.MapQuest.com with just NodeJS. NodeJS rules!!

What I learned

NodeJS is the only real dev language.

What's next for CrashBoulder

More NodeJS. 
",,https://github.com/crashboulder/crashboulder.github.io,,"Workday: API prize, Best domain name registered with Domain.com, MapQuest API Prize, Best use of Amazon Web Services","mapquest-geocoding, mapquest, mapquest-search, mapquest-open-guidance, angular.js, node.js, crashboulder.com, github, git",UT Dallas,"",hollykhk,The University of Texas at Dallas
magicbox,http://hackcu3.devpost.com/submissions/72184-magicbox,"Magicbox

A smart box that locks a safe based on input from the keypad. There is also a web interface that enables the lock's password to be modified through the particle's web api.

The Hardware

The main controller is a particle photon. It is connected to a stepper motor that serves as the bolt keeping the locked box closed. It is also connected to a keypad that provides the main user interface to the box.

Set Password Function

The photon's code has a function connected to the particle cloud. This enables the key combination to be modified through the web interface.

Challenges That Were Overcome

Prior to the start of the hackathon, James, the main developer of this project, knew almost nothing about how to use the main hardware components and how to set up particle devices to receive input rather than to post data. These were all challenges that over the course of the hackathon he overcame. He learned a large amount about how to get the various hardware components to work together.
",,https://github.com/phobos2390/magicbox,https://s3.amazonaws.com/challengepost/zip_files/production/23169/zip_files/magicbox.zip,"","arduino, particle, adafruit","Brigham Young University, Lindenwood University, University of Colorado",Particle Photon,phobos2390,"Lindenwood University, University of Colorado at Boulder",Lanceitar,adamcasey
Athena,http://hackcu3.devpost.com/submissions/72196-athena,"Inspiration

As virtual reality developers, we saw a major lack of vr educational platforms. We want to set a standard for this new and  emerging technology!

What it does

Athena is a mobile learning management system that focuses on virtual reality.

How I built it

Athena was built with Unity embedded into Android Studio.

Challenges I ran into

We got stuck on a single bug for almost 12 hours, only to realize that it was a bug in the editor.

Accomplishments that I'm proud of

Finishing our goals that we set in the beginning.

What I learned

That dedication is key, even if it takes you 12 hours.

What's next for Athena

AR and Networking! Students will soon be able engage with their professor's and their peers.
",,https://github.com/athena-app/athena-android,https://s3.amazonaws.com/challengepost/zip_files/production/23100/zip_files/athena-android-src.zip,"","java, android-studio, c#, unity, google-cardboard",University of Oklahoma,"",ryandobby,University of Oklahoma
OBD Buddy,http://hackcu3.devpost.com/submissions/72198-obd-buddy,"Inspiration

The inspiration for this project is two fold, both from an interest from one of our group members, and from the API's provided at HackCU. One of our members had purchased an OBD (on board diagnostics) sensor to play around with the diagnostics on his car, and was somewhat interested in playing around with it further. By combining the idea of getting useful, unique data from the car, and API's provided by MapQuest, OBD Buddy was born.

What it does

This application takes data from the on board diagnostics system from a vehicle such as a car or motorcycle. We use this data, layered over a directions application, to provide drivers and riders with contextual information and suggestions based on their location and car data. For example, say a user is on a road trip, and their car is running low on fuel. Because we know their destination, and how much fuel they have left in their car, a piece of data most apps wouldn't have, we can quickly warn them and suggest the nearest gas stations. From there, the user has the opportunity to add the nearest station as a way point, and be redirected for a refuel. 

How we built it

We started with an Arduino microcontroller, a wifi shield, and an OBDII-to-UART board. We hooked this into a Pontiac G6, and started collecting the data as the user drives. From there, the data is transmitted via an HTTP request using the Arduino and wifi shield. This data is captured by a Flask server, and stored in a SQLite3 database. Then, using the MapQuest directions API and leaflet.js, we provide simple directions to a desired location in a modern, intuitive user interface. In addition, our front end is polling our back end server checking for alerts based on the data being received. If one is found, our front end receives the necessary information, and informs the user with options to continue. 

Challenges we ran into


Soldering Wifi Board
Connection with Wifi Board
String Parsing from OBD Board
Docker Container Setup
Geolocation and HTTPS
Cordova/Phonegap
Malformed Raw HTTP Requests
Difficulty Debugging in Car at Night
Callback Hell
Leaflet.js Map Interfacing 


Accomplishments that we're proud of


Successfully communicating data from car to OBD to Arduino to Flask to Sqlite3 to front end display
Decoupled architecture
Front end user interface
Dedication to completion of project 


What we learned

Jake: The items I was really focused on were the data communication and general architecture of the application. Besides the vast amount of interdisciplinary knowledge such as the idea behind OBD and how it interfaces with an Arduino, I learned some hard lessons about the tradeoffs with decoupled architectures. I had been itching to design a system like this, and jumped at the opportunity to implement it. However, the work spent bouncing between different members of the team, helping to define precisely how the communication structure was going to go was eye opening. I felt as though at least a quarter of my time was spent bouncing around playing this middle man role, and it really showed me that defining this communication as early as possible is an important step for next time. In terms of technologies, the biggest new technology that I worked with was Docker. I had never used Docker before, and was impressed at how easily we were able to quickly deploy to different VPS's as we were trying to resolved our issues with HTTPS.

Boskin: I learned that it is very important to carefully analyze the exact byte responses of the OBDII to UART board to the Arduino so that data is properly extracted. I learned how to form basic HTTP GET requests and send them via the ESP8266 WIFI shield through a hotspot to a final HTTP server. I also learned that in complicated systems with multiple microprocessors with their own firmware running, it is important to be able to reset all of the systems to make sure they do not go out of sync.

Brent: Through the course of this project, I’ve gained perspective on things to consider before developing a product. For example, choosing the correct technologies for a particular problem is an important part in ensuring a pleasant development experience for the team. Some specific things I’ve learned is how to configure sqlite3 and why it can be more beneficial to use a more lightweight database than a full-fledged database such as Cassandra. I’ve also gained experience in developing REST API’s for other developers to utilize, and things to communicate to the front-end to ensure a fluid workflow.

Ryan: I designed and developed the web front end for OBD Buddy by utilizing MapQuest’s and leaflet.js’s APIs.  Due to constraints of phone usage while driving, I determined several goals that we must meet in the design process: the interface must be easy to glance at to receive information, it must be quick and simple to navigate, the user’s focus must be centered on the map and their personal directions, and finally, user’s must be able to understand prompts quickly, make a decision about the prompt quickly, and take the appropriate action quickly.  By keeping these goals in mind, we have developed a user interface that works extremely well for our data and user’s needs.

On the tech side I was spending most of my time utilizing MapQuest’s API in conjunction with the map API from leaflet.js to get directions, search for points of interest, add waypoints to routes, construct markers on the map, plot the user’s current location, and so on.  After using the Google Map API at my last hackathon, I was blown away with how straightforward MapQuest’s and leaflet.js’s API’s were to use, understand, and write for; though that does not mean I never encountered any issues; far from it.  Due to a number of functions being asynchronous and the existence of a large amount of data dependencies between functions, I found it became difficult to deal with all the callbacks and keeping the flow of data under control.  I’ll be the first to admit I do not have a great amount of experience with async programming, and as a result, keeping things simple became one of the most difficult parts of the project.  With a little help from others and Google, I learned how to write code effectively in this style and learned a lot about javascript in the process.  On a closing note, I also utilized SASS for the first time to simplify my CSS.  I will be using it in every one of my web based projects in the future.  It really helped to ensure a good structure of CSS, something that I always struggle with.

What's next for OBD Buddy

The next steps we would like to take with OBD Buddy, is to add more features surrounding the valuable data being collected by the OBD board. This could be things like monitoring fuel consumption or giving more details about the severity of any error codes collected by the car. 

In addition, the idea of using some kind of adapter to start getting data from motorcycles is a very interesting prospect for us. After talking to the guys at Rever, it seems like this kind of data, specifically the fuel levels in context, are very valuable to motorcyclists. 
",,https://github.com/t2nerb/OBD_buddy,,"MapQuest API Prize, BMW Motorrad/Rever","python, flask, arduino, wifi, hardware, sqlite, docker, nginx, uwsgi, javascript, sass, mapquest-directions, mapquest-search, leaflet.js, pontiac-g6",CU Boulder,"",JakeC1020,University of Colorado at Boulder,ryanrouleau,BrentDagdagan,Boskin
CrossOVr,http://hackcu3.devpost.com/submissions/72205-crossovr,"Inspiration

To have a multiplayer game where people outside of the VR headset and engage with a player in VR

What it does

The VR player is placed in a game where creatures slowly crawl to them.  He/she is able to fend them off with a vr gun.  Players on the browser platform are able to drop bombs into the game by clicking on an image of a map to fend the zombies off.

How we built it

Socket.IO for communication between Unity client and web browser game clients
Node.JS and Express for creating the web game client
Unity3D for building the VR game

Challenges we ran into

Setting up communication between clients and Node.js server

Accomplishments that we're proud of

A web browser game that is updated by a Socket.IO connection to a Unity application.  

What we learned

How simple it is to build an event messaging system with Socket.IO

What's next for CrossOVr

More items?  More players?
",,https://github.com/jkredzvr/HackCU_SocketUnityGame,,"","unity, socket.io, node.js, javascript",university of colorado boulder,"",jchinbu,"University of Colorado at Boulder, Front Range Community College",RoldanMelcon
3D Model Maker,http://hackcu3.devpost.com/submissions/72209-3d-model-maker,"Inspiration

We wanted to make changes to the places and buildings withing google earth.

What it does

Pick a place in google earth and it will make a 3D model of it for you.

How I built it

Using python and recap360

Challenges I ran into

NO API
NO Community Support because the new google earth was released ~2 weeks ago.
Doing the math to circle around the place taking screenshots
Convert the screenshots into 3D images

Accomplishments that I'm proud of

Accomplished our goal even with all of the problems we ran into.
",,,,"Workday: API prize, MapQuest API Prize",python,University of Colorado at Boulder,"",suso4455,University of Colorado at Boulder,nullmage,stevmak
Motion Cntrl,http://hackcu3.devpost.com/submissions/72214-motion-cntrl,"Inspiration

We wanted to create something new, exciting and futuristic. Something thats really cool but also has a lot of practical uses, and this interface was it. First of all, it's really cool being able to control your entire computer simply by waving your hands in the air. And second, it could make for a great assistive technology for people with disabilities who can't use a traditional computer inputs.

What it does

Use your hands in the air to control your computer! Wave your hand in front of the screen, above the leap-motion, and this simulates a mouse cursor; you can move the mouse by waving your hands around! If you want to click or scroll, there are various finger gestures that you can do, such as pinching your thumb to your index finger in order to click, or pinching your thumb to your middle finger to scroll down. Its just a really cool way to control your computer!

How we built it

The finished project uses the Java Programing Language, along with a LeapMotion and the LeapMotion SDK. The LeapMotion tracks the movement of your hands, and the Java code gets the data from the LeapMotion and uses it in order to simulate a mouse cursor. We use an arduino with various sensors in order to simulate various actions when certain finger gestures are made.

Challenges we ran into

Learning the LeapMotion SDK was hard, but worth it after we got cursor movement! We also ran into trouble with our original Arduino and Sensors. The arduino that we originally had wasn't capable of sending mouse movements to the computer, and we spent many hours trying to figure out a way to work around this. We also tried many different sensors for our controls, such as accelerometers, touch sensors, and light sensors. This was also a hardware hack filled with hours of soldering!

Accomplishments that we're proud of

Finishing and having a nice working product!!! It may not be the prettiest but it is extremely cool and actually works. Watch the video demo, it's amazing. After hours and hours of struggling, we were able to solve most of the problems we came across and got the product to work.

What we learned

We learned a lot about the LeapMotion, it's a really cool piece of tech and fun to develop for! We also got to learn a lot about hardware, as that was a major part of our project. It was really satisfying getting everything to work together.

What's next for Mind Cntrl

We are hoping to integrate a bluetooth module to the arduino so that it doesn't have to be connected to the computer!, and want to come up with  more useful gestures for the interface. We also hope to design a better looking product, as a glove with a bunch of wires sticking out isn't the most appealing (: 

Check out the video demo!!!
",https://youtu.be/shdoYP7hxOM,https://github.com/dryzhko/MotionCntrl,,"","java, arduino, c, leap-motion",University of Colorado Boulder,"Leap Motion,Arduino 101",dmry2547,University of Colorado at Boulder
Kyokan,http://hackcu3.devpost.com/submissions/72234-kyokan,"*

Kyokan is an empathy-driven wearable- the user's emotion is detected through EEGs sent through the Muse, and displayed on the Raspberry Pi; the idea is to be able to read another person's feelings. Ideally the screen would be sewn onto the t-shirt, or better integrated. Discrepancy in emotions will cause the electrodes to emit more current- i.e, two happy people will feel no shock, an angry and happy person will feel more shock. 
You ""feel"" what another person feels.

How I built it

Muse, MuseLab, Raspberry Pi

Challenges I ran into

Liblo OSC library

What I learned

Electroencephalography (EEG)
",,,,"","muse, raspberry-pi","Stony Brook University, University of Michigan",Muse,sharonpak,"",cameronjblocker,jbuchman
keepcalmandcyb.org,http://hackcu3.devpost.com/submissions/72236-keepcalmandcyb-org,"Not sure where to submit the punniest domain.com submission so defaulted to devpost :o )
",,,https://s3.amazonaws.com/challengepost/zip_files/production/23110/zip_files/keepcalm.pdf,Best domain name registered with Domain.com,"",CU,"",kstubblefield,""
Oodler,http://hackcu3.devpost.com/submissions/72322-oodler,"Inspiration

Due to midterm weekend, I opted to do a small funny side-project instead of something more complicated. I built a chrome extension based on a popular social media trend that went around where one would replace all the vowels in their name with 'oodle'. 

What it does

The extension replaces all vowels on any web-page (on first load) with oodle. Devpost -> Doodlevpoodlest. That way not only is it funny, but it strategically allows users to never get offended because they dont know what they are reading!

How I built it

I built it entirely in JavaScipt.

Challenges I ran into

Often times when replacing text, the html would be broken down as a result. I had to figure out a way to only target specific elements, and maintain the structure of the website whilst still replacing all vowels.

Accomplishments that I'm proud of

I came into it knowing no JavaScript.

What I learned

A gained experience and knowledge of JavaScript (and React).

What's next for Oodler

Add a button where you can toggle its effect so it's more convenient to turn it off and on.

Try it out on the chrome store, link down below
",,https://chrome.google.com/webstore/detail/oodler/fefgeoikfmbfppendeljhbjhippkljdi?hl=en,,#HackHarassment,javascript,University of Colorado Boulder,"",guso9085,""
mrmr,http://hackcu3.devpost.com/submissions/72324-mrmr,"mrmr

A simple but nice webchat application with rooms and fun!
mrmrchat.net

Goals

The main goal of the 24 hour project is to create a web application that supports chatting between users, user instance manipulation, and chat room manipulation.

Rules

No code can be written before April 21st, 2017 at 12:00 MST. However brainstorming/organization and concepts of ideas can be made prior (basically the idea can be developed).

Facts about the project


Our javascript will be strict to the idiomatic style guide to help with readability here.
All markdown documents will be strict to the style guide presented here.
All element styling will be done through classes in SCSS.
HTML will be written in Handlebars (however not much if anything will be passed through the route as most information is passed through the websocket)
The web server will be hosted on a raspberry pi that periodically pulls from the github. Commits to the repository should only be made when a feature is fully implemented.
The address of the pi (only accessible on UCB Wireless Networks) will be [INSERT ADDRESS HERE] at the time of the event through May 12th, 2017.


Bug Fixing and Tidying

Any features that we are working on or plan to work on will be posted on our Trello board here.

Contributors

Kyle Helmick
Morgan Burrows
",,https://github.com/Kyle-Helmick/mrmr,,"","javascript, html, css, scss, node.js, heroku, socket.io, uuid",CU Boulder,"",Kyle-Helmick,University of Colorado at Boulder,morganburrows
GOTO,http://hackcu3.devpost.com/submissions/72332-goto,"Inspiration

As college students, we often watch lectures on youtube to learn course concepts. Often watching an hour long lecture for one definition isn't the most effective use of time so we sought to speed that up.

What it does

You can search and fuzzy search through closed captions of lecture videos from youtube. Results will link directly to the time in the video in which that phrase. 

How we built it

We used elastic-search for the backend and angularjs running through ionic for the front end. The front end 

Challenges we ran into

Setting up elastic search had a pretty steep learning curve. We also needed to  enable cross-resource sharing to be able to interact with it. 

What we learned

We had never worked with elastic search  or ionic so we definitely learned from the ground up on those. We also had limited angular experience so we learned a lot more about how to use that for front end development.

What's next for Encounter

Including self-uploaded lectures, and adding more content to our search database.
",https://www.youtube.com/watch?v=Sj2CzMM2SHc,,,Best use of Amazon Web Services,"elasticsearch, angular.js, ionic, youtube",UT Auston,"",alioup,University of Texas at Austin,yuriyminin,krislaw
squidwardplaysclari.net,http://hackcu3.devpost.com/submissions/72336-squidwardplaysclari-net,"Who doesn't like spongebob?
",,http://www.squidwardplaysclari.net/,,Best domain name registered with Domain.com,"html5, youtube",Miami University,"",ezapanta,Miami University
SpektrumVR,http://hackcu3.devpost.com/submissions/72348-spektrumvr,"Inspiration

After seeing that it was possible to create a VR application fairly simply on the web, we wanted to create something really cool with the Rodin framework, since it allows for cross-platform web-based VR development. The concept that we came up with was audio visualization: a three-dimensional circular audio spectrum being the core concept. The backdrop for this experience is one of Rodin's template rooms, which provides a somewhat crude simulation of what this might be like in augmented - rather than virtual - reality.

What it does

The core concept is fairly simple. It builds on one of Rodin's templates to load in an audio file and perform the FFT on parts of the audio to obtain the spectrum from moment to moment. A series of rectangles are then updated each frame, with the end effect being a three-dimensional audio spectrum that surrounds the camera.

How we built it

The initial prototype was built using a simple WebVR boilerplate discovered on the Internet, for which I am immensely grateful. This allowed for tremendously fast prototyping using a simple locally hosted web server, which made it very easy to connect to the server from my laptop itself, or from another device on the same network, without having to upload and download constantly from Rodin or fiddle with npm and gulp.

Challenges we ran into

Actually getting the audio to work was rather difficult. Playing an audio file in a standard browser is relatively easy; playing it in a 3D VR context is much more difficult. It was also difficult to use a framework that we had never used before, since most of our experience is in non-web languages like C++ and Python. JavaScript has some syntax similarities to C++, but getting all of the files to play nicely together was quite a challenge.

Accomplishments that we're proud of

The thing that I'm most proud of is getting this working and running decently. On some hardware that's not particularly optimized for VR (my phone in particular) it seems to run a bit sluggish, but on decent VR-ready hardware - and even my 2010 MacBook - it seems to run fine. It's really cool to see how powerful and extensible JavaScript really is in this context.

What we learned

One of the main things that we've learned is how to work with JavaScript, npm, and the web in general. Working with the Rodin framework itself is also something that we've learned, although I'm sure that there's a lot else that we didn't even so much as skim the surface of.  Another thing that we learned is just how much it's possible to accomplish in a 24-hour timeframe, since this was our first hackathon and we didn't really expect to make something this cool.

What's next for SpektrumAR

I think there's a lot of places that we could go with this. Currently, SpektrumAR just plays one audio file (just something from my music library) and loops it once it reaches the end. There's many better ways of doing this; one could make a playlist available, integrate with SoundCloud or the like, or even draw from the user's local media library. Admittedly, each successive item in that list becomes more difficult in a mobile VR context, since a web app doesn't have a great way of interfacing with the user's local file system. I'd also like to add more ambient effects and the option for the user to customize the visualization a little bit. The pie-in-the-sky goal is to make it an augmented-reality experience, so that it can be an overlay over the user's own environment, so that the user could lie on their bed at home and see music around them.
",,https://rodin.io/paul.lucero/spektrumar,,"","javascript, html, rodin, webvr, webaudio",University of Colorado at Boulder,"",p-lucero,University of Colorado at Boulder,warrantgames
HackCU III Asymmetrical Game,http://hackcu3.devpost.com/submissions/72354-hackcu-iii-asymmetrical-game,"This proof of concept that may eventually be turned into a game was made for HackCU III.

The idea is that one person is playing a game where they have to escape some room or fulfill some other objective. They can wander around, mess with objects, and do stuff.

However, they are very likely to fail.

That's where the second player, the observer, comes in. They can look around the room, searching items and figuring out what everything does. They can see some things that the player cannot see as well. The only thing that connects the player and the observer is a log that the observer can type into to give the player some information.

The Player's Controls:

Left/Right/Up/Down or WASD for movement.
E or Enter for interaction/dropping an item from your inventory
Q or Space to open up the inventory.

The Observer's Controls:
Arrow Keys or WASD to look around the room.
The mouse to select an object or the typing bar.
The keys while on the typing bar to type a message to the player; Sent when hitting Enter.

This project uses Processing, which is a library for Java that allows you to do sketches and interactive sketches. (Although Processing calls itself a language, it really is just Java.) I have had a ton of experience in Processing before, but I had never messed around with the server capabilities of Processing before. 

Learning: I learned how to use servers and clients to communicate between two processes within Processing's network library. I had messed with servers a little bit with Unity, but I never actually wrote a Server/Client system until this point. Even then, there's still some stuff that I could've done better. (Having it so two clients communicate with each other on one server, rather than what I've done: Having each process have both a server and a client to the other server.)

Completion: This is pretty much at a proof of concept level currently, since 24 hours apparently isn't enough to create a full demo of this idea. However, for the purposes of a proof of concept, and for building the entire thing in 24 hours, it works wonderfully well!

Design: Hopefully, the controls are pretty simple? The objects are still blocks, though...
",,https://github.com/PlatPlat48/HackCUIII,,"",processing,University of Colorado: Boulder,"",PlatPlat48,University of Colorado at Boulder
Hashlock Option,http://hackcu3.devpost.com/submissions/72355-hashlock-option,"Inspiration

A thing

What it does

How I built it

Challenges I ran into

Accomplishments that I'm proud of

What I learned

What's next for Hashlock Option
",,,,"","",University of Colorado,"",AaronJaramillo,""
Phobos Jump,http://hackcu3.devpost.com/submissions/72357-phobos-jump,"Inspiration

We wanted to do something space related, and we though making an actually useful application would be even nicer.

What it does

You can walk around Phobos using a Samsung Gear VR, as well as jump and enter into orbit!

How we built it

We used Unity for the development, as well as Matlab for the numeric calculus of the gravity and Blender for the 3D models.

Challenges we ran into

Having the VR camera be well oriented when you are upside down is not easy at all.

Accomplishments that we're proud of

What sets this walking simulator apart from others is that the gravity is computed for each point of the space using an accurate physics model, instead of just using a simple approximation as most apps do.

What we learned

We learned how to use Unity, Samsung Gear VR, 

What's next for Phobos Jump

Generalize the gravity model to be able to use it for any planet or satellite, with any given form.
",,,,"","unity, oculus-gear-vr","UPC, CU, Cornell",Samsung Gear VR,aviros,"Cornell University, University of Colorado at Boulder",albertoroperpol,sabr6934,osfu6738
IsThisWebsiteOffline.com,http://hackcu3.devpost.com/submissions/72361-isthiswebsiteoffline-com,"Inspiration

I had this REALLY cool AR hack and it was going awesome until around 20 hours in the Internet decided to slap me across the face. I spent hours trying to get my TCP connection to work, but the UCB firewalls are too strong, VPNs don't work, localhost isn't an option, and even my mobile data failed

What it does

This lets you know if the site is indeed on or now

Challenges I ran into

Not crying over my AR project

Accomplishments that I'm proud of

Not walking over the IT department and starting a fire

What I learned

Bring a router next internet related hack

What's next for Is This Website Offline

To see if it stays online or not
",,http://isthiswebsiteoffline.com/,,Best domain name registered with Domain.com,"three.js, nginx, tears-from-last-project-failing, me-thinking-i-am-funny",University of Wisconsin Madison,"",sjfricke,""
u mad bro?,http://hackcu3.devpost.com/submissions/72362-u-mad-bro,"Inspiration

Working with people with autism, a lot of times they struggle understanding the emotions that are being portrayed by other people in a conversation.

What it does

Using a pebble watch, we are able to detect conversations, convert them to text and send them to IBM Watson, which will interpret the content and will gives us a range of emotions that can be inferred from the conversation. 

How we built it

We used CloudPebble and JavaScript to record and convert from Speech-to-Text. Then we created an API that uses IBM Watson to gives us the tone of the conversation recorded. After that, we converted that tone to a color that is displayed on the pebble watch. 

Challenges we ran into

Using CloudPebble IDE we first used some open source code in C, but we were not able to figure out how to make API calls so we pivoted to JavaScript whose default set-up was wrong, as a result we had to figure out everything from scratch. 
Another challenge that we overcame was to run a python server in node.

What we learned

Each of us learned new skills from each other including audio file in JavaScript, Python in Node, IBM Watson’s API and a lot more. We explored Machine Learning through IBM Watson's: Natural Language Analysis, Tone Analysis, Speech to Text. This allowed us to empathize with our target demographic through hardware that we were not familiar with before, i.e., the Pebble Smartwatch. As a multi-stack, language team, we all shared our experiences of how to best integrate the skills we knew into our project.

What's next for u mad bro?

We intend to further explore the social nuances that autism victims experience. We would like to create an app that works on other wearable devices. Additionally, we would like to take advantage of IBM Watson's capability to scan for certain keywords, so as to be able to alert a friend or family member if the user appears to be in danger.
",https://vimeo.com/214394691,https://github.com/THEAverageSpeedBurrito/speech_to_color_api,,#HackHarassment,"ibm-watson, javascript, python, node.js, love, jquery, pebble, html5, c","Lindenwood, MIT",Pebble Time,malilasage,"Galvanize, Massachusetts Institute of Technology",keenicholas,jordmanwick,AlexAndrei98,evanbusse
Over.LFG,http://hackcu3.devpost.com/submissions/72363-over-lfg,"Inspiration

I play Overwatch for the University of Kansas Crimson Alpha team, and I am also very active in the Overwatch community on campus. A frequent issue we face in the group, is trying to form teams to play competitive game modes. Players must be al within 1000 rating of each other, or within 500 if a player is above a certain rank. 

It can be difficult to figure this out when forming a team as others' rankings are not easily accessible, and you must still figure out the differences between everyone's skill. Our group also enjoys competition, so a ladder style ranking system would be great. I decided that I could combine both of these ideas into a simple web app.

What it does

Over.LFG uses javascript along with an API by Alfg on Heroku to gather data on players received from a text file or text box. The players are sorted and displayed, and can then be clicked to add to a queue. The tool will then display group size, average rank, and other viable teammates within the roster.

How I built it

I built this tool mostly in javascript. I created an html file for the skeleton, but then populated it and add functionality through javascript. The tool also relies on jQuery and a Heroic based API

Challenges I ran into

I've never built a web app or done much with javascript before, so this was certainly a learning experience. I struggled mostly with CSS formatting, and using jQuery functions for file retrieval and HTTP requests.

Accomplishments that I'm proud of

I'm glad I was able to finish, and that I learned how to use javascript to make web requests and handle them appropriately.

What I learned

I learned a great deal about HTTP requests and general file input on a webpage.

What's next for Over.LFG

I hope to continue adding polish and potentially the ability to track ranking changes over time. I also want to share it with broader Overwatch communities such as the subreddit /r/overwatch which has almost 900,000 users that could benefit from the tool.
",,http://masonwilde.github.io/OWTool/index.html,,"","javascript, html, css, heroku",University of Kansas,"",masonwilde,University of Kansas
Risk.io,http://hackcu3.devpost.com/submissions/72373-risk-io,"Inspiration

Utilizes location sharing to allow a large number of random, anonymous players to compete against each other.

What it does

Players are assigned to a random team upon opening the app. Regions are generated across the map, and players press a button collaboratively to try and sway the region to their team's favor.

How we built it

Android studio, Swift with xCode, and a PHP backend

Challenges we ran into

Utilizing custom REST API's in swift.
",,https://github.com/mdepero/HackCU,https://s3.amazonaws.com/challengepost/zip_files/production/23161/zip_files/app-debug.apk,"","php, swift, java, android-studio, xcode","Miami University, University of Colorado Boulder, Purdue","",mdepero,Miami University,mooremegan
HypeYoLyfe,http://hackcu3.devpost.com/submissions/72375-hypeyolyfe,"Inspiration

Do you ever accidentally leave your hype man at home? We do, which is why we built this app!

What it does

When you're feeling down (or just want some hype) simply specify what you need hype for, and the app delivers you a high quality hyped up message.

How we built it

Using Android Studio and Java.

Challenges we ran into

How to get multiple dialog boxes to appear and coming up with suffient hype messages for all of your hyping needs.

Accomplishments that we're proud of

We created our first app! Not only is it super positive but we've created a product for an untapped market.

What we learned

We learned how to use Android Studio and Java.

What's next for HypeYoLyfe

More hype categories, sounds and videos.
",,https://github.com/natalie-betts/HypeYoLyfe,https://s3.amazonaws.com/challengepost/zip_files/production/23164/zip_files/HYPEYOLYFE.zip,"",java,University of Colorado Boulder,"",natalie-betts,University of Colorado at Boulder,Sleepygill,ermontross
Pundering To The Masses,http://hackcu3.devpost.com/submissions/72377-pundering-to-the-masses,"Github doesn't handle external links well. Just go to this website. Copy/paste it into your search bar. main.punderingtothemasses.org 
",,https://github.com/camhealyon/camhealyon.github.io,,Best domain name registered with Domain.com,blogger,Gonzaga University,"",CameronHealy,Gonzaga University
Chartographer,http://hackcu3.devpost.com/submissions/72378-chartographer,"Inspiration

Have you ever needed to create a nice clean chart for class? Ever needed to impress your boss with a beautiful outline? Writing out these charts with pen and paper can be soooo difficult. And creating them on computer programs is tedious, forcing users to learn unintuitive user interfaces. We decided to create a complete chart and outline solution that was easy to use, fast, and intuitive. Enter: Chartographer!

What it does

Chartographer allows users to generate charts and outlines quickly and naturally on their phones using just their touch screens. The user draws a shape anywhere on the screen and the app will use machine learning to determine exactly what shape the user was trying to create and insert it into the chart. The result is a clean chart generated quickly and naturally.

How we built it

Sweat, tears, and less sleep than is probably safe for three grown men. Also, we each drew about 900 squares, circles, and lines for our training data. So... that was great.

Challenges we ran into

The classification algorithm's accuracy was hit or miss. We believe this may be partly due to poor training data.

Accomplishments we are proud of

The app actually works! The classification algorithm works about 90% of the time and inserts a nice clean shape onto the canvas.

What we learned


Leap Motion JavaScript API
A bunch of Machine Learning APIs in Python
Android OpenGL ES for drawing
Python Flask
Bresenham's Algorithm to connect two points by a line in discrete space


What's next for Chartographer


The ability to move objects
Snapping shapes to each other
Add more shapes
Add text options
Align options

",,https://github.com/Wmaxlees/hackcu,,Best use of Amazon Web Services,"android-studio, python, java, javascript, node.js, numpy, scikit-learn, amazon-web-services, github, yeoman, svm, hmm",University of Colorado - Denver,"Alienware Laptop,Oculus Rift,Leap Motion",Wmaxlees,University of Colorado Denver,robfitzgerald,nivin54
N_body_simulation,http://hackcu3.devpost.com/submissions/72379-n_body_simulation,"Inspiration:

-Our fascination with the universe contributed to the creation of a physical simulator. 

What it does

The simulator replicates the physics of an N-Body system.

How we built it

We used C++ and the QT library.

Challenges we ran into


Mathematical models
Precision
Accurate collision mechanics


Accomplishments that we're proud of

A fully functioning program as a first time competing team.

What we learned


Gravitational force as a vector
Team cooperation
Time management
Building a program with an update loop


What's next for N_body_simulation:


Evolves the model into 3D by using openGL
Refines the mathematical modeling
Update the cosmetics of the project

",,https://github.com/HackCUCacheMeOutside/N_body_simulation,,"","c++, qt","University of Colorado Boulder, University of Houston","",LesleyLai,"University of Colorado at Boulder, University of Houston, University of Colorado",sleep0holic,tzatzikisauce
Downspin Balloonist,http://hackcu3.devpost.com/submissions/72380-downspin-balloonist,"Inspiration

The conundrum of esoterica that is life We liked playing with our Spheros, and we thought it would be neat to do mixed reality stuff with it.

What it does

We simulate a virtual ball in a pinball-like environment and replicate that in reality by using a Sphero.

How we built it

We used the sphero.js library to control the Sphero, A-Frame to create the virtual environment, and Firebase to sync the virtual ball's velocity and direction with the Sphero.

Challenges we ran into

We originally planned to make this a multiplayer game, but every A-Frame multiplayer library had issues that we could not overcome within the time limit. We also had issues with syncing the virtual ball with the Sphero, which burned through a lot of our time that we could have used to complete the game portion.
",,https://github.com/technoboy10/downspin-balloonist,,"","javascript, aframe, firebase, webrtc, sphero",University of Colorado Boulder,"",technoboy10,University of Colorado at Boulder,KBooksforever
Super Emoji Face,http://hackcu3.devpost.com/submissions/72381-super-emoji-face,"We trained a deep convolutional neural network to recognize 7 emotions (Angry, Disgusted, Fearful, Happy, Sad, Surprised, Neutral). We then turned the emotions into emojis and used websockets to update the emojis in close to real time. Now you can see the emotions of your friends or other people you are playing against online without being next to them!
",,,,"Best domain name registered with Domain.com, Best use of Amazon Web Services","cv2, tensorflow, numpy, pandas, express.js, node.js, socket.io, html5, css3, python",University of Wisconsin-Madison,"",connorstamper,""
ReverQuest,http://hackcu3.devpost.com/submissions/72382-reverquest,"Inspiration

AppleTv

What it does

It creates enjoyable routes between the source and destination suited for bikers and allows user to see routes taken by his friends.

How we built it

We used flask, aws, mysql, angular js, leaflet js, Mapquest API, Facebook api, Bootstrap to build the project

Challenges we ran into

Integration with multiple apis was very challenging

Accomplishments that we're proud of

Learned several new APIS, workflows and successfully deployed the app in aws.

What's next for ReverQuest

Planning to integrate Fitbit data while riding and detecting anomalies and using spotify to suggest playlist.
",,https://github.com/logeswarishanmugavel/HackCU,,"","mapquest-api, amazon-web-services, python, leaflet.js, mysql, angular.js, bootstrap",University of Colorado Boulder,"",narain280493,University of Colorado Boulder,atpa2251,losh4423994
Sinque,http://hackcu3.devpost.com/submissions/72383-sinque,"Inspiration

We've all had those days where we want to change a music track while in the shower or while jogging/exercising hands free. So we added continuous voice control to it!

What it does

Voice controlled Spotify.

How we built it

Spotify web API, python, Android, ibm-watson

Challenges we ran into

Designating tasks to team members and integrating parts. (server and client)

Accomplishments that we're proud of

Building Sinque!

What we learned

Learned to use ibm watson and spotify web API.

What's next for Sinque

More voice controlled features.

Links to repo

Android app: https://github.com/aneeshverenkar/SpeechToText
Spotify server API requests: https://github.com/aneeshverenkar/HackCU
",,,,"","python, spotify, android, java, ibm-watson",university of Nebraska-Lincoln,"",aneeshverenkar,"University of Nebraska - Lincoln, University of Nebraska Lincoln, university of nebraska",m-block,themchimself,failsatheals
ID10T-errors,http://hackcu3.devpost.com/submissions/72387-id10t-errors,"Inspiration

Stackexchange and Yahoo Answers

What it does

It's a website that answers simple questions with simple answers for simple problems. For simple people. 

How we built it

Domain.com free domain and weebly website creator

Challenges we ran into

Website would not publish right away so viewing changes was difficult. Also, the page doesn't seem to load correctly on Wi-Fi. When opening the page on 4G/LTE, the webpage we created using weebly opens up. It opens the default domain.com page when opening if on Wi-Fi. It's a mystery. 

Accomplishments that we're proud of

It's looking pretty good.

What we learned

How to work with domain.com and weebly to create a visually appealing website with whatever name you want.

What's next for ID10t-errors

Open forums and users. 

The Sad Man picture came from: http://hdwallpapersrocks.com/i-miss-u/sad-man-seating-lonely-i-miss-you-wallpaper/

PS. Just to make it clear, the website is for idiot (id10t) problems. But in 1337.
",,http://id10t-errors.net/,,Best domain name registered with Domain.com,"weebly, domain.com, sad-men",University of Colorado Boulder,"",leungtw,University of Colorado at Boulder,Whatamia
Tonite,http://hackcu3.devpost.com/submissions/72388-tonite,"Tonite

Android app that helps users find what's going on around them. Utilizing carefully crafted recommendation algorithms, Tonite is able to present users with the best events happening in their area.

CarpoolMag.net

Tonite has interopeability with CarpoolMag.net, a carpool finding app that matches people heading to the same place. It's not a competitor to Uber or Lyft. It's simply a way to catch a ride from a new friend.
",,https://github.com/kbcovingtonjr/Tonite,,"","java, python, javascript","CU Boulder, Niwot HS","",hi-im-ryan-baten,University of Colorado at Boulder,Jaxkr,mgilroy
Re-Cal-Ibrate,http://hackcu3.devpost.com/submissions/72389-re-cal-ibrate,"Inspiration

What it does

How I built it

Challenges I ran into

Accomplishments that I'm proud of

What I learned

What's next for Re-Cal-Ibrate

UPDATE LATER
",,,https://s3.amazonaws.com/challengepost/zip_files/production/23168/zip_files/Recalibrate.zip,"","r, shiny, html",University of Arizona,"",ryan-papetti,University of Arizaona
Real Talk,http://hackcu3.devpost.com/submissions/72390-real-talk,"Inspiration

We are want to provide an effective tool to allow people to identify patterns within themselves so they can track things that improve their mood and worsen it. Identifying triggers and your patterns is an effective skill to manage mental health.

What it does

It tracks your mood with Amazon Alexa daily and helps to determine trends that affect your mood

How we built it

We used Amazon Alexa Skill SDK with AWS lambda to deploy a flask application in python. Also used html, javascript and python to analyze the data.

Challenges we ran into

Exporting regression analysis based on factorial design of the different factors in relation to mood.

Accomplishments that we're proud of

Building all the different components together and connecting them

What we learned

How to connect a database through AWS. Creating a factorial design via Python. Learned about Amazon alexa.

What's next for Real Talk

Refining the hackathon code and continuing development after HackCU 3.
",,https://github.com/tforrest/real-talk,,"#HackHarassment, Best use of Amazon Web Services","alexa, python, flask, javascript, amazon-web-services",Arizona State University,Amazon Echo,tforrest,Arizona State University,rachelknoche,mcaprile
The case of the missing ceiling tile,http://hackcu3.devpost.com/submissions/72391-the-case-of-the-missing-ceiling-tile,"Inspiration

""It's easier to ask forgiveness than it is to get permission""


Read Admiral Grace Murry Hopper

",,,,"","arduino, desperation, the-worst-leds-strips-in-the-world, our-hopes-and-dreams",University of Colorado Boulder,"",koscida,""
Alteryx Decryption,http://hackcu3.devpost.com/submissions/72392-alteryx-decryption,"Strategy

This breakdown of our deciphering process illustrates how we utilized alteryx at HackCU.

First Step

Characterize letter frequencies:


Regular expressions were used to parse the original ciphertext into rows of 2 character pairs
A Frequency Table Node was then applied to these rows to determine the relative frequencies of each character pair.


Second Step

Compare known letter frequencies


A record ID node was used to structure our data prior to comparison
The relative frequencies of english letters was compared to the histogram that was created on our 2 character pairs.


What does Pig Latin do to letter frequencies?

The number of occurrences of any given letter in the English language is thrown off when translated into Pig Latin. This is due to the fact that every word becomes translated into a similar version of itself with the letters A and Y appended to the word.

Considering this fact, it is important to note that the frequencies we observed in the ciphertext will not line up perfectly with what you would expect out of a normal frequency analysis.

A note about Pig Latin Dialects

According to the internet, Pig Latin can take on a few different forms. Some dialectics have different rules about what happens to words that start with vowels.

Some say:  Ocean   -->    Ocean way

Others say:  Ocean   -->    Ocean ay

With a bit of analysis on our data following some attempts on decoding the ciphertext, it became obvious that this particular set of Pig Latin utilizes a dialect in which words starting with vowels are translated in the following way:

Ocean   -->    Ocean yay

After making this discovery, it became trivial to fill in mappings between 2 character pairs and actual Pig Latin letters. 

But what about data loss?!?

Digging into things, we made the discovery that Pig Latin has some fatal encoding flaws. 
The issue is that when translating words that have consonant clusters at the front, multiple characters must be moved to the back of the word to create the Pig Latin equivalent. This creates a problem when attempting to return back from the Pig Latin, since there is no unique identifier to indicate that the original word contained one or several consonants as a prefix.

In other words, translating words to and from Pig Latin is not a one-to-one relationship.

To investigate the impact of this issue, we went ahead and wrote a python script to enumerate all of the potential words found in the original text which conflict due to consonant clusters.

Results:

Counting the occurrences, we found a total of 118 words with conflicts in the provided text.
If you account for positioning of apostrophes, this number goes up to 186 words!

Take a look at the gists below to see all collisions:


Collisions without quote issues
Collisions with quote issues


Tooling

We used a lot of python scripts to help solve the initial encoding of characters. All python files can be found at github.com/mguida22/alteryx-crypto and the alteryx workflow was submitted by email.

Contributors


Ben Williams
Michael Guida
Andrew Gentry
Travis Benson
Collin Berg

",,https://github.com/mguida22/alteryx-crypto,https://s3.amazonaws.com/challengepost/zip_files/production/23179/zip_files/Archive.zip,Alteryx,alteryx,University of Colorado Boulder,"",mguida22,""
HackCU 3 Plays: Mystery Dungeon,http://hackcu3.devpost.com/submissions/72393-hackcu-3-plays-mystery-dungeon,"Inspiration

Twitch Plays Pokemon seemed like a really cool idea, and I thought, why can't I try and build that?

What it does

Twitch viewers interact with the chat bot with various commands. The command is then forwarded to the Game Boy Advance Emulator. There is also a custom chat on the side to show people how quickly their commands are being sent so they can collaborate.

How I built it

I wrote a twitch chat bot in Node.js to parse that chat. It just reads for hardcoded instructions for now, meaning that it will only look for !up or !Up/!a/all the buttons, but I would like to add a token analyzer if I win the Amazon credits to allow people to make multiple instructions at a time and increase stream quality. Then, it calls a python script to call the win32 api and tap the appropriate key. Also, I built a small hack on the twitch chat api so that the stream could constantly be updating with the latest chat in a seamless way. All of this runs on a AWS EC2 container. 
Special note, I chose AWS because they own Twitch now and all streaming will be considered internal traffic and I will not have to pay to leave the data center.

Challenges I ran into

I couldn't get any amazon credits for this so its all out of my pocket right now, and the free instances were not powerful enough to run this app.

Accomplishments that I'm proud of

The key interaction was pretty difficult, I was satisfied with the win32 api solution as well as changing all of the inputs to the GBA Emulator to numbers as they are the most consistent to send through the win32 api. Optimizing the process scheduling to run effectively on a AWS container was very difficult as well. 

What I learned

I learned how to implement a twitch chat bot, how to use python to script things similar to how autohotkey works, I learned how to embed html/javascript in a stream, I learned how to stream on twitch, I learned how to use AWS, I learned how to optimize processes for running in a container.

What's next for HackCU 3 Plays: Mystery Dungeon

Well, if I win the AWS prize, upgrade the streaming container, iron out a couple streaming bugs with AWS, add a few more chat bot features and, finally, market it a lot more to share it with more people through Reddit, Friends, etc.
",,https://www.twitch.tv/robo_games942,,Best use of Amazon Web Services,"node.js, python, obs, javascript",University of Colorado at Boulder,"",saba6857,""
PartyBuddy,http://hackcu3.devpost.com/submissions/72394-partybuddy,"Does that occur to you that sometimes you spotted a party nearby and want to get hyped together, but you don't know how to join? Do you want to reach out new people and attend the best local meetings/parties? These questions inspired our team to develop this IOS app that aims to help users host, request and attend parties.

To make this app, we split the task into front-end(Objective-C) and back-end (Java), and linked the whole app together with AWS and restful-web-service. We incorporated multiple APIs from Mapquest, Facebook. We four cooperated greatly and worked hard for 24h to enable the birth of this awesome app.

We had great difficulties in establishing an Http server on Amazon Web Service and have spent lots of hours on that. We had trouble accessing the server from external computers and asked a lot of mentors and workday engineers here (thank you so much!). And finally, we are able to build our server on top of AWS.

Due to the great difficulties in setting up the server, so we are really proud of the http server we've set on AWS. It provides a RESTful service and JSON responses and can be accessed from any computer, instead of only local machines. 

what we learn:


How to host a server on AWS.
How to run java code on AWS remotely.
How to use MongoDB in Java.
How to link Objective C frontend with Java backend.


We are going to add more features and make it more intelligent to search for parties and other entertainments for users. 
",,https://github.com/AustinZzx/PartyBuddy,https://s3.amazonaws.com/challengepost/zip_files/production/23171/zip_files/PartyBuddy.jar,"MapQuest API Prize, Best use of Amazon Web Services","java, objective-c, amazon-web-services, facebook-login-api, mapkit, mapquest, json, github, ios, gps, mongodb, restful-web-services",USC,"",Jingxing-Yang,University of Southern California,tianchez,AustinZzx,SeasonJi
CyberTurret,http://hackcu3.devpost.com/submissions/72395-cyberturret,"Inspiration

We wanted a way to decrease cyber bullying by creating physical consequences for  people

What it does

It monitors a chat room called slack and shoots anyone who curses. It also takes commands from people in the chat room to shoot at others. 

How we built it

We had a USB nerf-gun turret that we used python, hubot, and a headless ras-pi instance to implement

Challenges we ran into

The turret refused to shoot people despite proper code

What we learned

We learned 

What's next for CyberTurret

We want to deploy a cyber turret across every router in the nation. This will greatly reduce cyber bullying through physical consequences.
",,https://github.com/lalaithion/cyberturret,,#HackHarassment,"hubot, slack, raspberry-pi, python, cats",University of COlorado,"",aowsenek,"University of Colorado, University of Colorado at Boulder",izwe5504
CardioWear,http://hackcu3.devpost.com/submissions/72396-cardiowear,"Inspiration

Nowadays, a wide spectrum of wearable electronic circuits aim to provide useful feedback regarding patients’ health conditions. However, the existing electronic packages are often rigid and non-stretchable, whereas the human body is soft, curvilinear and elastic. Because this, the currently available commercial products tend to be uncomfortable, so people have a hard time developing the habit of monitoring their health using such products; it is uncommon to find people who can easily and readily monitor their heart condition and core temperature every day using existing products. We want to provide a product that make this process easy.

What it does

The product provides easier everyday health monitoring through ECG (Electrocardiogram) and temperature analysis. We use use a iOS app collect data from the hardware devices and plot the ECG curve on the app.

How we built it

To communicate with the hardware, we have  a simblee module that collect data from user, and sent back the ECG data, heart rate as well as body temperature back to the smartphone via BLE. Then the app will process the ECG data, and send it back to the cloud the server. Later, the ECG data will be plot on the iOS app using d3.js.

Challenges we ran into

When we tried to send data back to the iOS app, we had a problem decoding the data. Also, the BLE device create a rather big latency. 

Accomplishments that we're proud of

We can now have a dynamic plot of ECG curve on the iOS app!

What we learned

We learn about BLE, and use of d3.js in this project.

What's next for CardioWear

We want to have a realtime later
",,https://ecg01.herokuapp.com/index/,,"","swift, d3.js, django, python, sqlite, heroku, simblee",University of Colorado at Boulder,"",YanyuXiong,University of Colorado at Boulder,woshibala
hackcu-clickbait,http://hackcu3.devpost.com/submissions/72397-hackcu-clickbait,"Inspiration

Browsing the internet and getting the content you are looking for has actually become a challenge in today's world. Every news outlet breaks an article down into multiple pages for extra ad revenue. 

What it does

We trained an ML model to power a Chrome Extension to make scrolling Facebook a better experience. The goal was to eliminate titles such as ""12 reasons why you should..."" and 

How I built it

We utilized Python BeauitfulSoup, CheerioJs, and the Reddit API to scrape articles to train an ML model. We used a node backend to set up an API to talk to Amazon ML to determine wether or not an article is clickbait. From there it communicates with a chrome extension to pull article links and headlines while the user is scrolling facebook. After this in real time, we used Node and Cheerio to scrape the source of the article. This accomplished several things. We can combined multi page articles down to a single reading experience with the hopes of injecting the new content directly into a users Facebook feed after passing through a summarization API called summary.

Challenges I ran into

Facebook was very blocking with the scripts we could inject. No two news websites are the same so scraping the articles themselves was a large challenge. On top of that we had to compile together a dataset to train the ML model. 

Accomplishments that I'm proud of

Some crazy Regex
Real Time API 
Accurately identify clickbait articles
Scraping data from news sites that were not alike.

What we learned

Amazon ML
NodeJS
Express
jQuery
Chrome API
Reddit API

What's next for hackcu-clickbait

We are very close to having a product worth being very proud of that will hopefully catch some traction. We are excited to move forward with the project.
",,https://github.com/JustinWayneOlson/hackcu-clickbait,,Best use of Amazon Web Services,"javascript, python, amazon-web-services, amazon-machine-learning, node.js","Milwaukee School of Engineering, UC Boulder","",zawadzkip,"Milwaukee School of Engineering, University of Colorado Boulder",laurenraddatz
whereUchat,http://hackcu3.devpost.com/submissions/72398-whereuchat,"HackCU Hackathon

Location Based Chatting

With WhereUchat we want to enable people to connect with other people around them, in real time. Our team has implemented a web-based application. Our application takes in the name of the user as well as the radius around him he wants to listen to. We are detecting the exact location of the user in near real-time. 

Challenges our team faced:
We started with a very ambitious idea. Our team took our time to cut the scope of the application to actually build a MVP. All of us used backbone.js for the first time which less of an obstacle and more of a learning experience.

Future Scope:
Starting with an ambitious perspective has given us vision to design an efficient project design that can be scaled-up in the future. For eg. we could add more features in the future like private user messages, chat rooms.
",,https://github.com/radhikabhatt/locationbasedChat,,"","javascript, css, html, socket.io, backbone.js, bootstrap, jquery","UPC, USC, UCB, CCD.","",yoelcabo,"UPC, Community College of Denver, University of Southern California",david_wreschner,radhikabhatt
wholesome booty,http://hackcu3.devpost.com/submissions/72399-wholesome-booty,"Inspiration

Cole Kenny always wanted to make a Reddit bot and this was the perfect opportunity as we had just scrapped our twentieth idea.

What it does

Not much.

How we built it

Python Reddit API library (praw) and sample code from LDA tutorial by Jordan Barber, the one and only.

Challenges we ran into

Natural language processing. Specifically, tfidf and LDA, you know what I mean? because I don't.

Accomplishments that we're proud of

Good joke.

What we learned

How to use Reddit API and navigate its documentation.

What's next for wholesome booty

Perfect natural language processing in order to fend off the forces of harassment on the Internet. 
",,https://github.com/robogungt8/blint,https://s3.amazonaws.com/challengepost/zip_files/production/23172/zip_files/booty.zip,#HackHarassment,"wholesomememes, compassion, love, python, reddit",CU BOULDER,"",buki4157,"",colemcpguns
SiriQuery,http://hackcu3.devpost.com/submissions/72401-siriquery,"Inspiration

We felt that Siri was a little too trapped in her Apple devices, so we decided to free her.

What it does

The web page sends either voice or text commands to Siri and returns her verbal response along with a screenshot.

How we built it

The web page sends the input through and AWS server to a Mac running our server application. The app triggers Siri, passes along the input, records the response, screenshots the Siri window, and passes it back to the web page.

Challenges we ran into

We had a lot of trouble passing audio back and forth. Transferring between the web page, AWS server, and Mac server was difficult. We also ran into trouble piping audio from the Mac server to Siri and back on the same machine. We also had problems with timing the commands correctly so the Mac server interacts with the Siri app correctly.

Accomplishments that we're proud of

Cal is proud he figured out how to write a Node server and Nate is proud that the Mac server interfaces with Siri so well. We're both proud that we managed to get Siri functioning on a website.

What we learned

Cal learned a lot about Node.JS and Nate learned a lot about Swift and Mac development.

What's next for SiriQuery

We'd like to make it so the audio is transferred live like a phone call so queries would be almost as fast as natively on the device. We also think it would be cool to bring it to Amazon Echo.
",,http://default-environment.r34djy5xx2.us-west-2.elasticbeanstalk.com/#,,"Best domain name registered with Domain.com, Best use of Amazon Web Services","swift, javascript, node.js, amazon-web-services, siri, macos","Georgia Institute of Technology, Georgia State University","",thompsonate,"",calda
HackCU-2017,http://hackcu3.devpost.com/submissions/72402-hackcu-2017,"1) Command.py is python file which queries DynamoDB on AWS and print changing direction.
2) NewWorkingLambdaFunc is the lambda function code which needs to be there on AWS (not to be run on local system)
3) ""Intent Schema"" on developer.amazon.com:
{
  ""intents"": [
    {
      ""slots"": [
        {
          ""name"": ""Command"",
          ""type"": ""LIST_OF_COMMANDS""
        }
      ],
      ""intent"": ""BotMovementIsIntent""
    },
    {
      ""intent"": ""WhatsNewBotDirectionIsIntent""
    },
    {
      ""intent"": ""AMAZON.HelpIntent""
    }
  ]
}

4) Echo Skill Config


5) Lambda Configureation:

",,https://github.com/vibhormishra/HackCU-2017,,"","python, amazon-web-services, amazon-dynamodb, aws-lambda, ros",University of Colorado Boulder,Amazon Echo,vibhormishra,University of Colorado at Boulder
Alteryx Cryptography Challenge,http://hackcu3.devpost.com/submissions/72403-alteryx-cryptography-challenge,"Alteryx Crypto Challenge. Solved individually with no mentor assistance and only the first 4 hints.
",,https://github.com/gsawich/AlteryxChallenge,https://s3.amazonaws.com/challengepost/zip_files/production/23173/zip_files/gsawichCypher.zip,Alteryx,alteryx,University of Colorado Denver,"",gsawich,University of Colorado Denver
Alteryx challenge Ali-Smit,http://hackcu3.devpost.com/submissions/72407-alteryx-challenge-ali-smit,"Inspiration

What it does

deciphers text 

How we built it

Challenges we ran into

Accomplishments that we're proud of

What we learned

What's next for Alteryx challenge Ali-Smit

Table Number

ROOM 205 Table 1
",,https://www.dropbox.com/sh/j0x4shonh0059ak/AACEO4vFO3xM9GnWRBDy-mC8a?dl=0,https://s3.amazonaws.com/challengepost/zip_files/production/23176/zip_files/Alteryx_Smit.zip,"","python, alteryx",CU Boulder,"",alnassirah95,University of Colorado at Boulder
Reverever,http://hackcu3.devpost.com/submissions/72408-reverever,"Inspiration

“A Good long ride can clear your mind, restore your faith, and use a lot of fuel”. 
As of the most recent report by the Department of Transportation, there were 8,410,255 motorcycles registered in the United States by private citizens and commercial organizations in 2011. To put this staggering number into perspective, out of every 36 people you meet in the U.S., one of them probably has a motorcycle.
 We, the developers of Reverever wanted to fulfill the dreams of millions of motor-bike lovers and people who are fascinated about a relaxing long drive with a holistic user experience that enhances the very concept of long drives. 

Contrary to the orthodox belief that, driving safe requires you restrict yourselves and focus seriously on the job, we believe that people can drive safe and enjoy the fun that comes along with a drive.

What it does

We do this, by providing the user, with a pleasant experience of driving in the most beautiful routes of the nation which boasts about 33% of green and fresh land that comes along with breathtaking scenic views ( http://data.worldbank.org/indicator/AG.LND.FRST.ZS ). We strongly believe that passionate motorbikers do deserve the opportunity to relish the Mother Nature. We aid them by crowdsourcing a set of picturesque locations and geotag them to provide them with a calm, serene and sublime routes. And guess what? The drivers don’t have to do anything extra! We take care of capturing breathtaking pictures of the places, whenever the driver stops. We further, characterize the image and provide tags, weather and other extra features of the place. We further pool out the temperature, breeze and bumpiness of the route of travel to provide greater amount of information, well before a planned ride, coz C’mmon, people would love a plethora of options to choose from.

Go ride! Drive safe! And do not miss out on loads of fun it comes along with.

How we built it

We have a state-of-the art multidisciplinary team, that strives hard to learn and innovate with new stuff.
We used the Raspberry Pi interfaced with a Camera, that snaps a picture whenever a vehicle stops, processes it using the Microsoft Cognitive Services to provide a detailed description of the place along with a captivating caption. We use the confidence of the information retrieved to provide fruitful outputs in the form of weather conditions, conditions for driving, traffic and various other real-time parameters to the user. 

The image captured using the Raspberry Pi Camera is first uploaded into an AWS S3 Bucket. A Lambda function will be triggered with insertion of image into S3 which will query the database to get the specifics of the image. This function obtains the characteristics of the image using the Microsoft Cognitive Services which describes the scenic beauty of the place. In addition to this, in case a Speed Limit Board is encountered, its characteristics are provided too. We are also using MapQuest APIs to obtain the location. On fetching the necessary information, we log them into a MySQL Database running on AWS RDS Service.

Further, As an extension to our product, with a strong societal value, we believed that, the vision and speech, though considered as core senses, are not the only way to experience the wonderful nature and decided to put a smile on their faces. We developed a prototype that provides an immersive experience to visually impaired people to feel the fresh air on their faces and listen about key aspects of the place they are in during a long drive whenever they wish. We did this by using a high performance NVIDIA TX1 GPU, that captures images on demand and provides voice-over description of beautiful and much needed aspects of the place.

Challenges we ran into

Hardware Integration issues. GPU interfacing Issues. AWS SQS, Lambda-RDS integration

We spent a lot of time trying to do a remote access into the DB instance created on RDS Service. This was necessary to create the table and to log in image related data. We deciphered the issue to be in the Security Groups configuration while creating the DB Instance.

We also faced a couple of issues while installing the Python libraries necessary for successful execution of the code in AWS Lambda. Further, the crowdsourcing simulations involved a lot of complications.

Accomplishments that we're proud of

Getting the Image capture performed on Raspberry Pi and passing the image over AWS S3, AWS EC2 and AWS Lambda Services as well as NVIDIA GPU interfacing.
Geotagging, with Chat Bot Implementation and the MAP-based WEBGUI.
Finding Picturesque Locations.
Crowdsourcing implementations

What we learned

We learned a crazy lot from HW as well as SW perspective on the Above topics

What's next for Reverever

We are Planning to expand with improvement in CUDNN Models for improved Machine learning
",,https://github.com/Mounika1494/HackCU.git,,"MapQuest API Prize, Best use of Amazon Web Services, BMW Motorrad/Rever","python, mapquest, google-web-speech-api, google-maps, ml, gpu",The University of Colorado Boulder,"",MounikaReddyEdula,"University of Colorado, University of Colorado Boulder",abhijit5893,bhallaji,disa6302
Accident detection and Prevention System (ADPS),http://hackcu3.devpost.com/submissions/72412-accident-detection-and-prevention-system-adps,"Number of cars have increased in the past 10 years, and hence the accidents rate has also drastically increased. Our  idea is to avoid accidents as much as possible and assist the driver with some essential information

Our product detects ""speed limit"" signs, ""stop signs"" on the road. Some times drivers will not see the signs properly. So if they go in a speed of 70mph in an area which has a limit of 40 mph, then accidents can occur easily. So our application assists the driver to find the current speed limit of the road. It also detects the accidents and reports on the accidents.

We used python scripts to emulate the process. The script runs in the raspberry pi. It takes snapshots every second and analyzes the image for stop sign and speed limit sign. This can be extended for any sign. We also have a vibration sensor which is used to detect an accident. If an accident is detected then the accident information is sent to near by hospitals and also to registered people. We used APIs like Cisco Spark, Microsoft Cognitive services, Google APIs and MapQuest APIs.

To detect the speed limit sign it was little difficult because we didnot had the sign with us. We did not get a camera to interface with the raspberry pi and have simulated the same in the laptop.

We are proud about the fact that we have contributed an application that assists drivers to avoid accidents and save potential lives.

We learned a lot through out the process. We learned how to use Microsoft Cognitive services and also MapQuest API.

Next our idea is to get a good camera and research about the accuracy. 
",,https://github.com/avra0601/Hack-CU---ADPS,https://s3.amazonaws.com/challengepost/zip_files/production/23181/zip_files/code.zip,"","python, microsoft-cognitive-api, amazon-web-services, android-studio",University of Colorado Boulder,"",avinashrmaharaj,University of Colorado Boulder,sisu7691
